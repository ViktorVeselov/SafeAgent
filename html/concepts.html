<html><head><meta charset='UTF-8'><link rel='stylesheet' href='style.css'></head><body><nav><a href="index.html">Index</a> <a href="quickstart.html">Quickstart</a> <a href="concepts.html">Concepts</a> <a href="reference.html">Reference</a></nav>
<h1>Core Concepts</h1>

<p>MiniLLM consists of small, composable modules that can be swapped out as your application grows. The default configuration uses Gemini for text generation and embeddings.</p>

<h2>Memory Manager</h2>

<p>`MemoryManager` stores a rolling summary of past conversations. It supports a Redis backend for persistence and an in-memory fallback for quick testing.</p>

<h2>Retrievers</h2>

<p>Two retrievers help fetch relevant documents:</p>

<ul>
<li>`VectorRetriever` uses FAISS for similarity search. It calls the `gemini_embed` function to compute embeddings.</li>
<li>`GraphRetriever` performs Neo4j graph search and also relies on the Gemini embedding API for text similarity.</li>
</ul>

<h2>Orchestrator</h2>

<p>`SimpleOrchestrator` connects each step of the workflow in a directed acyclic graph. You can add nodes and edges to customise the execution order.</p>

<p>Together these pieces let you build durable, stateful agents that remember past context and retrieve domain knowledge when answering new questions.</p>
</body></html>
