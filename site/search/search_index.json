{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SafeAgent","text":"<p>SafeAgent is a minimal, flexible framework for orchestrating production-ready LLM agents. It provides pluggable components for retrieval, memory, and orchestration with enterprise-grade governance, reliability, and observability built-in from day one.</p> <p>While many tools can help you build a prototype, SafeAgent is designed to build systems you can confidently run in production.</p>"},{"location":"#the-safeagent-advantage-beyond-the-prototype","title":"The SafeAgent Advantage: Beyond the Prototype","text":"<ul> <li>Unparalleled Governance &amp; Observability: Every action\u2014from LLM calls to tool executions\u2014is automatically audited with detailed logs for cost, latency, and data lineage. This isn't an add-on; it's part of the core framework.</li> <li>Production-Grade Reliability: Build resilient agents with built-in policies for caching (with TTL), automatic retries with exponential backoff, and circuit breakers to prevent cascading failures.</li> <li>Secure by Design: A declarative, role-based access control (RBAC) system for tools ensures that agents and users only have access to the functions they're authorized to use.</li> <li>Developer-First Experience: With features like automatic tool-schema generation, optional state validation, and a visual run tracer (via the audit log), SafeAgent is designed to maximize developer velocity and minimize debugging headaches.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Tutorial: See the power of SafeAgent in a single, runnable script.</li> <li>Configuration: Learn how to configure SafeAgent for your environment.</li> </ul>"},{"location":"#ready-for-advanced-use-cases","title":"Ready for Advanced Use Cases?","text":"<ul> <li>Stateful Agents: See how to build complex, cyclical agents using the <code>StatefulOrchestrator</code>.</li> <li>Production Policies: Dive deep into the reliability and cost-management features of the <code>ToolRegistry</code>.</li> <li>Output Sinks: Learn how to automatically send tool outputs to other systems like files or message queues.</li> </ul>"},{"location":"comparison/","title":"Comparison to LangGraph","text":"<p>LangGraph is a powerful library for building stateful, multi-actor applications. SafeAgent shares this goal but takes a different, more opinionated approach focused on production-readiness from day one.</p>"},{"location":"comparison/#philosophy","title":"Philosophy","text":"<ul> <li>LangGraph: A flexible, low-level toolkit that requires you to build your own surrounding architecture for governance, reliability, and operational monitoring.</li> <li>SafeAgent: A \"batteries-included\" framework providing a complete architecture with pre-integrated, production-grade components for these critical functions.</li> </ul>"},{"location":"comparison/#key-differences","title":"Key Differences","text":"Feature LangGraph SafeAgent Governance Not a built-in feature. A core, defining feature. Automatic, detailed audit logs for every action. Reliability Requires custom implementation. Built-in via declarative policies. Caching, retries, and circuit breakers. Security Requires a custom solution. Built-in via declarative policies. RBAC to restrict tool access. Tool Management Manual schema creation. Automatic schema generation and semantic search to find relevant tools."},{"location":"comparison/#when-to-choose-which","title":"When to Choose Which?","text":"<ul> <li>Choose LangGraph when you need highly customized or unconventional graph structures, or prefer to build your own architecture from low-level primitives.</li> <li>Choose SafeAgent when your priority is building robust, observable, and secure agents for production, and you want to accelerate development with pre-built solutions.</li> </ul>"},{"location":"concepts/","title":"Core Concepts","text":"<p>MiniLLM consists of small, composable modules that can be swapped out as your application grows. The default configuration uses Gemini for text generation and embeddings.</p>"},{"location":"concepts/#memory-manager","title":"Memory Manager","text":"<p><code>MemoryManager</code> stores a rolling summary of past conversations. It supports a Redis backend for persistence and an in-memory fallback for quick testing.</p>"},{"location":"concepts/#retrievers","title":"Retrievers","text":"<p>Two retrievers help fetch relevant documents:</p> <ul> <li><code>VectorRetriever</code> uses FAISS for similarity search. It calls the <code>gemini_embed</code> function to compute embeddings.</li> <li><code>GraphRetriever</code> performs Neo4j graph search and also relies on the Gemini embedding API for text similarity.</li> </ul>"},{"location":"concepts/#orchestrator","title":"Orchestrator","text":"<p><code>SimpleOrchestrator</code> connects each step of the workflow in a directed acyclic graph. You can add nodes and edges to customise the execution order.</p> <p>Together these pieces let you build durable, stateful agents that remember past context and retrieve domain knowledge when answering new questions.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Follow these steps to try the demo agent.</p>"},{"location":"quickstart/#installation","title":"Installation","text":""},{"location":"quickstart/#install-the-package-with-the-testing-extras-so-you-can-run-the-included-example-and-tests","title":"Install the package with the testing extras so you can run the included example and tests:","text":"<p>Install the package with testing extras:</p> <pre><code>pip install -e .[test]\n</code></pre> <p>Set your Gemini API key in the environment:</p> <pre><code>export GEMINI_API_KEY=&lt;your-key&gt;\n</code></pre>"},{"location":"quickstart/#running-the-example","title":"Running the example","text":""},{"location":"quickstart/#execute-the-pipeline-entrypoint-to-start-a-question-answering-agent","title":"Execute the pipeline entrypoint to start a question-answering agent:","text":"<p>Run the example pipeline:</p> <pre><code>from minillm.pipeline import main as run_pipeline\nrun_pipeline()\n</code></pre> <p>The agent will retrieve documents, call Gemini to generate an answer and store a summary of the conversation.</p>"},{"location":"quickstart/#configuration-values-such-as-model-name-vector-index-path-and-database-credentials-are-controlled-by-environment-variables-see-minillmconfigconfig-for-defaults","title":"Configuration values such as model name, vector index path and database credentials are controlled by environment variables. See <code>minillm.config.Config</code> for defaults.","text":"<p>Configuration values are read from environment variables, e.g. <code>GEMINI_API_KEY</code> for Gemini models. See <code>minillm.config.Config</code> for the complete list of defaults.</p>"},{"location":"reference/","title":"API Reference","text":"<p>This page provides the auto-generated API reference for the MiniLLM library, created directly from the source code's docstrings.</p>"},{"location":"reference/#core-components","title":"Core Components","text":""},{"location":"reference/#safeagentconfig","title":"<code>safeagent.config</code>","text":"<p>Simple configuration loader with environment variable defaults.</p>"},{"location":"reference/#safeagentgovernance","title":"<code>safeagent.governance</code>","text":""},{"location":"reference/#safeagent.governance.DataGovernanceError","title":"<code>DataGovernanceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when governance policies are violated.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>class DataGovernanceError(Exception):\n    \"\"\"Exception raised when governance policies are violated.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager","title":"<code>GovernanceManager</code>","text":"<p>Manages data governance policies, including encryption, auditing, retention policies, and run ID management.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>class GovernanceManager:\n    \"\"\"\n    Manages data governance policies, including encryption, auditing,\n    retention policies, and run ID management.\n    \"\"\"\n\n    def __init__(self, audit_log_path: str = \"audit.log\", retention_days: int = 30):\n        self.audit_log_path = audit_log_path\n        self.retention_days = retention_days\n        open(self.audit_log_path, \"a\").close()\n        self.current_run_id = None\n\n    def start_new_run(self) -&gt; str:\n        \"\"\"Generates a new unique ID for a single, complete run of an orchestrator.\"\"\"\n        self.current_run_id = str(uuid.uuid4())\n        return self.current_run_id\n\n    def get_current_run_id(self) -&gt; str:\n        \"\"\"Returns the ID for the current run, creating one if it doesn't exist.\"\"\"\n        if not self.current_run_id:\n            return self.start_new_run()\n        return self.current_run_id\n\n    def encrypt(self, plaintext: str) -&gt; str:\n        \"\"\"Encrypt sensitive data before storage.\"\"\"\n        return fernet.encrypt(plaintext.encode()).decode()\n\n    def decrypt(self, token: str) -&gt; str:\n        \"\"\"Decrypt sensitive data when needed.\"\"\"\n        return fernet.decrypt(token.encode()).decode()\n\n    def audit(self, user_id: str, action: str, resource: str, metadata: Dict[str, Any] = None) -&gt; None:\n        \"\"\"Write an audit log entry for data actions, including the current run_id.\"\"\"\n        entry = {\n            \"timestamp\": time.time(),\n            \"run_id\": self.get_current_run_id(), \n            \"user_id\": user_id,\n            \"action\": action,\n            \"resource\": resource,\n            \"metadata\": metadata or {}\n        }\n        with open(self.audit_log_path, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n\n    def tag_lineage(self, record: Dict[str, Any], source: str) -&gt; Dict[str, Any]:\n        \"\"\"Attach lineage metadata to a record.\"\"\"\n        if \"_lineage\" not in record:\n            record[\"_lineage\"] = []\n        record[\"_lineage\"].append({\n            \"timestamp\": time.time(),\n            \"source\": source\n        })\n        return record\n\n    def purge_old_logs(self) -&gt; None:\n        \"\"\"Purge audit log entries older than retention period.\"\"\"\n        cutoff = time.time() - self.retention_days * 86400\n        retained = []\n        with open(self.audit_log_path, \"r\") as f:\n            for line in f:\n                try:\n                    entry = json.loads(line)\n                    if entry.get(\"timestamp\", 0) &gt;= cutoff:\n                        retained.append(line)\n                except json.JSONDecodeError:\n                    continue\n        with open(self.audit_log_path, \"w\") as f:\n            f.writelines(retained)\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.audit","title":"<code>audit(user_id, action, resource, metadata=None)</code>","text":"<p>Write an audit log entry for data actions, including the current run_id.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def audit(self, user_id: str, action: str, resource: str, metadata: Dict[str, Any] = None) -&gt; None:\n    \"\"\"Write an audit log entry for data actions, including the current run_id.\"\"\"\n    entry = {\n        \"timestamp\": time.time(),\n        \"run_id\": self.get_current_run_id(), \n        \"user_id\": user_id,\n        \"action\": action,\n        \"resource\": resource,\n        \"metadata\": metadata or {}\n    }\n    with open(self.audit_log_path, \"a\") as f:\n        f.write(json.dumps(entry) + \"\\n\")\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.decrypt","title":"<code>decrypt(token)</code>","text":"<p>Decrypt sensitive data when needed.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def decrypt(self, token: str) -&gt; str:\n    \"\"\"Decrypt sensitive data when needed.\"\"\"\n    return fernet.decrypt(token.encode()).decode()\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.encrypt","title":"<code>encrypt(plaintext)</code>","text":"<p>Encrypt sensitive data before storage.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def encrypt(self, plaintext: str) -&gt; str:\n    \"\"\"Encrypt sensitive data before storage.\"\"\"\n    return fernet.encrypt(plaintext.encode()).decode()\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.get_current_run_id","title":"<code>get_current_run_id()</code>","text":"<p>Returns the ID for the current run, creating one if it doesn't exist.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def get_current_run_id(self) -&gt; str:\n    \"\"\"Returns the ID for the current run, creating one if it doesn't exist.\"\"\"\n    if not self.current_run_id:\n        return self.start_new_run()\n    return self.current_run_id\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.purge_old_logs","title":"<code>purge_old_logs()</code>","text":"<p>Purge audit log entries older than retention period.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def purge_old_logs(self) -&gt; None:\n    \"\"\"Purge audit log entries older than retention period.\"\"\"\n    cutoff = time.time() - self.retention_days * 86400\n    retained = []\n    with open(self.audit_log_path, \"r\") as f:\n        for line in f:\n            try:\n                entry = json.loads(line)\n                if entry.get(\"timestamp\", 0) &gt;= cutoff:\n                    retained.append(line)\n            except json.JSONDecodeError:\n                continue\n    with open(self.audit_log_path, \"w\") as f:\n        f.writelines(retained)\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.start_new_run","title":"<code>start_new_run()</code>","text":"<p>Generates a new unique ID for a single, complete run of an orchestrator.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def start_new_run(self) -&gt; str:\n    \"\"\"Generates a new unique ID for a single, complete run of an orchestrator.\"\"\"\n    self.current_run_id = str(uuid.uuid4())\n    return self.current_run_id\n</code></pre>"},{"location":"reference/#safeagent.governance.GovernanceManager.tag_lineage","title":"<code>tag_lineage(record, source)</code>","text":"<p>Attach lineage metadata to a record.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def tag_lineage(self, record: Dict[str, Any], source: str) -&gt; Dict[str, Any]:\n    \"\"\"Attach lineage metadata to a record.\"\"\"\n    if \"_lineage\" not in record:\n        record[\"_lineage\"] = []\n    record[\"_lineage\"].append({\n        \"timestamp\": time.time(),\n        \"source\": source\n    })\n    return record\n</code></pre>"},{"location":"reference/#safeagentllm_client","title":"<code>safeagent.llm_client</code>","text":""},{"location":"reference/#safeagent.llm_client.FrameworkError","title":"<code>FrameworkError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for framework-related errors.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>class FrameworkError(Exception):\n    \"\"\"Custom exception for framework-related errors.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#safeagent.llm_client.LLMClient","title":"<code>LLMClient</code>","text":"<p>Thin wrapper around any LLM provider with retries, error handling, and structured JSON logging.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>class LLMClient:\n    \"\"\"Thin wrapper around any LLM provider with retries, error handling, and structured JSON logging.\"\"\"\n\n    def __init__(self, provider: str, api_key: str, model: str, base_url: str = None):\n        \"\"\"\n        Initialize the LLM client.\n\n        Args:\n            provider (str): Name of the provider (e.g., 'openai', 'anthropic').\n            api_key (str): API key or token for authentication.\n            model (str): Model identifier (e.g., 'gpt-4', 'claude-3-opus').\n            base_url (str, optional): Custom endpoint URL; defaults to provider-specific default.\n        \"\"\"\n        self.provider = provider\n        self.api_key = api_key\n        self.model = model\n        self.base_url = base_url or self._default_url()\n        if requests is not None:\n            self.session = requests.Session()\n        else:\n            class _DummySession:\n                def __init__(self):\n                    self.headers = {}\n\n                def post(self, *_, **__):\n                    raise FrameworkError(\"requests package is required for HTTP calls\")\n\n            self.session = _DummySession()\n        self.session.headers.update({\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        })\n        self.gov = GovernanceManager()\n\n    def _default_url(self) -&gt; str:\n        \"\"\"Return default endpoint URL based on provider.\"\"\"\n        if self.provider == \"openai\":\n            return \"https://api.openai.com/v1/chat/completions\"\n        if self.provider == \"anthropic\":\n            return \"https://api.anthropic.com/v1/complete\"\n        if self.provider == \"gemini\":\n            return f\"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}\"\n        raise FrameworkError(f\"No default URL configured for provider '{self.provider}'\")\n\n    def generate(self, prompt: str, max_tokens: int = 512, temperature: float = 0.7) -&gt; Dict:\n        \"\"\"\n        Call the underlying LLM API, with up to 3 retries.\n\n        Args:\n            prompt (str): The textual prompt to send to the model.\n            max_tokens (int): Maximum number of tokens in the response.\n            temperature (float): Sampling temperature.\n\n        Returns:\n            Dict: A dictionary containing keys 'text', 'usage', and 'metadata'.\n\n        Raises:\n            FrameworkError: If the API fails after retries.\n        \"\"\"\n        # Encrypt the prompt before logging\n        encrypted_prompt = self.gov.encrypt(prompt)\n        self.gov.audit(user_id=\"system\", action=\"encrypt_prompt\", resource=\"llm_client\", metadata={\"prompt_enc\": encrypted_prompt[:50]})\n        payload = self._build_payload(prompt, max_tokens, temperature)\n\n        # Log start of LLM call and audit\n        req_id = get_request_id()\n        log_entry_start = {\n            \"event\": \"llm_call_start\",\n            \"provider\": self.provider,\n            \"model\": self.model,\n            \"prompt_snippet\": prompt[:100],\n            \"request_id\": req_id,\n            \"timestamp\": time.time(),\n        }\n        logging.info(json.dumps(log_entry_start))\n        self.gov.audit(\n            user_id=\"system\",\n            action=\"llm_call_start\",\n            resource=self.provider,\n            metadata={\"model\": self.model, \"request_id\": req_id},\n        )\n\n        # Attempt with exponential backoff\n        for attempt in range(3):\n            try:\n                resp = self.session.post(self.base_url, json=payload, timeout=30)\n                if resp.status_code != 200:\n                    raise FrameworkError(f\"LLM returned status {resp.status_code}: {resp.text}\")\n                data = resp.json()\n                text, usage = self._parse_response(data)\n\n                # Log end of LLM call and audit\n                log_entry_end = {\n                    \"event\": \"llm_call_end\",\n                    \"provider\": self.provider,\n                    \"model\": self.model,\n                    \"usage\": usage,\n                    \"request_id\": req_id,\n                    \"timestamp\": time.time(),\n                }\n                logging.info(json.dumps(log_entry_end))\n                self.gov.audit(\n                    user_id=\"system\",\n                    action=\"llm_call_end\",\n                    resource=self.provider,\n                    metadata={\"model\": self.model, \"usage\": usage, \"request_id\": req_id},\n                )\n\n                return {\"text\": text, \"usage\": usage, \"metadata\": {\"provider\": self.provider, \"model\": self.model}}\n\n            except Exception as e:\n                wait = 2 ** attempt\n                logging.warning(f\"LLM call failed (attempt {attempt + 1}): {e}. Retrying in {wait}s\")\n                time.sleep(wait)\n\n        raise FrameworkError(\"LLM generate() failed after 3 attempts\")\n\n    def _build_payload(self, prompt: str, max_tokens: int, temperature: float) -&gt; Dict:\n        \"\"\"Construct provider-specific payload for the API call.\"\"\"\n        if self.provider == \"openai\":\n            return {\n                \"model\": self.model,\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                \"max_tokens\": max_tokens,\n                \"temperature\": temperature\n            }\n        if self.provider == \"anthropic\":\n            return {\n                \"model\": self.model,\n                \"prompt\": prompt,\n                \"max_tokens_to_sample\": max_tokens,\n                \"temperature\": temperature\n            }\n        if self.provider == \"gemini\":\n            return {\n                \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n                \"generationConfig\": {\"maxOutputTokens\": max_tokens, \"temperature\": temperature}\n            }\n        raise FrameworkError(f\"Payload builder not implemented for '{self.provider}'\")\n\n    def _parse_response(self, data: Dict) -&gt; (str, Dict):\n        \"\"\"Extract generated text and usage info from API response.\"\"\"\n        if self.provider == \"openai\":\n            choice = data.get(\"choices\", [])[0]\n            return choice.get(\"message\", {}).get(\"content\", \"\"), data.get(\"usage\", {})\n        if self.provider == \"anthropic\":\n            return data.get(\"completion\", \"\"), {\n                \"prompt_tokens\": data.get(\"prompt_tokens\"),\n                \"completion_tokens\": data.get(\"completion_tokens\")\n            }\n        if self.provider == \"gemini\":\n            text = (\n                data.get(\"candidates\", [{}])[0]\n                .get(\"content\", {})\n                .get(\"parts\", [{}])[0]\n                .get(\"text\", \"\")\n            )\n            usage = data.get(\"usageMetadata\", {})\n            return text, {\n                \"prompt_tokens\": usage.get(\"promptTokenCount\"),\n                \"completion_tokens\": usage.get(\"candidatesTokenCount\"),\n            }\n        raise FrameworkError(f\"Response parser not implemented for '{self.provider}'\")\n</code></pre>"},{"location":"reference/#safeagent.llm_client.LLMClient.__init__","title":"<code>__init__(provider, api_key, model, base_url=None)</code>","text":"<p>Initialize the LLM client.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>Name of the provider (e.g., 'openai', 'anthropic').</p> required <code>api_key</code> <code>str</code> <p>API key or token for authentication.</p> required <code>model</code> <code>str</code> <p>Model identifier (e.g., 'gpt-4', 'claude-3-opus').</p> required <code>base_url</code> <code>str</code> <p>Custom endpoint URL; defaults to provider-specific default.</p> <code>None</code> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>def __init__(self, provider: str, api_key: str, model: str, base_url: str = None):\n    \"\"\"\n    Initialize the LLM client.\n\n    Args:\n        provider (str): Name of the provider (e.g., 'openai', 'anthropic').\n        api_key (str): API key or token for authentication.\n        model (str): Model identifier (e.g., 'gpt-4', 'claude-3-opus').\n        base_url (str, optional): Custom endpoint URL; defaults to provider-specific default.\n    \"\"\"\n    self.provider = provider\n    self.api_key = api_key\n    self.model = model\n    self.base_url = base_url or self._default_url()\n    if requests is not None:\n        self.session = requests.Session()\n    else:\n        class _DummySession:\n            def __init__(self):\n                self.headers = {}\n\n            def post(self, *_, **__):\n                raise FrameworkError(\"requests package is required for HTTP calls\")\n\n        self.session = _DummySession()\n    self.session.headers.update({\n        \"Authorization\": f\"Bearer {self.api_key}\",\n        \"Content-Type\": \"application/json\"\n    })\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"reference/#safeagent.llm_client.LLMClient.generate","title":"<code>generate(prompt, max_tokens=512, temperature=0.7)</code>","text":"<p>Call the underlying LLM API, with up to 3 retries.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The textual prompt to send to the model.</p> required <code>max_tokens</code> <code>int</code> <p>Maximum number of tokens in the response.</p> <code>512</code> <code>temperature</code> <code>float</code> <p>Sampling temperature.</p> <code>0.7</code> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing keys 'text', 'usage', and 'metadata'.</p> <p>Raises:</p> Type Description <code>FrameworkError</code> <p>If the API fails after retries.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>def generate(self, prompt: str, max_tokens: int = 512, temperature: float = 0.7) -&gt; Dict:\n    \"\"\"\n    Call the underlying LLM API, with up to 3 retries.\n\n    Args:\n        prompt (str): The textual prompt to send to the model.\n        max_tokens (int): Maximum number of tokens in the response.\n        temperature (float): Sampling temperature.\n\n    Returns:\n        Dict: A dictionary containing keys 'text', 'usage', and 'metadata'.\n\n    Raises:\n        FrameworkError: If the API fails after retries.\n    \"\"\"\n    # Encrypt the prompt before logging\n    encrypted_prompt = self.gov.encrypt(prompt)\n    self.gov.audit(user_id=\"system\", action=\"encrypt_prompt\", resource=\"llm_client\", metadata={\"prompt_enc\": encrypted_prompt[:50]})\n    payload = self._build_payload(prompt, max_tokens, temperature)\n\n    # Log start of LLM call and audit\n    req_id = get_request_id()\n    log_entry_start = {\n        \"event\": \"llm_call_start\",\n        \"provider\": self.provider,\n        \"model\": self.model,\n        \"prompt_snippet\": prompt[:100],\n        \"request_id\": req_id,\n        \"timestamp\": time.time(),\n    }\n    logging.info(json.dumps(log_entry_start))\n    self.gov.audit(\n        user_id=\"system\",\n        action=\"llm_call_start\",\n        resource=self.provider,\n        metadata={\"model\": self.model, \"request_id\": req_id},\n    )\n\n    # Attempt with exponential backoff\n    for attempt in range(3):\n        try:\n            resp = self.session.post(self.base_url, json=payload, timeout=30)\n            if resp.status_code != 200:\n                raise FrameworkError(f\"LLM returned status {resp.status_code}: {resp.text}\")\n            data = resp.json()\n            text, usage = self._parse_response(data)\n\n            # Log end of LLM call and audit\n            log_entry_end = {\n                \"event\": \"llm_call_end\",\n                \"provider\": self.provider,\n                \"model\": self.model,\n                \"usage\": usage,\n                \"request_id\": req_id,\n                \"timestamp\": time.time(),\n            }\n            logging.info(json.dumps(log_entry_end))\n            self.gov.audit(\n                user_id=\"system\",\n                action=\"llm_call_end\",\n                resource=self.provider,\n                metadata={\"model\": self.model, \"usage\": usage, \"request_id\": req_id},\n            )\n\n            return {\"text\": text, \"usage\": usage, \"metadata\": {\"provider\": self.provider, \"model\": self.model}}\n\n        except Exception as e:\n            wait = 2 ** attempt\n            logging.warning(f\"LLM call failed (attempt {attempt + 1}): {e}. Retrying in {wait}s\")\n            time.sleep(wait)\n\n    raise FrameworkError(\"LLM generate() failed after 3 attempts\")\n</code></pre>"},{"location":"reference/#safeagentmemory_manager","title":"<code>safeagent.memory_manager</code>","text":""},{"location":"reference/#safeagent.memory_manager.MemoryManager","title":"<code>MemoryManager</code>","text":"<p>Minimal key-value memory store. Supports 'inmemory' or 'redis' backends and logs each read/write. Optionally, can summarize entire memory via an LLM.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>class MemoryManager:\n    \"\"\"\n    Minimal key-value memory store.\n    Supports 'inmemory' or 'redis' backends and logs each read/write.\n    Optionally, can summarize entire memory via an LLM.\n    \"\"\"\n\n    def __init__(self, backend: str = \"inmemory\", redis_url: str = None):\n        \"\"\"\n        backend: \"inmemory\" (default) or \"redis\".\n        redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".\n        \"\"\"\n        global _redis\n        if backend == \"redis\":\n            if _redis is None:\n                import redis as _redis\n            self.client = _redis.from_url(redis_url)\n            self.backend = \"redis\"\n        else:\n            self.store = {}  # {user_id: {key: value}}\n            self.backend = \"inmemory\"\n\n    def save(self, user_id: str, key: str, value: str) -&gt; None:\n        \"\"\"Saves value under (user_id, key).\"\"\"\n        if self.backend == \"redis\":\n            self.client.hset(user_id, key, value)\n        else:\n            self.store.setdefault(user_id, {})[key] = value\n\n        logging.info(json.dumps({\n            \"event\": \"memory_save\",\n            \"user_id\": user_id,\n            \"key\": key,\n            \"request_id\": get_request_id(),\n            \"timestamp\": time.time(),\n        }))\n\n    def load(self, user_id: str, key: str) -&gt; str:\n        \"\"\"Loads value for (user_id, key). Returns empty string if missing.\"\"\"\n        if self.backend == \"redis\":\n            raw = self.client.hget(user_id, key)\n            if isinstance(raw, bytes):\n                value = raw.decode(\"utf-8\")\n            elif raw is None:\n                value = \"\"\n            else:\n                value = str(raw)\n        else:\n            value = self.store.get(user_id, {}).get(key, \"\")\n\n        logging.info(json.dumps({\n            \"event\": \"memory_load\",\n            \"user_id\": user_id,\n            \"key\": key,\n            \"request_id\": get_request_id(),\n            \"timestamp\": time.time(),\n        }))\n        return value\n\n    def summarize(self, user_id: str, embed_fn, llm_client, max_tokens: int = 256) -&gt; str:\n        \"\"\"\n        Reads all entries for user_id, concatenates them, and calls LLM to generate a summary.\n        Stores the summary under key=\"summary\" and returns it.\n        \"\"\"\n        if self.backend == \"redis\":\n            all_vals = [v.decode(\"utf-8\") for v in self.client.hvals(user_id)]\n        else:\n            all_vals = list(self.store.get(user_id, {}).values())\n\n        full_text = \"\\n\".join(all_vals)\n        if not full_text:\n            return \"\"\n\n        summary_prompt = f\"Summarize the following conversation history:\\n\\n{full_text}\"\n        resp = llm_client.generate(summary_prompt, max_tokens=max_tokens)\n        summary = resp[\"text\"]\n\n        # Save summary back to memory\n        self.save(user_id, \"summary\", summary)\n        return summary\n</code></pre>"},{"location":"reference/#safeagent.memory_manager.MemoryManager.__init__","title":"<code>__init__(backend='inmemory', redis_url=None)</code>","text":"<p>backend: \"inmemory\" (default) or \"redis\". redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def __init__(self, backend: str = \"inmemory\", redis_url: str = None):\n    \"\"\"\n    backend: \"inmemory\" (default) or \"redis\".\n    redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".\n    \"\"\"\n    global _redis\n    if backend == \"redis\":\n        if _redis is None:\n            import redis as _redis\n        self.client = _redis.from_url(redis_url)\n        self.backend = \"redis\"\n    else:\n        self.store = {}  # {user_id: {key: value}}\n        self.backend = \"inmemory\"\n</code></pre>"},{"location":"reference/#safeagent.memory_manager.MemoryManager.load","title":"<code>load(user_id, key)</code>","text":"<p>Loads value for (user_id, key). Returns empty string if missing.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def load(self, user_id: str, key: str) -&gt; str:\n    \"\"\"Loads value for (user_id, key). Returns empty string if missing.\"\"\"\n    if self.backend == \"redis\":\n        raw = self.client.hget(user_id, key)\n        if isinstance(raw, bytes):\n            value = raw.decode(\"utf-8\")\n        elif raw is None:\n            value = \"\"\n        else:\n            value = str(raw)\n    else:\n        value = self.store.get(user_id, {}).get(key, \"\")\n\n    logging.info(json.dumps({\n        \"event\": \"memory_load\",\n        \"user_id\": user_id,\n        \"key\": key,\n        \"request_id\": get_request_id(),\n        \"timestamp\": time.time(),\n    }))\n    return value\n</code></pre>"},{"location":"reference/#safeagent.memory_manager.MemoryManager.save","title":"<code>save(user_id, key, value)</code>","text":"<p>Saves value under (user_id, key).</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def save(self, user_id: str, key: str, value: str) -&gt; None:\n    \"\"\"Saves value under (user_id, key).\"\"\"\n    if self.backend == \"redis\":\n        self.client.hset(user_id, key, value)\n    else:\n        self.store.setdefault(user_id, {})[key] = value\n\n    logging.info(json.dumps({\n        \"event\": \"memory_save\",\n        \"user_id\": user_id,\n        \"key\": key,\n        \"request_id\": get_request_id(),\n        \"timestamp\": time.time(),\n    }))\n</code></pre>"},{"location":"reference/#safeagent.memory_manager.MemoryManager.summarize","title":"<code>summarize(user_id, embed_fn, llm_client, max_tokens=256)</code>","text":"<p>Reads all entries for user_id, concatenates them, and calls LLM to generate a summary. Stores the summary under key=\"summary\" and returns it.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def summarize(self, user_id: str, embed_fn, llm_client, max_tokens: int = 256) -&gt; str:\n    \"\"\"\n    Reads all entries for user_id, concatenates them, and calls LLM to generate a summary.\n    Stores the summary under key=\"summary\" and returns it.\n    \"\"\"\n    if self.backend == \"redis\":\n        all_vals = [v.decode(\"utf-8\") for v in self.client.hvals(user_id)]\n    else:\n        all_vals = list(self.store.get(user_id, {}).values())\n\n    full_text = \"\\n\".join(all_vals)\n    if not full_text:\n        return \"\"\n\n    summary_prompt = f\"Summarize the following conversation history:\\n\\n{full_text}\"\n    resp = llm_client.generate(summary_prompt, max_tokens=max_tokens)\n    summary = resp[\"text\"]\n\n    # Save summary back to memory\n    self.save(user_id, \"summary\", summary)\n    return summary\n</code></pre>"},{"location":"reference/#safeagentprompt_renderer","title":"<code>safeagent.prompt_renderer</code>","text":""},{"location":"reference/#safeagent.prompt_renderer.PromptRenderer","title":"<code>PromptRenderer</code>","text":"<p>Jinja2-based templating engine with structured logging and lineage tagging.</p> Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>class PromptRenderer:\n    \"\"\"Jinja2-based templating engine with structured logging and lineage tagging.\"\"\"\n\n    def __init__(self, template_dir: Path):\n        \"\"\"\n        Args:\n            template_dir (Path): Path to the directory containing Jinja2 templates.\n        \"\"\"\n        self.env = jinja2.Environment(\n            loader=jinja2.FileSystemLoader(str(template_dir)),\n            autoescape=False\n        )\n        self.gov = GovernanceManager()\n\n    def render(self, template_name: str, **context) -&gt; str:\n        \"\"\"\n        Render a Jinja2 template with provided context, logging the event and tagging lineage.\n\n        Args:\n            template_name (str): Filename of the template (e.g., 'qa_prompt.j2').\n            **context: Key-value pairs to pass into the template rendering.\n\n        Returns:\n            str: The rendered template as a string.\n        \"\"\"\n        # Audit prompt render\n        lineage_metadata = {\"template\": template_name, \"context_keys\": list(context.keys())}\n        self.gov.audit(user_id=\"system\", action=\"prompt_render\", resource=template_name, metadata=lineage_metadata)\n\n        template = self.env.get_template(template_name)\n        rendered = template.render(**context)\n        log_entry = {\n            \"event\": \"prompt_render\",\n            \"template\": template_name,\n            \"context_keys\": list(context.keys()),\n            \"output_length\": len(rendered),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return rendered\n</code></pre>"},{"location":"reference/#safeagent.prompt_renderer.PromptRenderer.__init__","title":"<code>__init__(template_dir)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>template_dir</code> <code>Path</code> <p>Path to the directory containing Jinja2 templates.</p> required Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>def __init__(self, template_dir: Path):\n    \"\"\"\n    Args:\n        template_dir (Path): Path to the directory containing Jinja2 templates.\n    \"\"\"\n    self.env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(str(template_dir)),\n        autoescape=False\n    )\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"reference/#safeagent.prompt_renderer.PromptRenderer.render","title":"<code>render(template_name, **context)</code>","text":"<p>Render a Jinja2 template with provided context, logging the event and tagging lineage.</p> <p>Parameters:</p> Name Type Description Default <code>template_name</code> <code>str</code> <p>Filename of the template (e.g., 'qa_prompt.j2').</p> required <code>**context</code> <p>Key-value pairs to pass into the template rendering.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The rendered template as a string.</p> Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>def render(self, template_name: str, **context) -&gt; str:\n    \"\"\"\n    Render a Jinja2 template with provided context, logging the event and tagging lineage.\n\n    Args:\n        template_name (str): Filename of the template (e.g., 'qa_prompt.j2').\n        **context: Key-value pairs to pass into the template rendering.\n\n    Returns:\n        str: The rendered template as a string.\n    \"\"\"\n    # Audit prompt render\n    lineage_metadata = {\"template\": template_name, \"context_keys\": list(context.keys())}\n    self.gov.audit(user_id=\"system\", action=\"prompt_render\", resource=template_name, metadata=lineage_metadata)\n\n    template = self.env.get_template(template_name)\n    rendered = template.render(**context)\n    log_entry = {\n        \"event\": \"prompt_render\",\n        \"template\": template_name,\n        \"context_keys\": list(context.keys()),\n        \"output_length\": len(rendered),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return rendered\n</code></pre>"},{"location":"reference/#safeagentembeddings","title":"<code>safeagent.embeddings</code>","text":""},{"location":"reference/#safeagent.embeddings.gemini_embed","title":"<code>gemini_embed(text, api_key, model='embedding-001')</code>","text":"<p>Return an embedding vector from the Gemini embedding API.</p> Source code in <code>src\\safeagent\\embeddings.py</code> <pre><code>def gemini_embed(text: str, api_key: str, model: str = \"embedding-001\") -&gt; List[float]:\n    \"\"\"Return an embedding vector from the Gemini embedding API.\"\"\"\n    url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:embedContent?key={api_key}\"\n    payload = {\"content\": {\"parts\": [{\"text\": text}]}}\n    resp = _session.post(url, json=payload, timeout=30)\n    if resp.status_code != 200:\n        raise RuntimeError(f\"Gemini embed failed: {resp.text}\")\n    data = resp.json()\n    return data.get(\"embedding\", {}).get(\"values\", [])\n</code></pre>"},{"location":"reference/#orchestrators","title":"Orchestrators","text":""},{"location":"reference/#safeagentorchestrator","title":"<code>safeagent.orchestrator</code>","text":""},{"location":"reference/#safeagent.orchestrator.SimpleOrchestrator","title":"<code>SimpleOrchestrator</code>","text":"<p>Minimal DAG runner: each node is a function, edges define dependencies, with audit and lineage tagging.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>class SimpleOrchestrator:\n    \"\"\"Minimal DAG runner: each node is a function, edges define dependencies, with audit and lineage tagging.\"\"\"\n\n    def __init__(self):\n        # Map node name to function\n        self.nodes: Dict[str, Callable[..., Any]] = {}\n        # Map node name to list of dependent node names\n        self.edges: Dict[str, List[str]] = {}\n        self.gov = GovernanceManager()\n\n    def add_node(self, name: str, func: Callable[..., Any]):\n        \"\"\"Register a function under the given node name.\"\"\"\n        self.nodes[name] = func\n        self.edges.setdefault(name, [])\n\n    def add_edge(self, src: str, dest: str):\n        \"\"\"Specify that 'dest' depends on 'src'.\"\"\"\n        if src not in self.nodes or dest not in self.nodes:\n            raise ValueError(f\"Either '{src}' or '{dest}' is not registered as a node.\")\n        self.edges[src].append(dest)\n\n    def run(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.\n\n        Args:\n            inputs (Dict[str, Any]): Global inputs (e.g., 'user_input', 'user_id').\n\n        Returns:\n            Dict[str, Any]: Mapping of node name to its return value.\n        \"\"\"\n        results: Dict[str, Any] = {}\n        visited = set()\n\n        # Audit pipeline start\n        self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_start\", resource=\"orchestrator\")\n\n        def execute(node: str):\n            if node in visited:\n                return results.get(node)\n            visited.add(node)\n            func = self.nodes[node]\n            kwargs = {}\n            import inspect\n            params = inspect.signature(func).parameters\n            for name in params:\n                if name in results:\n                    kwargs[name] = results[name]\n                elif name.startswith(\"node_\") and name[5:] in results:\n                    kwargs[name] = results[name[5:]]\n                elif name in inputs:\n                    kwargs[name] = inputs[name]\n            output = func(**kwargs)\n            # Tag lineage on dict outputs\n            if isinstance(output, dict):\n                output = self.gov.tag_lineage(output, source=node)\n            results[node] = output\n            return output\n\n        for node in self.nodes:\n            execute(node)\n\n        # Audit pipeline end\n        self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_end\", resource=\"orchestrator\")\n\n        return results\n</code></pre>"},{"location":"reference/#safeagent.orchestrator.SimpleOrchestrator.add_edge","title":"<code>add_edge(src, dest)</code>","text":"<p>Specify that 'dest' depends on 'src'.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def add_edge(self, src: str, dest: str):\n    \"\"\"Specify that 'dest' depends on 'src'.\"\"\"\n    if src not in self.nodes or dest not in self.nodes:\n        raise ValueError(f\"Either '{src}' or '{dest}' is not registered as a node.\")\n    self.edges[src].append(dest)\n</code></pre>"},{"location":"reference/#safeagent.orchestrator.SimpleOrchestrator.add_node","title":"<code>add_node(name, func)</code>","text":"<p>Register a function under the given node name.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def add_node(self, name: str, func: Callable[..., Any]):\n    \"\"\"Register a function under the given node name.\"\"\"\n    self.nodes[name] = func\n    self.edges.setdefault(name, [])\n</code></pre>"},{"location":"reference/#safeagent.orchestrator.SimpleOrchestrator.run","title":"<code>run(inputs)</code>","text":"<p>Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Dict[str, Any]</code> <p>Global inputs (e.g., 'user_input', 'user_id').</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Mapping of node name to its return value.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def run(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.\n\n    Args:\n        inputs (Dict[str, Any]): Global inputs (e.g., 'user_input', 'user_id').\n\n    Returns:\n        Dict[str, Any]: Mapping of node name to its return value.\n    \"\"\"\n    results: Dict[str, Any] = {}\n    visited = set()\n\n    # Audit pipeline start\n    self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_start\", resource=\"orchestrator\")\n\n    def execute(node: str):\n        if node in visited:\n            return results.get(node)\n        visited.add(node)\n        func = self.nodes[node]\n        kwargs = {}\n        import inspect\n        params = inspect.signature(func).parameters\n        for name in params:\n            if name in results:\n                kwargs[name] = results[name]\n            elif name.startswith(\"node_\") and name[5:] in results:\n                kwargs[name] = results[name[5:]]\n            elif name in inputs:\n                kwargs[name] = inputs[name]\n        output = func(**kwargs)\n        # Tag lineage on dict outputs\n        if isinstance(output, dict):\n            output = self.gov.tag_lineage(output, source=node)\n        results[node] = output\n        return output\n\n    for node in self.nodes:\n        execute(node)\n\n    # Audit pipeline end\n    self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_end\", resource=\"orchestrator\")\n\n    return results\n</code></pre>"},{"location":"reference/#safeagentstateful_orchestrator","title":"<code>safeagent.stateful_orchestrator</code>","text":""},{"location":"reference/#safeagent.stateful_orchestrator.EdgeRegistrationError","title":"<code>EdgeRegistrationError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised during an invalid attempt to register an edge.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class EdgeRegistrationError(OrchestratorError):\n    \"\"\"Raised during an invalid attempt to register an edge.\"\"\"\n    def __init__(self, node_name: str, message: str):\n        self.node_name = node_name\n        super().__init__(\"{}: '{}'\".format(message, node_name))\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.NodeNotFoundError","title":"<code>NodeNotFoundError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when a node name is not found in the graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class NodeNotFoundError(OrchestratorError):\n    \"\"\"Raised when a node name is not found in the graph.\"\"\"\n    def __init__(self, node_name: str):\n        self.node_name = node_name\n        super().__init__(\"Node '{}' not found in the graph.\".format(node_name))\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.OrchestratorError","title":"<code>OrchestratorError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all stateful orchestrator errors.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class OrchestratorError(Exception):\n    \"\"\"Base exception for all stateful orchestrator errors.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.StateValidationError","title":"<code>StateValidationError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when the state does not conform to the defined schema.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class StateValidationError(OrchestratorError):\n    \"\"\"Raised when the state does not conform to the defined schema.\"\"\"\n    def __init__(self, message: str):\n        super().__init__(message)\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.StatefulOrchestrator","title":"<code>StatefulOrchestrator</code>","text":"<p>An orchestrator that manages a central state object, allowing for complex, cyclical, and conditional workflows with integrated governance, human-in-the-loop interrupts, and optional state schema validation.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class StatefulOrchestrator:\n    \"\"\"\n    An orchestrator that manages a central state object, allowing for complex,\n    cyclical, and conditional workflows with integrated governance, human-in-the-loop\n    interrupts, and optional state schema validation.\n    \"\"\"\n\n    def __init__(self, entry_node: str, state_schema: Optional[Dict[str, Type]] = None):\n        \"\"\"\n        Initializes the stateful orchestrator.\n\n        Args:\n            entry_node (str): The name of the first node to execute in the graph.\n            state_schema (Optional[Dict[str, Type]]): An optional schema defining\n                expected keys and their Python types in the state object.\n        \"\"\"\n        if not isinstance(entry_node, str) or not entry_node:\n            raise ValueError(\"entry_node must be a non-empty string.\")\n\n        self.nodes: Dict[str, Callable[[Dict], Dict]] = {}\n        self.edges: Dict[str, Callable[[Dict], str]] = {}\n        self.entry_node = entry_node\n        self.state_schema = state_schema\n        self.gov = GovernanceManager()\n\n    def add_node(self, name: str, func: Callable[[Dict], Dict]):\n        self.nodes[name] = func\n\n    def add_edge(self, src: str, dest: str):\n        if src not in self.nodes:\n            raise EdgeRegistrationError(src, \"Source node for edge is not registered\")\n        if dest not in self.nodes and dest not in (\"__end__\", \"__interrupt__\"):\n             raise EdgeRegistrationError(dest, \"Destination node for edge is not registered\")\n        self.edges[src] = lambda state: dest\n\n    def add_conditional_edge(self, src: str, path_func: Callable[[Dict], str]):\n        if src not in self.nodes:\n            raise EdgeRegistrationError(src, \"Source node for conditional edge is not registered\")\n        self.edges[src] = path_func\n\n    def _validate_state(self, state: Dict[str, Any], keys_to_check: List[str]):\n        \"\"\"Validates a subset of the state against the schema if it exists.\"\"\"\n        if not self.state_schema:\n            return\n\n        for key in keys_to_check:\n            if key not in self.state_schema:\n                raise StateValidationError(\"Key '{}' in state is not defined in the schema.\".format(key))\n            if key in state and not isinstance(state[key], self.state_schema[key]):\n                expected_type = self.state_schema[key].__name__\n                actual_type = type(state[key]).__name__\n                msg = \"Type mismatch for key '{}'. Expected '{}', got '{}'.\".format(key, expected_type, actual_type)\n                raise StateValidationError(msg)\n\n    def run(self, inputs: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Executes the graph starting from the entry node.\n\n        Returns:\n            A tuple containing the final status ('completed', 'paused', 'error')\n            and the final state of the graph.\n        \"\"\"\n        state = inputs.copy()\n        self._validate_state(state, list(state.keys()))\n        self.gov.audit(user_id, \"stateful_run_start\", \"StatefulOrchestrator\", {\"initial_keys\": list(state.keys())})\n\n        return self._execute_from(self.entry_node, state, user_id, max_steps)\n\n    def resume(self, state: Dict[str, Any], human_input: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Resumes execution of a paused graph.\n        \"\"\"\n        if \"__next_node__\" not in state:\n            raise OrchestratorError(\"Cannot resume. The provided state is not a valid paused state.\")\n\n        next_node = state.pop(\"__next_node__\")\n        state.update(human_input)\n\n        self.gov.audit(user_id, \"graph_resume\", \"StatefulOrchestrator\", {\"resuming_at_node\": next_node, \"human_input_keys\": list(human_input.keys())})\n        self._validate_state(state, list(human_input.keys()))\n\n        return self._execute_from(next_node, state, user_id, max_steps, start_step=state.get('__step__', 0))\n\n    def _execute_from(self, start_node: str, state: Dict[str, Any], user_id: str, max_steps: int, start_step: int = 0) -&gt; Tuple[str, Dict[str, Any]]:\n        current_node_name = start_node\n\n        for step in range(start_step, max_steps):\n            if current_node_name == \"__end__\":\n                self.gov.audit(user_id, \"graph_end_reached\", \"StatefulOrchestrator\", {\"step\": step})\n                return \"completed\", state\n\n            if current_node_name == \"__interrupt__\":\n                self.gov.audit(user_id, \"graph_interrupt_human_input\", \"StatefulOrchestrator\", {\"step\": step})\n                if state['__previous_node__'] in self.edges:\n                    state[\"__next_node__\"] = self.edges[state['__previous_node__']](state)\n                    state[\"__step__\"] = step\n                return \"paused\", state\n\n            if current_node_name not in self.nodes:\n                raise NodeNotFoundError(current_node_name)\n\n            self.gov.audit(user_id, \"node_start\", current_node_name, {\"step\": step})\n            node_func = self.nodes[current_node_name]\n\n            try:\n                updates = node_func(state)\n                self._validate_state(updates, list(updates.keys()))\n\n                for key, value in updates.items():\n                    record_to_tag = value if isinstance(value, dict) else {'value': value}\n                    tagged_record = self.gov.tag_lineage(record_to_tag, source=current_node_name)\n                    state[key] = tagged_record.get('value', tagged_record)\n\n                self.gov.audit(user_id, \"node_end\", current_node_name, {\"step\": step, \"updated_keys\": list(updates.keys())})\n            except Exception as e:\n                self.gov.audit(user_id, \"node_error\", current_node_name, {\"step\": step, \"error\": str(e)})\n                raise\n\n            if current_node_name not in self.edges:\n                self.gov.audit(user_id, \"graph_path_end\", \"StatefulOrchestrator\", {\"last_node\": current_node_name})\n                return \"completed\", state\n\n            path_func = self.edges[current_node_name]\n            state[\"__previous_node__\"] = current_node_name\n            next_node_name = path_func(state)\n\n            self.gov.audit(user_id, \"conditional_edge_traversed\", current_node_name, {\"destination\": next_node_name})\n            current_node_name = next_node_name\n        else:\n             self.gov.audit(user_id, \"max_steps_reached\", \"StatefulOrchestrator\", {\"max_steps\": max_steps})\n             return \"max_steps_reached\", state\n\n        return \"completed\", state\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.StatefulOrchestrator.__init__","title":"<code>__init__(entry_node, state_schema=None)</code>","text":"<p>Initializes the stateful orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>entry_node</code> <code>str</code> <p>The name of the first node to execute in the graph.</p> required <code>state_schema</code> <code>Optional[Dict[str, Type]]</code> <p>An optional schema defining expected keys and their Python types in the state object.</p> <code>None</code> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def __init__(self, entry_node: str, state_schema: Optional[Dict[str, Type]] = None):\n    \"\"\"\n    Initializes the stateful orchestrator.\n\n    Args:\n        entry_node (str): The name of the first node to execute in the graph.\n        state_schema (Optional[Dict[str, Type]]): An optional schema defining\n            expected keys and their Python types in the state object.\n    \"\"\"\n    if not isinstance(entry_node, str) or not entry_node:\n        raise ValueError(\"entry_node must be a non-empty string.\")\n\n    self.nodes: Dict[str, Callable[[Dict], Dict]] = {}\n    self.edges: Dict[str, Callable[[Dict], str]] = {}\n    self.entry_node = entry_node\n    self.state_schema = state_schema\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.StatefulOrchestrator.resume","title":"<code>resume(state, human_input, user_id='system', max_steps=15)</code>","text":"<p>Resumes execution of a paused graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def resume(self, state: Dict[str, Any], human_input: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Resumes execution of a paused graph.\n    \"\"\"\n    if \"__next_node__\" not in state:\n        raise OrchestratorError(\"Cannot resume. The provided state is not a valid paused state.\")\n\n    next_node = state.pop(\"__next_node__\")\n    state.update(human_input)\n\n    self.gov.audit(user_id, \"graph_resume\", \"StatefulOrchestrator\", {\"resuming_at_node\": next_node, \"human_input_keys\": list(human_input.keys())})\n    self._validate_state(state, list(human_input.keys()))\n\n    return self._execute_from(next_node, state, user_id, max_steps, start_step=state.get('__step__', 0))\n</code></pre>"},{"location":"reference/#safeagent.stateful_orchestrator.StatefulOrchestrator.run","title":"<code>run(inputs, user_id='system', max_steps=15)</code>","text":"<p>Executes the graph starting from the entry node.</p> <p>Returns:</p> Type Description <code>str</code> <p>A tuple containing the final status ('completed', 'paused', 'error')</p> <code>Dict[str, Any]</code> <p>and the final state of the graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def run(self, inputs: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Executes the graph starting from the entry node.\n\n    Returns:\n        A tuple containing the final status ('completed', 'paused', 'error')\n        and the final state of the graph.\n    \"\"\"\n    state = inputs.copy()\n    self._validate_state(state, list(state.keys()))\n    self.gov.audit(user_id, \"stateful_run_start\", \"StatefulOrchestrator\", {\"initial_keys\": list(state.keys())})\n\n    return self._execute_from(self.entry_node, state, user_id, max_steps)\n</code></pre>"},{"location":"reference/#tooling","title":"Tooling","text":""},{"location":"reference/#safeagenttool_registry","title":"<code>safeagent.tool_registry</code>","text":""},{"location":"reference/#safeagent.tool_registry.SimilarityMetric","title":"<code>SimilarityMetric</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Specifies the similarity metric for vector search.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class SimilarityMetric(Enum):\n    \"\"\"Specifies the similarity metric for vector search.\"\"\"\n    L2 = \"l2\"\n    COSINE = \"cosine\"\n    DOT_PRODUCT = \"dot_product\"\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolExecutionError","title":"<code>ToolExecutionError</code>","text":"<p>               Bases: <code>ToolRegistryError</code></p> <p>Raised when a tool fails to execute after all retries.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolExecutionError(ToolRegistryError):\n    \"\"\"Raised when a tool fails to execute after all retries.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolNotFoundError","title":"<code>ToolNotFoundError</code>","text":"<p>               Bases: <code>ToolRegistryError</code></p> <p>Raised when a tool is not found in the registry.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolNotFoundError(ToolRegistryError):\n    \"\"\"Raised when a tool is not found in the registry.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistry","title":"<code>ToolRegistry</code>","text":"<p>A central, governed registry for tools that includes RBAC, automatic retries, circuit breakers, cost/latency tracking, caching, async support, output sinks, and dynamic schemas.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolRegistry:\n    \"\"\"\n    A central, governed registry for tools that includes RBAC, automatic retries,\n    circuit breakers, cost/latency tracking, caching, async support, output sinks,\n    and dynamic schemas.\n    \"\"\"\n    def __init__(\n        self,\n        governance_manager: GovernanceManager,\n        embedding_config: Optional[Dict] = None,\n        similarity_metric: SimilarityMetric = SimilarityMetric.L2,\n        embedding_dimension: int = 768\n    ):\n        self._tools: Dict[str, Callable] = {}\n        self._tool_metadata: Dict[str, Dict] = {}\n        self.gov = governance_manager\n        self.embedding_config = embedding_config or {}\n        self.similarity_metric = similarity_metric\n        self.embedding_dimension = embedding_dimension\n        self._circuit_breaker_state: Dict[str, Dict] = {}\n        self._cache: Dict[str, Dict] = {}  # In-memory cache\n\n        self._tool_index = None\n        self._index_to_tool_name: Dict[int, str] = {}\n        if _EMBEDDINGS_ENABLED:\n            self._initialize_faiss_index()\n\n    def _initialize_faiss_index(self):\n        \"\"\"Initializes the correct FAISS index based on the chosen similarity metric.\"\"\"\n        if self.similarity_metric == SimilarityMetric.L2:\n            self._tool_index = faiss.IndexFlatL2(self.embedding_dimension)\n        elif self.similarity_metric in (SimilarityMetric.COSINE, SimilarityMetric.DOT_PRODUCT):\n            self._tool_index = faiss.IndexFlatIP(self.embedding_dimension)\n        else:\n            raise ValueError(\"Unsupported similarity metric: {}\".format(self.similarity_metric))\n\n    def _index_tool(self, tool_name: str):\n        \"\"\"Embeds and indexes a tool's description for semantic search.\"\"\"\n        if not _EMBEDDINGS_ENABLED or self._tool_index is None: return\n        metadata = self._tool_metadata.get(tool_name, {})\n        description = \"Tool: {}. Description: {}\".format(tool_name, metadata.get(\"docstring\", \"\"))\n        api_key = self.embedding_config.get(\"api_key\", \"\")\n        vector = gemini_embed(text=description, api_key=api_key)\n        if vector:\n            vector_np = np.array([vector], dtype=np.float32)\n            if self.similarity_metric == SimilarityMetric.COSINE:\n                faiss.normalize_L2(vector_np)\n            new_index_id = self._tool_index.ntotal\n            self._tool_index.add(vector_np)\n            self._index_to_tool_name[new_index_id] = tool_name\n\n    def register(\n        self,\n        required_role: Optional[str] = None,\n        retry_attempts: int = 0,\n        retry_delay: float = 1.0,\n        circuit_breaker_threshold: int = 0,\n        cache_ttl_seconds: int = 0,\n        cost_per_call: Optional[float] = None,\n        cost_calculator: Optional[Callable[[Any], float]] = None,\n        output_sinks: Optional[List[BaseOutputSink]] = None\n    ) -&gt; Callable:\n        \"\"\"A decorator to register a tool with advanced, governed execution policies.\"\"\"\n        def decorator(func: Callable) -&gt; Callable:\n            tool_name = func.__name__\n            self._tools[tool_name] = func\n            self._tool_metadata[tool_name] = {\n                \"docstring\": inspect.getdoc(func),\n                \"signature\": inspect.signature(func),\n                \"is_async\": inspect.iscoroutinefunction(func),\n                \"policies\": {\n                    \"role\": required_role, \"retry_attempts\": retry_attempts,\n                    \"retry_delay\": retry_delay, \"circuit_breaker_threshold\": circuit_breaker_threshold,\n                    \"cache_ttl_seconds\": cache_ttl_seconds, \"cost_per_call\": cost_per_call,\n                    \"cost_calculator\": cost_calculator, \"output_sinks\": output_sinks or []\n                }\n            }\n            self._circuit_breaker_state[tool_name] = {'failure_count': 0, 'is_open': False, 'opened_at': 0}\n            self._index_tool(tool_name)\n            return func\n        return decorator\n\n    def _create_cache_key(self, tool_name: str, **kwargs) -&gt; str:\n        \"\"\"Creates a stable cache key from the tool name and arguments.\"\"\"\n        hasher = hashlib.md5()\n        encoded = json.dumps(kwargs, sort_keys=True).encode('utf-8')\n        hasher.update(encoded)\n        return \"{}:{}\".format(tool_name, hasher.hexdigest())\n\n    def _check_pre_execution_policies(self, name: str, user_id: str, policies: Dict, **kwargs) -&gt; Optional[Any]:\n        \"\"\"Handles caching, circuit breaker, and RBAC checks. Returns cached result if hit.\"\"\"\n        # 1. Caching\n        if policies[\"cache_ttl_seconds\"] &gt; 0:\n            cache_key = self._create_cache_key(name, **kwargs)\n            if cache_key in self._cache:\n                cached_item = self._cache[cache_key]\n                if time.time() - cached_item[\"timestamp\"] &lt; policies[\"cache_ttl_seconds\"]:\n                    self.gov.audit(user_id, \"tool_cache_hit\", name, {\"args\": kwargs})\n                    return cached_item[\"result\"]\n\n        # 2. Circuit Breaker\n        cb_state = self._circuit_breaker_state[name]\n        if cb_state['is_open']:\n            if time.time() - cb_state['opened_at'] &gt; 60:  # 1-minute cooldown\n                cb_state['is_open'] = False\n            else:\n                msg = \"Circuit breaker for tool '{}' is open.\".format(name)\n                self.gov.audit(user_id, \"tool_circuit_breaker_open\", name, {\"error\": msg})\n                raise ToolExecutionError(msg)\n\n        # 3. RBAC\n        if policies[\"role\"] and not check_access(user_id, policies[\"role\"]):\n            msg = \"User '{}' lacks required role '{}' for tool '{}'.\".format(user_id, policies[\"role\"], name)\n            self.gov.audit(user_id, \"tool_access_denied\", name, {\"required_role\": policies[\"role\"]})\n            raise RBACError(msg)\n\n        return None\n\n    def _handle_post_execution(self, name: str, user_id: str, policies: Dict, result: Any, latency_ms: float, **kwargs):\n        \"\"\"Handles auditing, cost calculation, caching, and output sinks after successful execution.\"\"\"\n        cost = policies[\"cost_per_call\"]\n        if policies[\"cost_calculator\"]:\n            cost = policies[\"cost_calculator\"](result)\n\n        audit_metadata = {\"result_type\": type(result).__name__, \"latency_ms\": round(latency_ms), \"cost\": cost}\n        self.gov.audit(user_id, \"tool_call_end\", name, audit_metadata)\n\n        if policies[\"cache_ttl_seconds\"] &gt; 0:\n            cache_key = self._create_cache_key(name, **kwargs)\n            self._cache[cache_key] = {\"timestamp\": time.time(), \"result\": result}\n\n        run_id = self.gov.get_current_run_id()\n        for sink in policies[\"output_sinks\"]:\n            try:\n                sink_metadata = sink.handle(name, result, run_id, **kwargs)\n                self.gov.audit(user_id, \"output_sink_success\", str(sink), {\"tool_name\": name, **sink_metadata})\n            except Exception as e:\n                self.gov.audit(user_id, \"output_sink_failure\", str(sink), {\"tool_name\": name, \"error\": str(e)})\n\n    def _handle_execution_error(self, name: str, user_id: str, policies: Dict, e: Exception, attempt: int):\n        \"\"\"Handles failures, including retry logic and circuit breaker trips.\"\"\"\n        self.gov.audit(user_id, \"tool_call_error\", name, {\"error\": str(e), \"attempt\": attempt + 1})\n        if attempt &gt;= policies[\"retry_attempts\"]:\n            cb_state = self._circuit_breaker_state[name]\n            cb_state['failure_count'] += 1\n            if policies[\"circuit_breaker_threshold\"] &gt; 0 and cb_state['failure_count'] &gt;= policies[\"circuit_breaker_threshold\"]:\n                cb_state['is_open'] = True\n                cb_state['opened_at'] = time.time()\n                self.gov.audit(user_id, \"tool_circuit_breaker_tripped\", name)\n            raise ToolExecutionError(\"Tool '{}' failed after all retry attempts.\".format(name)) from e\n\n    def _get_governed_sync_tool(self, name: str, user_id: str, original_func: Callable, policies: Dict) -&gt; Callable:\n        \"\"\"Returns the fully governed wrapper for a synchronous tool.\"\"\"\n        def sync_wrapper(**kwargs):\n            cached_result = self._check_pre_execution_policies(name, user_id, policies, **kwargs)\n            if cached_result is not None: return cached_result\n\n            for attempt in range(policies[\"retry_attempts\"] + 1):\n                start_time = time.monotonic()\n                try:\n                    self.gov.audit(user_id, \"tool_call_start\", name, {\"args\": kwargs, \"attempt\": attempt + 1})\n                    result = original_func(**kwargs)\n                    latency_ms = (time.monotonic() - start_time) * 1000\n                    self._handle_post_execution(name, user_id, policies, result, latency_ms, **kwargs)\n                    return result\n                except Exception as e:\n                    self._handle_execution_error(name, user_id, policies, e, attempt)\n                    time.sleep(policies[\"retry_delay\"] * (2 ** attempt))\n            # This line should be logically unreachable if retry_attempts &gt;= 0\n            raise ToolExecutionError(\"Tool '{}' execution logic failed unexpectedly.\".format(name))\n        return sync_wrapper\n\n    def _get_governed_async_tool(self, name: str, user_id: str, original_func: Callable, policies: Dict) -&gt; Callable:\n        \"\"\"Returns the fully governed wrapper for an asynchronous tool.\"\"\"\n        async def async_wrapper(**kwargs):\n            cached_result = self._check_pre_execution_policies(name, user_id, policies, **kwargs)\n            if cached_result is not None: return cached_result\n\n            for attempt in range(policies[\"retry_attempts\"] + 1):\n                start_time = time.monotonic()\n                try:\n                    self.gov.audit(user_id, \"tool_call_start\", name, {\"args\": kwargs, \"attempt\": attempt + 1})\n                    result = await original_func(**kwargs)\n                    latency_ms = (time.monotonic() - start_time) * 1000\n                    self._handle_post_execution(name, user_id, policies, result, latency_ms, **kwargs)\n                    return result\n                except Exception as e:\n                    self._handle_execution_error(name, user_id, policies, e, attempt)\n                    await asyncio.sleep(policies[\"retry_delay\"] * (2 ** attempt))\n            # This line should be logically unreachable if retry_attempts &gt;= 0\n            raise ToolExecutionError(\"Tool '{}' execution logic failed unexpectedly.\".format(name))\n        return async_wrapper\n\n    def get_governed_tool(self, name: str, user_id: str) -&gt; Callable:\n        \"\"\"\n        Retrieves a tool by name and wraps it in all registered governance policies.\n        This method correctly handles both synchronous and asynchronous tools.\n        \"\"\"\n        if name not in self._tools:\n            raise ToolNotFoundError(\"Tool '{}' not found in registry.\".format(name))\n\n        metadata = self._tool_metadata[name]\n        original_func = self._tools[name]\n        policies = metadata[\"policies\"]\n\n        if metadata[\"is_async\"]:\n            return self._get_governed_async_tool(name, user_id, original_func, policies)\n        else:\n            return self._get_governed_sync_tool(name, user_id, original_func, policies)\n\n    def generate_tool_schema(self, tool_names: List[str]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generates a JSON Schema-like description for a list of tools.\"\"\"\n        schema = []\n        for name in tool_names:\n            if name in self._tool_metadata:\n                metadata = self._tool_metadata[name]\n                sig = metadata[\"signature\"]\n                properties = {}\n                for param in sig.parameters.values():\n                    if param.name != 'self':\n                        type_map = {str: 'string', int: 'number', float: 'number', bool: 'boolean'}\n                        param_type = type_map.get(param.annotation, 'string')\n                        properties[param.name] = {'type': param_type, 'description': ''}\n                schema.append({\n                    \"name\": name,\n                    \"description\": metadata[\"docstring\"],\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": properties,\n                        \"required\": [p.name for p in sig.parameters.values() if p.default == inspect.Parameter.empty and p.name != 'self']\n                    }\n                })\n        return schema\n\n    def get_relevant_tools(self, query: str, top_k: int = 3) -&gt; List[str]:\n        \"\"\"Finds the most semantically relevant tools for a given query using a vector index.\"\"\"\n        if not _EMBEDDINGS_ENABLED or self._tool_index is None or self._tool_index.ntotal == 0:\n            return []\n        api_key = self.embedding_config.get(\"api_key\", \"\")\n        query_vector = gemini_embed(text=query, api_key=api_key)\n        if not query_vector:\n            return []\n        query_np = np.array([query_vector], dtype=np.float32)\n        if self.similarity_metric == SimilarityMetric.COSINE:\n            faiss.normalize_L2(query_np)\n        distances, indices = self._tool_index.search(query_np, min(top_k, self._tool_index.ntotal))\n        return [self._index_to_tool_name[i] for i in indices[0]]\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistry.generate_tool_schema","title":"<code>generate_tool_schema(tool_names)</code>","text":"<p>Generates a JSON Schema-like description for a list of tools.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def generate_tool_schema(self, tool_names: List[str]) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generates a JSON Schema-like description for a list of tools.\"\"\"\n    schema = []\n    for name in tool_names:\n        if name in self._tool_metadata:\n            metadata = self._tool_metadata[name]\n            sig = metadata[\"signature\"]\n            properties = {}\n            for param in sig.parameters.values():\n                if param.name != 'self':\n                    type_map = {str: 'string', int: 'number', float: 'number', bool: 'boolean'}\n                    param_type = type_map.get(param.annotation, 'string')\n                    properties[param.name] = {'type': param_type, 'description': ''}\n            schema.append({\n                \"name\": name,\n                \"description\": metadata[\"docstring\"],\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": properties,\n                    \"required\": [p.name for p in sig.parameters.values() if p.default == inspect.Parameter.empty and p.name != 'self']\n                }\n            })\n    return schema\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistry.get_governed_tool","title":"<code>get_governed_tool(name, user_id)</code>","text":"<p>Retrieves a tool by name and wraps it in all registered governance policies. This method correctly handles both synchronous and asynchronous tools.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def get_governed_tool(self, name: str, user_id: str) -&gt; Callable:\n    \"\"\"\n    Retrieves a tool by name and wraps it in all registered governance policies.\n    This method correctly handles both synchronous and asynchronous tools.\n    \"\"\"\n    if name not in self._tools:\n        raise ToolNotFoundError(\"Tool '{}' not found in registry.\".format(name))\n\n    metadata = self._tool_metadata[name]\n    original_func = self._tools[name]\n    policies = metadata[\"policies\"]\n\n    if metadata[\"is_async\"]:\n        return self._get_governed_async_tool(name, user_id, original_func, policies)\n    else:\n        return self._get_governed_sync_tool(name, user_id, original_func, policies)\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistry.get_relevant_tools","title":"<code>get_relevant_tools(query, top_k=3)</code>","text":"<p>Finds the most semantically relevant tools for a given query using a vector index.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def get_relevant_tools(self, query: str, top_k: int = 3) -&gt; List[str]:\n    \"\"\"Finds the most semantically relevant tools for a given query using a vector index.\"\"\"\n    if not _EMBEDDINGS_ENABLED or self._tool_index is None or self._tool_index.ntotal == 0:\n        return []\n    api_key = self.embedding_config.get(\"api_key\", \"\")\n    query_vector = gemini_embed(text=query, api_key=api_key)\n    if not query_vector:\n        return []\n    query_np = np.array([query_vector], dtype=np.float32)\n    if self.similarity_metric == SimilarityMetric.COSINE:\n        faiss.normalize_L2(query_np)\n    distances, indices = self._tool_index.search(query_np, min(top_k, self._tool_index.ntotal))\n    return [self._index_to_tool_name[i] for i in indices[0]]\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistry.register","title":"<code>register(required_role=None, retry_attempts=0, retry_delay=1.0, circuit_breaker_threshold=0, cache_ttl_seconds=0, cost_per_call=None, cost_calculator=None, output_sinks=None)</code>","text":"<p>A decorator to register a tool with advanced, governed execution policies.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def register(\n    self,\n    required_role: Optional[str] = None,\n    retry_attempts: int = 0,\n    retry_delay: float = 1.0,\n    circuit_breaker_threshold: int = 0,\n    cache_ttl_seconds: int = 0,\n    cost_per_call: Optional[float] = None,\n    cost_calculator: Optional[Callable[[Any], float]] = None,\n    output_sinks: Optional[List[BaseOutputSink]] = None\n) -&gt; Callable:\n    \"\"\"A decorator to register a tool with advanced, governed execution policies.\"\"\"\n    def decorator(func: Callable) -&gt; Callable:\n        tool_name = func.__name__\n        self._tools[tool_name] = func\n        self._tool_metadata[tool_name] = {\n            \"docstring\": inspect.getdoc(func),\n            \"signature\": inspect.signature(func),\n            \"is_async\": inspect.iscoroutinefunction(func),\n            \"policies\": {\n                \"role\": required_role, \"retry_attempts\": retry_attempts,\n                \"retry_delay\": retry_delay, \"circuit_breaker_threshold\": circuit_breaker_threshold,\n                \"cache_ttl_seconds\": cache_ttl_seconds, \"cost_per_call\": cost_per_call,\n                \"cost_calculator\": cost_calculator, \"output_sinks\": output_sinks or []\n            }\n        }\n        self._circuit_breaker_state[tool_name] = {'failure_count': 0, 'is_open': False, 'opened_at': 0}\n        self._index_tool(tool_name)\n        return func\n    return decorator\n</code></pre>"},{"location":"reference/#safeagent.tool_registry.ToolRegistryError","title":"<code>ToolRegistryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for tool registry exceptions.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolRegistryError(Exception):\n    \"\"\"Base class for tool registry exceptions.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/#retrievers","title":"Retrievers","text":""},{"location":"reference/#safeagentretriever","title":"<code>safeagent.retriever</code>","text":""},{"location":"reference/#safeagent.retriever.BaseRetriever","title":"<code>BaseRetriever</code>","text":"<p>Base interface for retrieval. Requires implementing index and query.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class BaseRetriever:\n    \"\"\"Base interface for retrieval. Requires implementing index and query.\"\"\"\n    def index(self, embeddings: List[Any], metadata: List[Dict[str, Any]]) -&gt; None:\n        raise NotImplementedError\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/#safeagent.retriever.GraphRetriever","title":"<code>GraphRetriever</code>","text":"<p>               Bases: <code>BaseRetriever</code></p> <p>Neo4j-backed GraphRAG retriever using GDS k-NN, with governance integration.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class GraphRetriever(BaseRetriever):\n    \"\"\"Neo4j-backed GraphRAG retriever using GDS k-NN, with governance integration.\"\"\"\n\n    def __init__(self, neo4j_uri: str, user: str, password: str, gds_graph_name: str, embed_model_fn):\n        \"\"\"Create the retriever.\n\n        Args:\n            neo4j_uri (str): Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').\n            user (str): Username for Neo4j.\n            password (str): Password for Neo4j.\n            gds_graph_name (str): Name of the GDS graph projection in Neo4j.\n            embed_model_fn (callable): Function mapping text to an embedding vector.\n        \"\"\"\n        from neo4j import GraphDatabase\n\n        self.driver = GraphDatabase.driver(neo4j_uri, auth=(user, password))\n        self.gds_graph = gds_graph_name\n        self.embed = embed_model_fn\n        self.gov = GovernanceManager()\n\n    def index(self, embeddings: List[List[float]], metadata: List[Dict[str, Any]]):\n        \"\"\"\n        Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).\n\n        Args:\n            embeddings (List[List[float]]): List of embedding vectors.\n            metadata (List[Dict[str, Any]]): List of metadata dicts (must include 'id').\n        \"\"\"\n        self.gov.audit(user_id=\"system\", action=\"graph_index\", resource=\"neo4j\", metadata={\"count\": len(embeddings)})\n        with self.driver.session() as session:\n            for vec, meta in zip(embeddings, metadata):\n                tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_index\")\n                session.run(\n                    \"MERGE (d:Document {id: $id}) \"\n                    \"SET d.vector = $vector, d.metadata = $meta\",\n                    id=meta[\"id\"], vector=vec, meta=tagged_meta\n                )\n        log_entry = {\n            \"event\": \"graph_index\",\n            \"count\": len(embeddings),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).\n\n        Args:\n            query_text (str): The query string.\n            top_k (int): Number of nearest neighbors to return.\n\n        Returns:\n            List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n        \"\"\"\n        # Encrypt and audit query\n        encrypted_query = self.gov.encrypt(query_text)\n        self.gov.audit(user_id=\"system\", action=\"graph_query\", resource=\"neo4j\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n        vec = self._compute_embedding(query_text)\n        cypher = f\"\"\"\n            CALL gds.knn.query(\n                '{self.gds_graph}',\n                $vector,\n                {{k: $k}}\n            ) YIELD nodeId, similarity\n            RETURN gds.util.asNode(nodeId).id AS id, similarity\n        \"\"\"\n        results = []\n        with self.driver.session() as session:\n            for record in session.run(cypher, vector=vec, k=top_k):\n                node_id = record[\"id\"]\n                score = record[\"similarity\"]\n                meta = session.run(\n                    \"MATCH (d:Document {id: $id}) RETURN d.metadata AS meta\", id=node_id\n                ).single()[\"meta\"]\n                tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_query\")\n                results.append({\"id\": node_id, \"score\": score, \"metadata\": tagged_meta})\n\n        log_entry = {\n            \"event\": \"graph_query\",\n            \"top_k\": top_k,\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return results\n\n    def _compute_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"Return an embedding for ``text`` via the provided embedding function.\"\"\"\n        return self.embed(text)\n</code></pre>"},{"location":"reference/#safeagent.retriever.GraphRetriever.__init__","title":"<code>__init__(neo4j_uri, user, password, gds_graph_name, embed_model_fn)</code>","text":"<p>Create the retriever.</p> <p>Parameters:</p> Name Type Description Default <code>neo4j_uri</code> <code>str</code> <p>Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').</p> required <code>user</code> <code>str</code> <p>Username for Neo4j.</p> required <code>password</code> <code>str</code> <p>Password for Neo4j.</p> required <code>gds_graph_name</code> <code>str</code> <p>Name of the GDS graph projection in Neo4j.</p> required <code>embed_model_fn</code> <code>callable</code> <p>Function mapping text to an embedding vector.</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def __init__(self, neo4j_uri: str, user: str, password: str, gds_graph_name: str, embed_model_fn):\n    \"\"\"Create the retriever.\n\n    Args:\n        neo4j_uri (str): Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').\n        user (str): Username for Neo4j.\n        password (str): Password for Neo4j.\n        gds_graph_name (str): Name of the GDS graph projection in Neo4j.\n        embed_model_fn (callable): Function mapping text to an embedding vector.\n    \"\"\"\n    from neo4j import GraphDatabase\n\n    self.driver = GraphDatabase.driver(neo4j_uri, auth=(user, password))\n    self.gds_graph = gds_graph_name\n    self.embed = embed_model_fn\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"reference/#safeagent.retriever.GraphRetriever.index","title":"<code>index(embeddings, metadata)</code>","text":"<p>Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>List[List[float]]</code> <p>List of embedding vectors.</p> required <code>metadata</code> <code>List[Dict[str, Any]]</code> <p>List of metadata dicts (must include 'id').</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def index(self, embeddings: List[List[float]], metadata: List[Dict[str, Any]]):\n    \"\"\"\n    Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).\n\n    Args:\n        embeddings (List[List[float]]): List of embedding vectors.\n        metadata (List[Dict[str, Any]]): List of metadata dicts (must include 'id').\n    \"\"\"\n    self.gov.audit(user_id=\"system\", action=\"graph_index\", resource=\"neo4j\", metadata={\"count\": len(embeddings)})\n    with self.driver.session() as session:\n        for vec, meta in zip(embeddings, metadata):\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_index\")\n            session.run(\n                \"MERGE (d:Document {id: $id}) \"\n                \"SET d.vector = $vector, d.metadata = $meta\",\n                id=meta[\"id\"], vector=vec, meta=tagged_meta\n            )\n    log_entry = {\n        \"event\": \"graph_index\",\n        \"count\": len(embeddings),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n</code></pre>"},{"location":"reference/#safeagent.retriever.GraphRetriever.query","title":"<code>query(query_text, top_k=5)</code>","text":"<p>Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>query_text</code> <code>str</code> <p>The query string.</p> required <code>top_k</code> <code>int</code> <p>Number of nearest neighbors to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).\n\n    Args:\n        query_text (str): The query string.\n        top_k (int): Number of nearest neighbors to return.\n\n    Returns:\n        List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n    \"\"\"\n    # Encrypt and audit query\n    encrypted_query = self.gov.encrypt(query_text)\n    self.gov.audit(user_id=\"system\", action=\"graph_query\", resource=\"neo4j\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n    vec = self._compute_embedding(query_text)\n    cypher = f\"\"\"\n        CALL gds.knn.query(\n            '{self.gds_graph}',\n            $vector,\n            {{k: $k}}\n        ) YIELD nodeId, similarity\n        RETURN gds.util.asNode(nodeId).id AS id, similarity\n    \"\"\"\n    results = []\n    with self.driver.session() as session:\n        for record in session.run(cypher, vector=vec, k=top_k):\n            node_id = record[\"id\"]\n            score = record[\"similarity\"]\n            meta = session.run(\n                \"MATCH (d:Document {id: $id}) RETURN d.metadata AS meta\", id=node_id\n            ).single()[\"meta\"]\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_query\")\n            results.append({\"id\": node_id, \"score\": score, \"metadata\": tagged_meta})\n\n    log_entry = {\n        \"event\": \"graph_query\",\n        \"top_k\": top_k,\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return results\n</code></pre>"},{"location":"reference/#safeagent.retriever.VectorRetriever","title":"<code>VectorRetriever</code>","text":"<p>               Bases: <code>BaseRetriever</code></p> <p>FAISS-backed vector retriever. Uses an embedding function to map text to vectors, with governance integration.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class VectorRetriever(BaseRetriever):\n    \"\"\"FAISS-backed vector retriever. Uses an embedding function to map text to vectors, with governance integration.\"\"\"\n    def __init__(self, index_path: str, embed_model_fn):\n        \"\"\"\n        Args:\n            index_path (str): Filesystem path to store/load FAISS index.\n            embed_model_fn (callable): Function that maps text (str) to a numpy ndarray vector.\n        \"\"\"\n        self.embed = embed_model_fn\n        self.gov = GovernanceManager()\n        self.metadata_store: Dict[int, Dict[str, Any]] = {}\n        self.next_id = 0\n        self.index_path = index_path\n        if _FAISS:\n            if Path(index_path).exists():\n                self._index = faiss.read_index(index_path)\n            else:\n                self._index = faiss.IndexFlatL2(768)\n        else:\n            self._index = []  # type: ignore\n\n    def index(self, embeddings: List[np.ndarray], metadata: List[Dict[str, Any]]):\n        \"\"\"\n        Add embeddings to the FAISS index and store metadata (with lineage tagging).\n\n        Args:\n            embeddings (List[np.ndarray]): List of vectors.\n            metadata (List[Dict[str, Any]]): Corresponding metadata dicts (must include 'id').\n        \"\"\"\n        if _FAISS:\n            vectors = np.vstack(embeddings)\n            self._index.add(vectors)\n        else:\n            for vec in embeddings:\n                self._index.append(np.array(vec))\n        for vec, meta in zip(embeddings, metadata):\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"vector_index\")\n            self.metadata_store[self.next_id] = tagged_meta\n            self.next_id += 1\n\n        log_entry = {\n            \"event\": \"vector_index\",\n            \"count\": len(embeddings),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        if _FAISS:\n            faiss.write_index(self._index, self.index_path)\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Perform KNN search on the FAISS index using the embedded query, with encryption and audit.\n\n        Args:\n            query_text (str): The query string.\n            top_k (int): Number of nearest neighbors to return.\n\n        Returns:\n            List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n        \"\"\"\n        # Encrypt and audit query\n        encrypted_query = self.gov.encrypt(query_text)\n        self.gov.audit(user_id=\"system\", action=\"vector_query\", resource=\"faiss\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n        vec = self.embed(query_text)\n        if _FAISS:\n            distances, indices = self._index.search(np.array([vec]), top_k)\n            idx_list = indices[0]\n            dist_list = distances[0]\n        else:\n            if not self._index:\n                idx_list, dist_list = [], []\n            else:\n                def dist(a, b):\n                    return sum((ai - bi) ** 2 for ai, bi in zip(a, b)) ** 0.5\n\n                dists = [dist(v, vec) for v in self._index]\n                sorted_idx = sorted(range(len(dists)), key=lambda i: dists[i])[:top_k]\n                idx_list = sorted_idx\n                dist_list = [dists[i] for i in sorted_idx]\n        results = []\n        for idx, dist in zip(idx_list, dist_list):\n            meta = self.metadata_store.get(int(idx), {})\n            results.append({\"id\": int(idx), \"score\": float(dist), \"metadata\": meta})\n\n        log_entry = {\n            \"event\": \"vector_query\",\n            \"top_k\": top_k,\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return results\n</code></pre>"},{"location":"reference/#safeagent.retriever.VectorRetriever.__init__","title":"<code>__init__(index_path, embed_model_fn)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>index_path</code> <code>str</code> <p>Filesystem path to store/load FAISS index.</p> required <code>embed_model_fn</code> <code>callable</code> <p>Function that maps text (str) to a numpy ndarray vector.</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def __init__(self, index_path: str, embed_model_fn):\n    \"\"\"\n    Args:\n        index_path (str): Filesystem path to store/load FAISS index.\n        embed_model_fn (callable): Function that maps text (str) to a numpy ndarray vector.\n    \"\"\"\n    self.embed = embed_model_fn\n    self.gov = GovernanceManager()\n    self.metadata_store: Dict[int, Dict[str, Any]] = {}\n    self.next_id = 0\n    self.index_path = index_path\n    if _FAISS:\n        if Path(index_path).exists():\n            self._index = faiss.read_index(index_path)\n        else:\n            self._index = faiss.IndexFlatL2(768)\n    else:\n        self._index = []  # type: ignore\n</code></pre>"},{"location":"reference/#safeagent.retriever.VectorRetriever.index","title":"<code>index(embeddings, metadata)</code>","text":"<p>Add embeddings to the FAISS index and store metadata (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>List[ndarray]</code> <p>List of vectors.</p> required <code>metadata</code> <code>List[Dict[str, Any]]</code> <p>Corresponding metadata dicts (must include 'id').</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def index(self, embeddings: List[np.ndarray], metadata: List[Dict[str, Any]]):\n    \"\"\"\n    Add embeddings to the FAISS index and store metadata (with lineage tagging).\n\n    Args:\n        embeddings (List[np.ndarray]): List of vectors.\n        metadata (List[Dict[str, Any]]): Corresponding metadata dicts (must include 'id').\n    \"\"\"\n    if _FAISS:\n        vectors = np.vstack(embeddings)\n        self._index.add(vectors)\n    else:\n        for vec in embeddings:\n            self._index.append(np.array(vec))\n    for vec, meta in zip(embeddings, metadata):\n        tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"vector_index\")\n        self.metadata_store[self.next_id] = tagged_meta\n        self.next_id += 1\n\n    log_entry = {\n        \"event\": \"vector_index\",\n        \"count\": len(embeddings),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    if _FAISS:\n        faiss.write_index(self._index, self.index_path)\n</code></pre>"},{"location":"reference/#safeagent.retriever.VectorRetriever.query","title":"<code>query(query_text, top_k=5)</code>","text":"<p>Perform KNN search on the FAISS index using the embedded query, with encryption and audit.</p> <p>Parameters:</p> Name Type Description Default <code>query_text</code> <code>str</code> <p>The query string.</p> required <code>top_k</code> <code>int</code> <p>Number of nearest neighbors to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Perform KNN search on the FAISS index using the embedded query, with encryption and audit.\n\n    Args:\n        query_text (str): The query string.\n        top_k (int): Number of nearest neighbors to return.\n\n    Returns:\n        List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n    \"\"\"\n    # Encrypt and audit query\n    encrypted_query = self.gov.encrypt(query_text)\n    self.gov.audit(user_id=\"system\", action=\"vector_query\", resource=\"faiss\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n    vec = self.embed(query_text)\n    if _FAISS:\n        distances, indices = self._index.search(np.array([vec]), top_k)\n        idx_list = indices[0]\n        dist_list = distances[0]\n    else:\n        if not self._index:\n            idx_list, dist_list = [], []\n        else:\n            def dist(a, b):\n                return sum((ai - bi) ** 2 for ai, bi in zip(a, b)) ** 0.5\n\n            dists = [dist(v, vec) for v in self._index]\n            sorted_idx = sorted(range(len(dists)), key=lambda i: dists[i])[:top_k]\n            idx_list = sorted_idx\n            dist_list = [dists[i] for i in sorted_idx]\n    results = []\n    for idx, dist in zip(idx_list, dist_list):\n        meta = self.metadata_store.get(int(idx), {})\n        results.append({\"id\": int(idx), \"score\": float(dist), \"metadata\": meta})\n\n    log_entry = {\n        \"event\": \"vector_query\",\n        \"top_k\": top_k,\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return results\n</code></pre>"},{"location":"reference/#safeagent.retriever.register_retriever","title":"<code>register_retriever(name, cls)</code>","text":"<p>Register a retriever class for dynamic loading.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def register_retriever(name: str, cls):\n    \"\"\"Register a retriever class for dynamic loading.\"\"\"\n    RETRIEVER_REGISTRY[name] = cls\n</code></pre>"},{"location":"reference/#protocols","title":"Protocols","text":""},{"location":"reference/#safeagentprotocol_manager","title":"<code>safeagent.protocol_manager</code>","text":""},{"location":"reference/#safeagent.protocol_manager.PROTOCOLS","title":"<code>PROTOCOLS</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Defines the supported communication/execution protocols.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>class PROTOCOLS(Enum):\n    \"\"\"Defines the supported communication/execution protocols.\"\"\"\n    MCP = \"mcp\"  # Master/Controller/Program protocol\n    AGENT2AGENT = \"agent2agent\"\n</code></pre>"},{"location":"reference/#safeagent.protocol_manager.ProtocolManager","title":"<code>ProtocolManager</code>","text":"<p>Manages the selection and execution of different agent workflows (protocols). This class acts as the main entry point for running a complete agent system.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>class ProtocolManager:\n    \"\"\"\n    Manages the selection and execution of different agent workflows (protocols).\n    This class acts as the main entry point for running a complete agent system.\n    \"\"\"\n    def __init__(self, protocol: str = None):\n        self.protocol = protocol or DEFAULT_PROTOCOL\n        if self.protocol not in (p.value for p in PROTOCOLS):\n            raise ValueError(\"Unsupported protocol: {}\".format(self.protocol))\n        gov.audit(\n            user_id=\"system\",\n            action=\"protocol_selected\",\n            resource=\"ProtocolManager\",\n            metadata={\"protocol\": self.protocol}\n        )\n\n    def run(self, inputs: Dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Executes the configured workflow based on the selected protocol.\n        \"\"\"\n        if self.protocol == PROTOCOLS.MCP.value:\n            return self._run_mcp(inputs)\n        elif self.protocol == PROTOCOLS.AGENT2AGENT.value:\n            return self._run_agent2agent(inputs)\n        else:\n            raise NotImplementedError(\"Protocol '{}' is not implemented.\".format(self.protocol))\n\n    def _initialize_shared_resources(self):\n        \"\"\"Initializes all shared components needed by the protocols.\"\"\"\n        cfg = Config()\n        llm = LLMClient(provider=cfg.llm_provider, api_key=cfg.api_key, model=cfg.llm_model)\n        renderer = PromptRenderer(template_dir=Path(cfg.template_dir))\n        embedding_fn = lambda text: gemini_embed(text, cfg.api_key)\n\n        vector_ret = VectorRetriever(index_path=cfg.faiss_index_path, embed_model_fn=embedding_fn)\n        graph_ret = GraphRetriever(\n            neo4j_uri=cfg.neo4j_uri,\n            user=cfg.neo4j_user,\n            password=cfg.neo4j_password,\n            gds_graph_name=cfg.gds_graph_name,\n            embed_model_fn=embedding_fn\n        )\n        mem_mgr = MemoryManager(backend=cfg.memory_backend, redis_url=cfg.redis_url)\n\n        # Correctly initialize the ToolRegistry with all new configurations\n        tool_registry = ToolRegistry(\n            governance_manager=gov,\n            embedding_config={\"api_key\": cfg.api_key},\n            similarity_metric=SimilarityMetric(cfg.tool_similarity_metric),\n            embedding_dimension=cfg.embedding_dimension\n        )\n        return llm, renderer, vector_ret, graph_ret, mem_mgr, tool_registry\n\n    def _define_tools(self, tool_registry: ToolRegistry):\n        \"\"\"A central place to define and register all available tools with policies.\"\"\"\n        @tool_registry.register(\n            cost_per_call=0.001,\n            cache_ttl_seconds=512,  # Cache results for 8 minutes 31.8 seconds\n            retry_attempts=2\n        )\n        def get_weather(city: str) -&gt; str:\n            \"\"\"A governed tool to fetch the weather for a given city.\"\"\"\n            if \"zephyrhills\" in city.lower():\n                return \"It is currently 82\u00b0F and sunny in Zephyrhills.\"\n            elif \"san francisco\" in city.lower():\n                return \"It is currently 65\u00b0F and foggy in San Francisco.\"\n            else:\n                return \"Weather data for {} is not available.\".format(city)\n\n    def _build_mcp_orchestrator(self, resources: tuple) -&gt; SimpleOrchestrator:\n        \"\"\"Builds the MCP orchestrator with the superior tool-use workflow.\"\"\"\n        llm, renderer, vector_ret, graph_ret, mem_mgr, tool_registry = resources\n        self._define_tools(tool_registry)\n\n        orch = SimpleOrchestrator()\n\n        def retrieve_docs(user_input: str, user_id: str, **kwargs):\n            if not check_access(user_id, \"vector_store\"):\n                raise RBACError(\"User {} unauthorized for retrieval\".format(user_id))\n            v_docs = vector_ret.query(user_input, top_k=3)\n            g_docs = graph_ret.query(user_input, top_k=3)\n            combined = {d[\"id\"]: d for d in (v_docs + g_docs)}\n            return list(combined.values())\n\n        def make_initial_prompt(user_input: str, retrieve_docs: List[dict], **kwargs) -&gt; str:\n            # Use semantic search to find only the most relevant tools\n            relevant_tools = tool_registry.get_relevant_tools(user_input, top_k=3)\n            tool_schemas = tool_registry.generate_tool_schema(relevant_tools)\n            return renderer.render(\n                \"tool_decider_prompt.j2\",\n                question=user_input,\n                docs=retrieve_docs,\n                tools=tool_schemas\n            )\n\n        def call_llm_for_tool(make_initial_prompt: str, user_id: str, **kwargs) -&gt; dict:\n            if not check_access(user_id, \"llm_call\"):\n                raise RBACError(\"User {} unauthorized for LLM calls\".format(user_id))\n            summary = mem_mgr.load(user_id, \"summary\") or \"\"\n            full_prompt = \"{}\\n\\n{}\".format(summary, make_initial_prompt)\n            return llm.generate(full_prompt)\n\n        def execute_tool(call_llm_for_tool: dict, user_id: str, **kwargs) -&gt; dict:\n            response_text = call_llm_for_tool.get(\"text\", \"\")\n            try:\n                data = json.loads(response_text)\n                if isinstance(data, dict) and \"tool_name\" in data and \"tool_args\" in data:\n                    tool_name = data[\"tool_name\"]\n                    tool_args = data[\"tool_args\"]\n                    # Use the fully governed tool wrapper\n                    governed_tool = tool_registry.get_governed_tool(tool_name, user_id)\n                    result = governed_tool(**tool_args)\n                    return {\"status\": \"success\", \"output\": result}\n            except (json.JSONDecodeError, TypeError, NameError):\n                # If it's not a valid tool call, pass through the text\n                pass\n            return {\"status\": \"no_tool_needed\", \"output\": response_text}\n\n        def generate_final_answer(execute_tool: dict, user_input: str, **kwargs) -&gt; dict:\n            if execute_tool[\"status\"] != \"success\":\n                # If no tool was called, the output from the first LLM is the final answer\n                return {\"text\": execute_tool[\"output\"]}\n            # If a tool was called, synthesize a final answer from its result\n            final_prompt = renderer.render(\"synthesis_prompt.j2\", question=user_input, tool_result=execute_tool[\"output\"])\n            return llm.generate(final_prompt)\n\n        # Define the graph structure\n        orch.add_node(\"retrieve_docs\", retrieve_docs)\n        orch.add_node(\"make_initial_prompt\", make_initial_prompt)\n        orch.add_node(\"call_llm_for_tool\", call_llm_for_tool)\n        orch.add_node(\"execute_tool\", execute_tool)\n        orch.add_node(\"generate_final_answer\", generate_final_answer)\n        # Define the execution flow\n        orch.add_edge(\"user_input\", \"retrieve_docs\")\n        orch.add_edge(\"user_input\", \"make_initial_prompt\")\n        orch.add_edge(\"retrieve_docs\", \"make_initial_prompt\")\n        orch.add_edge(\"make_initial_prompt\", \"call_llm_for_tool\")\n        orch.add_edge(\"call_llm_for_tool\", \"execute_tool\")\n        orch.add_edge(\"user_id\", \"execute_tool\")\n        orch.add_edge(\"execute_tool\", \"generate_final_answer\")\n        orch.add_edge(\"user_input\", \"generate_final_answer\")\n\n        return orch\n\n    def _run_mcp(self, inputs: Dict[str, Any]) -&gt; Any:\n        \"\"\"Runs the complete MCP workflow.\"\"\"\n        resources = self._initialize_shared_resources()\n        orch = self._build_mcp_orchestrator(resources)\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_mcp_start\", resource=\"ProtocolManager\")\n        results = orch.run(inputs)\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_mcp_end\", resource=\"ProtocolManager\")\n        return results\n\n    def _run_agent2agent(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Runs the Agent-to-Agent simulation workflow.\"\"\"\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_agent2agent_start\", resource=\"ProtocolManager\")\n        llm, _, _, vector_ret, mem_mgr, _ = self._initialize_shared_resources()\n        agents = {}\n        agent_ids = [\"analyst_agent\", \"manager_agent\"]\n\n        for aid in agent_ids:\n            orch = SimpleOrchestrator()\n            def retrieve(agent_id=aid, user_input: str = inputs[\"user_input\"], **kwargs):\n                return vector_ret.query(\"Query for {}: {}\".format(agent_id, user_input), top_k=2)\n\n            def respond(retrieve: List[dict], agent_id=aid, **kwargs) -&gt; dict:\n                doc_ids = [d.get('id', 'N/A') for d in retrieve]\n                prompt = \"As {}, generate a one-sentence response based on documents: {}\".format(agent_id, doc_ids)\n                return llm.generate(prompt)\n\n            orch.add_node(\"{}_retrieve\".format(aid), retrieve)\n            orch.add_node(\"{}_respond\".format(aid), respond)\n            orch.add_edge(\"{}_retrieve\".format(aid), \"{}_respond\".format(aid))\n            agents[aid] = orch\n\n        outputs = {}\n        for aid, orch in agents.items():\n            gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"agent_start\", resource=aid)\n            res = orch.run(inputs)\n            outputs[aid] = res.get(\"{}_respond\".format(aid), {}).get(\"text\", \"\")\n            mem_mgr.save(aid, \"last_response\", outputs[aid])\n            gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"agent_end\", resource=aid)\n\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_agent2agent_end\", resource=\"ProtocolManager\")\n        return outputs\n</code></pre>"},{"location":"reference/#safeagent.protocol_manager.ProtocolManager.run","title":"<code>run(inputs)</code>","text":"<p>Executes the configured workflow based on the selected protocol.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>def run(self, inputs: Dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Executes the configured workflow based on the selected protocol.\n    \"\"\"\n    if self.protocol == PROTOCOLS.MCP.value:\n        return self._run_mcp(inputs)\n    elif self.protocol == PROTOCOLS.AGENT2AGENT.value:\n        return self._run_agent2agent(inputs)\n    else:\n        raise NotImplementedError(\"Protocol '{}' is not implemented.\".format(self.protocol))\n</code></pre>"},{"location":"advanced-guides/human-in-the-loop/","title":"Advanced Guide: Human-in-the-Loop","text":"<p>For many critical tasks, you need to pause an agent's execution and ask for human approval. The <code>StatefulOrchestrator</code> supports this with a special <code>__interrupt__</code> node.</p>"},{"location":"advanced-guides/human-in-the-loop/#example-agent-seeking-approval","title":"Example: Agent Seeking Approval","text":"<p>This is a complete, runnable script demonstrating a human-in-the-loop workflow.</p> <pre><code>from safeagent import *\n\n# --- Setup ---\ngov = GovernanceManager()\nllm = LLMClient(api_key=Config().api_key)\ndef send_email(body: str): \n    print(\"--- EMAIL SENT ---\")\n    print(body)\n\n# --- Agent Nodes ---\ndef draft_email(state: dict) -&gt; dict:\n    prompt = f\"Draft a polite email about: {state['topic']}\"\n    response = llm.generate(prompt, max_tokens=100)\n    return {\"draft\": response['text']}\n\ndef get_human_approval(state: dict) -&gt; str:\n    return \"__interrupt__\"\n\n# --- Build and Run ---\nagent = StatefulOrchestrator(entry_node=\"draft_email\")\nagent.add_node(\"draft_email\", draft_email)\nagent.add_node(\"send_final_email\", lambda state: send_email(state['final_draft']))\nagent.add_conditional_edge(\"draft_email\", get_human_approval)\nagent.add_edge(\"send_final_email\", \"__end__\")\n\ngov.start_new_run() \ninitial_state = {\"topic\": \"team meeting moved to 3 PM\"}\nstatus, paused_state = agent.run(initial_state)\n\nprint(f\"\\n--- AGENT PAUSED --- DRAFT FOR APPROVAL:\\n{paused_state['draft']}\")\n\nif status == \"paused\":\n    feedback = input(\"\\nType 'approve' or provide edits: \")\n    human_input = {\"final_draft\": paused_state['draft'] if \"approve\" in feedback.lower() else feedback}\n    paused_state['__next_node__'] = 'send_final_email'\n\n    status, final_state = agent.resume(paused_state, human_input)\n    print(f\"\\n--- AGENT COMPLETED --- Final Status: {status}\")\n</code></pre>"},{"location":"advanced-guides/output-sinks/","title":"Advanced Guide: Tool Output Sinks","text":"<p>In a production environment, a tool's output often needs to be sent to other systems. SafeAgent handles this declaratively with Output Sinks.</p>"},{"location":"advanced-guides/output-sinks/#the-core-idea","title":"The Core Idea","text":"<p>Instead of writing publishing logic inside every tool, you can attach \"sinks\" to a tool when you register it. After the tool runs successfully, the framework automatically sends its result to each attached sink.</p>"},{"location":"advanced-guides/output-sinks/#example-saving-and-publishing-tool-results","title":"Example: Saving and Publishing Tool Results","text":"<p>This runnable example defines a tool to generate an invoice and attaches two sinks: 1.  A <code>FileOutputSink</code> to save a JSON record locally. 2.  A conceptual <code>PubSubSink</code> to send the data to a cloud messaging queue.</p> <pre><code>from safeagent import *\nimport datetime\nimport os\nimport json\nimport shutil\n\n# --- Setup ---\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\n# 1. Define and register the tool with multiple output sinks\n@tool_registry.register(\n    required_role=\"billing\",\n    output_sinks=[\n        FileOutputSink(base_path=\"invoices\"), # Sink 1\n        PubSubSink(project_id=\"my-gcp-project\", topic_id=\"invoice-queue\") # Sink 2\n    ]\n)\ndef generate_invoice(customer_id: int, amount: float) -&gt; dict:\n    \"\"\"Generates a new invoice for a customer.\"\"\"\n    return {\n        \"invoice_id\": f\"INV-{datetime.datetime.now().timestamp()}\",\n        \"customer_id\": customer_id, \"amount\": amount,\n        \"due_date\": (datetime.date.today() + datetime.timedelta(days=30)).isoformat()\n    }\n\n# --- Execution ---\ngov.start_new_run() \ninvoice_tool = tool_registry.get_governed_tool(name=\"generate_invoice\", user_id=\"billing_clerk\")\nresult = invoice_tool(customer_id=123, amount=99.99)\nprint(f\"Tool Result: {result}\")\n\n# --- Verification ---\nrun_id = gov.get_current_run_id()\nexpected_path = os.path.join(\"invoices\", f\"generate_invoice_{run_id}.json\")\nprint(f\"\\nVerifying file sink result at: {expected_path}\")\n\nwith open(expected_path, \"r\") as f:\n    saved_data = json.load(f)\n\nprint(f\"\\n--- Contents of Saved File ---\\n{json.dumps(saved_data, indent=2)}\")\n\nshutil.rmtree(\"invoices\")\n</code></pre>"},{"location":"advanced-guides/production-policies/","title":"Advanced Guide: Production Policies","text":"<p>A key advantage of SafeAgent is the ability to declaratively add production-grade policies to your tools via the <code>@tool_registry.register</code> decorator.</p>"},{"location":"advanced-guides/production-policies/#1-caching-cache_ttl_seconds","title":"1. Caching (<code>cache_ttl_seconds</code>)","text":"<p>Prevents redundant tool calls by caching results.</p> <pre><code>@tool_registry.register(cache_ttl_seconds=300)\ndef get_user_profile(user_id: int) -&gt; dict: #...\n</code></pre>"},{"location":"advanced-guides/production-policies/#2-retries-retry_attempts-retry_delay","title":"2. Retries (<code>retry_attempts</code>, <code>retry_delay</code>)","text":"<p>Automatically retries a tool if it fails due to transient issues.</p> <pre><code>@tool_registry.register(retry_attempts=2, retry_delay=2.0)\ndef call_flaky_api(): #...\n</code></pre>"},{"location":"advanced-guides/production-policies/#3-circuit-breaker-circuit_breaker_threshold","title":"3. Circuit Breaker (<code>circuit_breaker_threshold</code>)","text":"<p>Prevents an agent from repeatedly calling a service that is clearly down.</p> <pre><code>@tool_registry.register(circuit_breaker_threshold=5)\ndef call_critical_service(): #...\n</code></pre>"},{"location":"advanced-guides/production-policies/#4-cost-tracking-cost_per_call-cost_calculator","title":"4. Cost Tracking (<code>cost_per_call</code>, <code>cost_calculator</code>)","text":"<p>Adds cost information to the audit log for every tool call.</p> <pre><code># Fixed cost\n@tool_registry.register(cost_per_call=0.01)\ndef get_map_data(): #...\n</code></pre>"},{"location":"advanced-guides/production-policies/#5-security-required_role","title":"5. Security (<code>required_role</code>)","text":"<p>Restricts tool execution to users with a specific role.</p> <pre><code>@tool_registry.register(required_role=\"billing_admin\")\ndef process_refund(transaction_id: str): #...\n</code></pre>"},{"location":"advanced-guides/stateful-agents/","title":"Advanced Guide: Stateful Agents (ReAct)","text":"<p>The <code>StatefulOrchestrator</code> is designed to build complex agents that can reason, act, and loop until a task is complete. A classic example is the ReAct (Reason + Act) pattern.</p> <p>This is a complete, runnable script for a ReAct agent.</p> <pre><code>from safeagent import *\nimport json\n\n# --- Setup ---\ngov = GovernanceManager()\ncfg = Config()\nllm = LLMClient(api_key=cfg.api_key)\ntool_registry = ToolRegistry(governance_manager=gov, embedding_config={\"api_key\": cfg.api_key})\n\n@tool_registry.register()\ndef search_wikipedia(query: str) -&gt; str:\n    \"\"\"Searches for a term on Wikipedia. Use this for general knowledge questions.\"\"\"\n    print(f\"TOOL: Searching Wikipedia for '{query}'\")\n    if \"zephyrhills\" in query.lower():\n        return \"Zephyrhills is a city in Pasco County, Florida, known for its bottled water.\"\n    return \"No information found for that query.\"\n\n# --- Agent Nodes ---\ndef reason_node(state: dict) -&gt; dict:\n    \"\"\"Decides which tool to use or if the task is complete.\"\"\"\n    print(\"--- STEP: REASONING ---\")\n\n    prompt = f\"Question: {state['question']}\\n\"\n    prompt += f\"Conversation History: {state.get('history', [])}\\n\\n\"\n    prompt += \"Decide the next action. Should you use a tool, or do you have the final answer? \"\n    prompt += \"If using a tool, respond with JSON: {\\\"tool_name\\\": \\\"tool_to_use\\\", \\\"tool_args\\\": {\\\"arg\\\": \\\"value\\\"}}. \"\n    prompt += \"Otherwise, respond with the final answer as a plain string.\"\n\n    response = llm.generate(prompt)\n\n    try:\n        decision = json.loads(response['text'])\n        print(f\"Decision: Call tool '{decision.get('tool_name')}'\")\n        return {\"decision\": decision}\n    except json.JSONDecodeError:\n        print(f\"Decision: Final Answer Found\")\n        return {\"decision\": {\"tool_name\": \"__end__\", \"final_answer\": response['text']}}\n\ndef act_node(state: dict) -&gt; dict:\n    \"\"\"Executes the chosen tool.\"\"\"\n    print(\"--- STEP: ACTING ---\")\n    tool_name = state['decision']['tool_name']\n    tool_args = state['decision']['tool_args']\n\n    governed_tool = tool_registry.get_governed_tool(tool_name, user_id=\"agent_123\")\n    observation = governed_tool(**tool_args)\n\n    print(f\"Observation: {observation}\")\n    new_history = state.get('history', []) + [f\"Called tool '{tool_name}' and got this result: '{observation}'\"]\n    return {\"history\": new_history}\n\n# --- Define Conditional Edge ---\ndef should_continue(state: dict) -&gt; str:\n    \"\"\"The routing logic for the graph. It checks the reasoning decision.\"\"\"\n    if state['decision']['tool_name'] == \"__end__\":\n        return \"__end__\"\n    return \"act_node\"\n\n# --- Build and Run the Graph ---\nagent = StatefulOrchestrator(entry_node=\"reason_node\")\nagent.add_node(\"reason_node\", reason_node)\nagent.add_node(\"act_node\", act_node)\nagent.add_edge(\"act_node\", \"reason_node\") \nagent.add_conditional_edge(\"reason_node\", should_continue)\n\ninitial_state = {\"question\": \"What is Zephyrhills known for?\"}\ngov.start_new_run()\nstatus, final_state = agent.run(initial_state)\n\nprint(\"\\n--- AGENT FINISHED ---\")\nprint(f\"Status: {status}\")\nprint(f\"Final Answer: {final_state.get('decision', {}).get('final_answer')}\")\n\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the SafeAgent API reference. This section provides detailed, auto-generated documentation for all public classes and functions in the framework.</p> <p>Use the navigation on the left to browse the different components of the framework.</p>"},{"location":"api/core/","title":"API: Core Components","text":"<p>This section covers the fundamental building blocks of the SafeAgent framework.</p>"},{"location":"api/core/#safeagentconfig","title":"<code>safeagent.config</code>","text":"<p>Simple configuration loader with environment variable defaults.</p>"},{"location":"api/core/#safeagentgovernance","title":"<code>safeagent.governance</code>","text":""},{"location":"api/core/#safeagent.governance.DataGovernanceError","title":"<code>DataGovernanceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised when governance policies are violated.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>class DataGovernanceError(Exception):\n    \"\"\"Exception raised when governance policies are violated.\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager","title":"<code>GovernanceManager</code>","text":"<p>Manages data governance policies, including encryption, auditing, retention policies, and run ID management.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>class GovernanceManager:\n    \"\"\"\n    Manages data governance policies, including encryption, auditing,\n    retention policies, and run ID management.\n    \"\"\"\n\n    def __init__(self, audit_log_path: str = \"audit.log\", retention_days: int = 30):\n        self.audit_log_path = audit_log_path\n        self.retention_days = retention_days\n        open(self.audit_log_path, \"a\").close()\n        self.current_run_id = None\n\n    def start_new_run(self) -&gt; str:\n        \"\"\"Generates a new unique ID for a single, complete run of an orchestrator.\"\"\"\n        self.current_run_id = str(uuid.uuid4())\n        return self.current_run_id\n\n    def get_current_run_id(self) -&gt; str:\n        \"\"\"Returns the ID for the current run, creating one if it doesn't exist.\"\"\"\n        if not self.current_run_id:\n            return self.start_new_run()\n        return self.current_run_id\n\n    def encrypt(self, plaintext: str) -&gt; str:\n        \"\"\"Encrypt sensitive data before storage.\"\"\"\n        return fernet.encrypt(plaintext.encode()).decode()\n\n    def decrypt(self, token: str) -&gt; str:\n        \"\"\"Decrypt sensitive data when needed.\"\"\"\n        return fernet.decrypt(token.encode()).decode()\n\n    def audit(self, user_id: str, action: str, resource: str, metadata: Dict[str, Any] = None) -&gt; None:\n        \"\"\"Write an audit log entry for data actions, including the current run_id.\"\"\"\n        entry = {\n            \"timestamp\": time.time(),\n            \"run_id\": self.get_current_run_id(), \n            \"user_id\": user_id,\n            \"action\": action,\n            \"resource\": resource,\n            \"metadata\": metadata or {}\n        }\n        with open(self.audit_log_path, \"a\") as f:\n            f.write(json.dumps(entry) + \"\\n\")\n\n    def tag_lineage(self, record: Dict[str, Any], source: str) -&gt; Dict[str, Any]:\n        \"\"\"Attach lineage metadata to a record.\"\"\"\n        if \"_lineage\" not in record:\n            record[\"_lineage\"] = []\n        record[\"_lineage\"].append({\n            \"timestamp\": time.time(),\n            \"source\": source\n        })\n        return record\n\n    def purge_old_logs(self) -&gt; None:\n        \"\"\"Purge audit log entries older than retention period.\"\"\"\n        cutoff = time.time() - self.retention_days * 86400\n        retained = []\n        with open(self.audit_log_path, \"r\") as f:\n            for line in f:\n                try:\n                    entry = json.loads(line)\n                    if entry.get(\"timestamp\", 0) &gt;= cutoff:\n                        retained.append(line)\n                except json.JSONDecodeError:\n                    continue\n        with open(self.audit_log_path, \"w\") as f:\n            f.writelines(retained)\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.audit","title":"<code>audit(user_id, action, resource, metadata=None)</code>","text":"<p>Write an audit log entry for data actions, including the current run_id.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def audit(self, user_id: str, action: str, resource: str, metadata: Dict[str, Any] = None) -&gt; None:\n    \"\"\"Write an audit log entry for data actions, including the current run_id.\"\"\"\n    entry = {\n        \"timestamp\": time.time(),\n        \"run_id\": self.get_current_run_id(), \n        \"user_id\": user_id,\n        \"action\": action,\n        \"resource\": resource,\n        \"metadata\": metadata or {}\n    }\n    with open(self.audit_log_path, \"a\") as f:\n        f.write(json.dumps(entry) + \"\\n\")\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.decrypt","title":"<code>decrypt(token)</code>","text":"<p>Decrypt sensitive data when needed.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def decrypt(self, token: str) -&gt; str:\n    \"\"\"Decrypt sensitive data when needed.\"\"\"\n    return fernet.decrypt(token.encode()).decode()\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.encrypt","title":"<code>encrypt(plaintext)</code>","text":"<p>Encrypt sensitive data before storage.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def encrypt(self, plaintext: str) -&gt; str:\n    \"\"\"Encrypt sensitive data before storage.\"\"\"\n    return fernet.encrypt(plaintext.encode()).decode()\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.get_current_run_id","title":"<code>get_current_run_id()</code>","text":"<p>Returns the ID for the current run, creating one if it doesn't exist.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def get_current_run_id(self) -&gt; str:\n    \"\"\"Returns the ID for the current run, creating one if it doesn't exist.\"\"\"\n    if not self.current_run_id:\n        return self.start_new_run()\n    return self.current_run_id\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.purge_old_logs","title":"<code>purge_old_logs()</code>","text":"<p>Purge audit log entries older than retention period.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def purge_old_logs(self) -&gt; None:\n    \"\"\"Purge audit log entries older than retention period.\"\"\"\n    cutoff = time.time() - self.retention_days * 86400\n    retained = []\n    with open(self.audit_log_path, \"r\") as f:\n        for line in f:\n            try:\n                entry = json.loads(line)\n                if entry.get(\"timestamp\", 0) &gt;= cutoff:\n                    retained.append(line)\n            except json.JSONDecodeError:\n                continue\n    with open(self.audit_log_path, \"w\") as f:\n        f.writelines(retained)\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.start_new_run","title":"<code>start_new_run()</code>","text":"<p>Generates a new unique ID for a single, complete run of an orchestrator.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def start_new_run(self) -&gt; str:\n    \"\"\"Generates a new unique ID for a single, complete run of an orchestrator.\"\"\"\n    self.current_run_id = str(uuid.uuid4())\n    return self.current_run_id\n</code></pre>"},{"location":"api/core/#safeagent.governance.GovernanceManager.tag_lineage","title":"<code>tag_lineage(record, source)</code>","text":"<p>Attach lineage metadata to a record.</p> Source code in <code>src\\safeagent\\governance.py</code> <pre><code>def tag_lineage(self, record: Dict[str, Any], source: str) -&gt; Dict[str, Any]:\n    \"\"\"Attach lineage metadata to a record.\"\"\"\n    if \"_lineage\" not in record:\n        record[\"_lineage\"] = []\n    record[\"_lineage\"].append({\n        \"timestamp\": time.time(),\n        \"source\": source\n    })\n    return record\n</code></pre>"},{"location":"api/core/#safeagentllm_client","title":"<code>safeagent.llm_client</code>","text":""},{"location":"api/core/#safeagent.llm_client.FrameworkError","title":"<code>FrameworkError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Custom exception for framework-related errors.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>class FrameworkError(Exception):\n    \"\"\"Custom exception for framework-related errors.\"\"\"\n    pass\n</code></pre>"},{"location":"api/core/#safeagent.llm_client.LLMClient","title":"<code>LLMClient</code>","text":"<p>Thin wrapper around any LLM provider with retries, error handling, and structured JSON logging.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>class LLMClient:\n    \"\"\"Thin wrapper around any LLM provider with retries, error handling, and structured JSON logging.\"\"\"\n\n    def __init__(self, provider: str, api_key: str, model: str, base_url: str = None):\n        \"\"\"\n        Initialize the LLM client.\n\n        Args:\n            provider (str): Name of the provider (e.g., 'openai', 'anthropic').\n            api_key (str): API key or token for authentication.\n            model (str): Model identifier (e.g., 'gpt-4', 'claude-3-opus').\n            base_url (str, optional): Custom endpoint URL; defaults to provider-specific default.\n        \"\"\"\n        self.provider = provider\n        self.api_key = api_key\n        self.model = model\n        self.base_url = base_url or self._default_url()\n        if requests is not None:\n            self.session = requests.Session()\n        else:\n            class _DummySession:\n                def __init__(self):\n                    self.headers = {}\n\n                def post(self, *_, **__):\n                    raise FrameworkError(\"requests package is required for HTTP calls\")\n\n            self.session = _DummySession()\n        self.session.headers.update({\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\"\n        })\n        self.gov = GovernanceManager()\n\n    def _default_url(self) -&gt; str:\n        \"\"\"Return default endpoint URL based on provider.\"\"\"\n        if self.provider == \"openai\":\n            return \"https://api.openai.com/v1/chat/completions\"\n        if self.provider == \"anthropic\":\n            return \"https://api.anthropic.com/v1/complete\"\n        if self.provider == \"gemini\":\n            return f\"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}\"\n        raise FrameworkError(f\"No default URL configured for provider '{self.provider}'\")\n\n    def generate(self, prompt: str, max_tokens: int = 512, temperature: float = 0.7) -&gt; Dict:\n        \"\"\"\n        Call the underlying LLM API, with up to 3 retries.\n\n        Args:\n            prompt (str): The textual prompt to send to the model.\n            max_tokens (int): Maximum number of tokens in the response.\n            temperature (float): Sampling temperature.\n\n        Returns:\n            Dict: A dictionary containing keys 'text', 'usage', and 'metadata'.\n\n        Raises:\n            FrameworkError: If the API fails after retries.\n        \"\"\"\n        # Encrypt the prompt before logging\n        encrypted_prompt = self.gov.encrypt(prompt)\n        self.gov.audit(user_id=\"system\", action=\"encrypt_prompt\", resource=\"llm_client\", metadata={\"prompt_enc\": encrypted_prompt[:50]})\n        payload = self._build_payload(prompt, max_tokens, temperature)\n\n        # Log start of LLM call and audit\n        req_id = get_request_id()\n        log_entry_start = {\n            \"event\": \"llm_call_start\",\n            \"provider\": self.provider,\n            \"model\": self.model,\n            \"prompt_snippet\": prompt[:100],\n            \"request_id\": req_id,\n            \"timestamp\": time.time(),\n        }\n        logging.info(json.dumps(log_entry_start))\n        self.gov.audit(\n            user_id=\"system\",\n            action=\"llm_call_start\",\n            resource=self.provider,\n            metadata={\"model\": self.model, \"request_id\": req_id},\n        )\n\n        # Attempt with exponential backoff\n        for attempt in range(3):\n            try:\n                resp = self.session.post(self.base_url, json=payload, timeout=30)\n                if resp.status_code != 200:\n                    raise FrameworkError(f\"LLM returned status {resp.status_code}: {resp.text}\")\n                data = resp.json()\n                text, usage = self._parse_response(data)\n\n                # Log end of LLM call and audit\n                log_entry_end = {\n                    \"event\": \"llm_call_end\",\n                    \"provider\": self.provider,\n                    \"model\": self.model,\n                    \"usage\": usage,\n                    \"request_id\": req_id,\n                    \"timestamp\": time.time(),\n                }\n                logging.info(json.dumps(log_entry_end))\n                self.gov.audit(\n                    user_id=\"system\",\n                    action=\"llm_call_end\",\n                    resource=self.provider,\n                    metadata={\"model\": self.model, \"usage\": usage, \"request_id\": req_id},\n                )\n\n                return {\"text\": text, \"usage\": usage, \"metadata\": {\"provider\": self.provider, \"model\": self.model}}\n\n            except Exception as e:\n                wait = 2 ** attempt\n                logging.warning(f\"LLM call failed (attempt {attempt + 1}): {e}. Retrying in {wait}s\")\n                time.sleep(wait)\n\n        raise FrameworkError(\"LLM generate() failed after 3 attempts\")\n\n    def _build_payload(self, prompt: str, max_tokens: int, temperature: float) -&gt; Dict:\n        \"\"\"Construct provider-specific payload for the API call.\"\"\"\n        if self.provider == \"openai\":\n            return {\n                \"model\": self.model,\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                \"max_tokens\": max_tokens,\n                \"temperature\": temperature\n            }\n        if self.provider == \"anthropic\":\n            return {\n                \"model\": self.model,\n                \"prompt\": prompt,\n                \"max_tokens_to_sample\": max_tokens,\n                \"temperature\": temperature\n            }\n        if self.provider == \"gemini\":\n            return {\n                \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n                \"generationConfig\": {\"maxOutputTokens\": max_tokens, \"temperature\": temperature}\n            }\n        raise FrameworkError(f\"Payload builder not implemented for '{self.provider}'\")\n\n    def _parse_response(self, data: Dict) -&gt; (str, Dict):\n        \"\"\"Extract generated text and usage info from API response.\"\"\"\n        if self.provider == \"openai\":\n            choice = data.get(\"choices\", [])[0]\n            return choice.get(\"message\", {}).get(\"content\", \"\"), data.get(\"usage\", {})\n        if self.provider == \"anthropic\":\n            return data.get(\"completion\", \"\"), {\n                \"prompt_tokens\": data.get(\"prompt_tokens\"),\n                \"completion_tokens\": data.get(\"completion_tokens\")\n            }\n        if self.provider == \"gemini\":\n            text = (\n                data.get(\"candidates\", [{}])[0]\n                .get(\"content\", {})\n                .get(\"parts\", [{}])[0]\n                .get(\"text\", \"\")\n            )\n            usage = data.get(\"usageMetadata\", {})\n            return text, {\n                \"prompt_tokens\": usage.get(\"promptTokenCount\"),\n                \"completion_tokens\": usage.get(\"candidatesTokenCount\"),\n            }\n        raise FrameworkError(f\"Response parser not implemented for '{self.provider}'\")\n</code></pre>"},{"location":"api/core/#safeagent.llm_client.LLMClient.__init__","title":"<code>__init__(provider, api_key, model, base_url=None)</code>","text":"<p>Initialize the LLM client.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>Name of the provider (e.g., 'openai', 'anthropic').</p> required <code>api_key</code> <code>str</code> <p>API key or token for authentication.</p> required <code>model</code> <code>str</code> <p>Model identifier (e.g., 'gpt-4', 'claude-3-opus').</p> required <code>base_url</code> <code>str</code> <p>Custom endpoint URL; defaults to provider-specific default.</p> <code>None</code> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>def __init__(self, provider: str, api_key: str, model: str, base_url: str = None):\n    \"\"\"\n    Initialize the LLM client.\n\n    Args:\n        provider (str): Name of the provider (e.g., 'openai', 'anthropic').\n        api_key (str): API key or token for authentication.\n        model (str): Model identifier (e.g., 'gpt-4', 'claude-3-opus').\n        base_url (str, optional): Custom endpoint URL; defaults to provider-specific default.\n    \"\"\"\n    self.provider = provider\n    self.api_key = api_key\n    self.model = model\n    self.base_url = base_url or self._default_url()\n    if requests is not None:\n        self.session = requests.Session()\n    else:\n        class _DummySession:\n            def __init__(self):\n                self.headers = {}\n\n            def post(self, *_, **__):\n                raise FrameworkError(\"requests package is required for HTTP calls\")\n\n        self.session = _DummySession()\n    self.session.headers.update({\n        \"Authorization\": f\"Bearer {self.api_key}\",\n        \"Content-Type\": \"application/json\"\n    })\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"api/core/#safeagent.llm_client.LLMClient.generate","title":"<code>generate(prompt, max_tokens=512, temperature=0.7)</code>","text":"<p>Call the underlying LLM API, with up to 3 retries.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The textual prompt to send to the model.</p> required <code>max_tokens</code> <code>int</code> <p>Maximum number of tokens in the response.</p> <code>512</code> <code>temperature</code> <code>float</code> <p>Sampling temperature.</p> <code>0.7</code> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>A dictionary containing keys 'text', 'usage', and 'metadata'.</p> <p>Raises:</p> Type Description <code>FrameworkError</code> <p>If the API fails after retries.</p> Source code in <code>src\\safeagent\\llm_client.py</code> <pre><code>def generate(self, prompt: str, max_tokens: int = 512, temperature: float = 0.7) -&gt; Dict:\n    \"\"\"\n    Call the underlying LLM API, with up to 3 retries.\n\n    Args:\n        prompt (str): The textual prompt to send to the model.\n        max_tokens (int): Maximum number of tokens in the response.\n        temperature (float): Sampling temperature.\n\n    Returns:\n        Dict: A dictionary containing keys 'text', 'usage', and 'metadata'.\n\n    Raises:\n        FrameworkError: If the API fails after retries.\n    \"\"\"\n    # Encrypt the prompt before logging\n    encrypted_prompt = self.gov.encrypt(prompt)\n    self.gov.audit(user_id=\"system\", action=\"encrypt_prompt\", resource=\"llm_client\", metadata={\"prompt_enc\": encrypted_prompt[:50]})\n    payload = self._build_payload(prompt, max_tokens, temperature)\n\n    # Log start of LLM call and audit\n    req_id = get_request_id()\n    log_entry_start = {\n        \"event\": \"llm_call_start\",\n        \"provider\": self.provider,\n        \"model\": self.model,\n        \"prompt_snippet\": prompt[:100],\n        \"request_id\": req_id,\n        \"timestamp\": time.time(),\n    }\n    logging.info(json.dumps(log_entry_start))\n    self.gov.audit(\n        user_id=\"system\",\n        action=\"llm_call_start\",\n        resource=self.provider,\n        metadata={\"model\": self.model, \"request_id\": req_id},\n    )\n\n    # Attempt with exponential backoff\n    for attempt in range(3):\n        try:\n            resp = self.session.post(self.base_url, json=payload, timeout=30)\n            if resp.status_code != 200:\n                raise FrameworkError(f\"LLM returned status {resp.status_code}: {resp.text}\")\n            data = resp.json()\n            text, usage = self._parse_response(data)\n\n            # Log end of LLM call and audit\n            log_entry_end = {\n                \"event\": \"llm_call_end\",\n                \"provider\": self.provider,\n                \"model\": self.model,\n                \"usage\": usage,\n                \"request_id\": req_id,\n                \"timestamp\": time.time(),\n            }\n            logging.info(json.dumps(log_entry_end))\n            self.gov.audit(\n                user_id=\"system\",\n                action=\"llm_call_end\",\n                resource=self.provider,\n                metadata={\"model\": self.model, \"usage\": usage, \"request_id\": req_id},\n            )\n\n            return {\"text\": text, \"usage\": usage, \"metadata\": {\"provider\": self.provider, \"model\": self.model}}\n\n        except Exception as e:\n            wait = 2 ** attempt\n            logging.warning(f\"LLM call failed (attempt {attempt + 1}): {e}. Retrying in {wait}s\")\n            time.sleep(wait)\n\n    raise FrameworkError(\"LLM generate() failed after 3 attempts\")\n</code></pre>"},{"location":"api/core/#safeagentmemory_manager","title":"<code>safeagent.memory_manager</code>","text":""},{"location":"api/core/#safeagent.memory_manager.MemoryManager","title":"<code>MemoryManager</code>","text":"<p>Minimal key-value memory store. Supports 'inmemory' or 'redis' backends and logs each read/write. Optionally, can summarize entire memory via an LLM.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>class MemoryManager:\n    \"\"\"\n    Minimal key-value memory store.\n    Supports 'inmemory' or 'redis' backends and logs each read/write.\n    Optionally, can summarize entire memory via an LLM.\n    \"\"\"\n\n    def __init__(self, backend: str = \"inmemory\", redis_url: str = None):\n        \"\"\"\n        backend: \"inmemory\" (default) or \"redis\".\n        redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".\n        \"\"\"\n        global _redis\n        if backend == \"redis\":\n            if _redis is None:\n                import redis as _redis\n            self.client = _redis.from_url(redis_url)\n            self.backend = \"redis\"\n        else:\n            self.store = {}  # {user_id: {key: value}}\n            self.backend = \"inmemory\"\n\n    def save(self, user_id: str, key: str, value: str) -&gt; None:\n        \"\"\"Saves value under (user_id, key).\"\"\"\n        if self.backend == \"redis\":\n            self.client.hset(user_id, key, value)\n        else:\n            self.store.setdefault(user_id, {})[key] = value\n\n        logging.info(json.dumps({\n            \"event\": \"memory_save\",\n            \"user_id\": user_id,\n            \"key\": key,\n            \"request_id\": get_request_id(),\n            \"timestamp\": time.time(),\n        }))\n\n    def load(self, user_id: str, key: str) -&gt; str:\n        \"\"\"Loads value for (user_id, key). Returns empty string if missing.\"\"\"\n        if self.backend == \"redis\":\n            raw = self.client.hget(user_id, key)\n            if isinstance(raw, bytes):\n                value = raw.decode(\"utf-8\")\n            elif raw is None:\n                value = \"\"\n            else:\n                value = str(raw)\n        else:\n            value = self.store.get(user_id, {}).get(key, \"\")\n\n        logging.info(json.dumps({\n            \"event\": \"memory_load\",\n            \"user_id\": user_id,\n            \"key\": key,\n            \"request_id\": get_request_id(),\n            \"timestamp\": time.time(),\n        }))\n        return value\n\n    def summarize(self, user_id: str, embed_fn, llm_client, max_tokens: int = 256) -&gt; str:\n        \"\"\"\n        Reads all entries for user_id, concatenates them, and calls LLM to generate a summary.\n        Stores the summary under key=\"summary\" and returns it.\n        \"\"\"\n        if self.backend == \"redis\":\n            all_vals = [v.decode(\"utf-8\") for v in self.client.hvals(user_id)]\n        else:\n            all_vals = list(self.store.get(user_id, {}).values())\n\n        full_text = \"\\n\".join(all_vals)\n        if not full_text:\n            return \"\"\n\n        summary_prompt = f\"Summarize the following conversation history:\\n\\n{full_text}\"\n        resp = llm_client.generate(summary_prompt, max_tokens=max_tokens)\n        summary = resp[\"text\"]\n\n        # Save summary back to memory\n        self.save(user_id, \"summary\", summary)\n        return summary\n</code></pre>"},{"location":"api/core/#safeagent.memory_manager.MemoryManager.__init__","title":"<code>__init__(backend='inmemory', redis_url=None)</code>","text":"<p>backend: \"inmemory\" (default) or \"redis\". redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def __init__(self, backend: str = \"inmemory\", redis_url: str = None):\n    \"\"\"\n    backend: \"inmemory\" (default) or \"redis\".\n    redis_url: e.g., \"redis://localhost:6379\" if backend=\"redis\".\n    \"\"\"\n    global _redis\n    if backend == \"redis\":\n        if _redis is None:\n            import redis as _redis\n        self.client = _redis.from_url(redis_url)\n        self.backend = \"redis\"\n    else:\n        self.store = {}  # {user_id: {key: value}}\n        self.backend = \"inmemory\"\n</code></pre>"},{"location":"api/core/#safeagent.memory_manager.MemoryManager.load","title":"<code>load(user_id, key)</code>","text":"<p>Loads value for (user_id, key). Returns empty string if missing.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def load(self, user_id: str, key: str) -&gt; str:\n    \"\"\"Loads value for (user_id, key). Returns empty string if missing.\"\"\"\n    if self.backend == \"redis\":\n        raw = self.client.hget(user_id, key)\n        if isinstance(raw, bytes):\n            value = raw.decode(\"utf-8\")\n        elif raw is None:\n            value = \"\"\n        else:\n            value = str(raw)\n    else:\n        value = self.store.get(user_id, {}).get(key, \"\")\n\n    logging.info(json.dumps({\n        \"event\": \"memory_load\",\n        \"user_id\": user_id,\n        \"key\": key,\n        \"request_id\": get_request_id(),\n        \"timestamp\": time.time(),\n    }))\n    return value\n</code></pre>"},{"location":"api/core/#safeagent.memory_manager.MemoryManager.save","title":"<code>save(user_id, key, value)</code>","text":"<p>Saves value under (user_id, key).</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def save(self, user_id: str, key: str, value: str) -&gt; None:\n    \"\"\"Saves value under (user_id, key).\"\"\"\n    if self.backend == \"redis\":\n        self.client.hset(user_id, key, value)\n    else:\n        self.store.setdefault(user_id, {})[key] = value\n\n    logging.info(json.dumps({\n        \"event\": \"memory_save\",\n        \"user_id\": user_id,\n        \"key\": key,\n        \"request_id\": get_request_id(),\n        \"timestamp\": time.time(),\n    }))\n</code></pre>"},{"location":"api/core/#safeagent.memory_manager.MemoryManager.summarize","title":"<code>summarize(user_id, embed_fn, llm_client, max_tokens=256)</code>","text":"<p>Reads all entries for user_id, concatenates them, and calls LLM to generate a summary. Stores the summary under key=\"summary\" and returns it.</p> Source code in <code>src\\safeagent\\memory_manager.py</code> <pre><code>def summarize(self, user_id: str, embed_fn, llm_client, max_tokens: int = 256) -&gt; str:\n    \"\"\"\n    Reads all entries for user_id, concatenates them, and calls LLM to generate a summary.\n    Stores the summary under key=\"summary\" and returns it.\n    \"\"\"\n    if self.backend == \"redis\":\n        all_vals = [v.decode(\"utf-8\") for v in self.client.hvals(user_id)]\n    else:\n        all_vals = list(self.store.get(user_id, {}).values())\n\n    full_text = \"\\n\".join(all_vals)\n    if not full_text:\n        return \"\"\n\n    summary_prompt = f\"Summarize the following conversation history:\\n\\n{full_text}\"\n    resp = llm_client.generate(summary_prompt, max_tokens=max_tokens)\n    summary = resp[\"text\"]\n\n    # Save summary back to memory\n    self.save(user_id, \"summary\", summary)\n    return summary\n</code></pre>"},{"location":"api/core/#safeagentprompt_renderer","title":"<code>safeagent.prompt_renderer</code>","text":""},{"location":"api/core/#safeagent.prompt_renderer.PromptRenderer","title":"<code>PromptRenderer</code>","text":"<p>Jinja2-based templating engine with structured logging and lineage tagging.</p> Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>class PromptRenderer:\n    \"\"\"Jinja2-based templating engine with structured logging and lineage tagging.\"\"\"\n\n    def __init__(self, template_dir: Path):\n        \"\"\"\n        Args:\n            template_dir (Path): Path to the directory containing Jinja2 templates.\n        \"\"\"\n        self.env = jinja2.Environment(\n            loader=jinja2.FileSystemLoader(str(template_dir)),\n            autoescape=False\n        )\n        self.gov = GovernanceManager()\n\n    def render(self, template_name: str, **context) -&gt; str:\n        \"\"\"\n        Render a Jinja2 template with provided context, logging the event and tagging lineage.\n\n        Args:\n            template_name (str): Filename of the template (e.g., 'qa_prompt.j2').\n            **context: Key-value pairs to pass into the template rendering.\n\n        Returns:\n            str: The rendered template as a string.\n        \"\"\"\n        # Audit prompt render\n        lineage_metadata = {\"template\": template_name, \"context_keys\": list(context.keys())}\n        self.gov.audit(user_id=\"system\", action=\"prompt_render\", resource=template_name, metadata=lineage_metadata)\n\n        template = self.env.get_template(template_name)\n        rendered = template.render(**context)\n        log_entry = {\n            \"event\": \"prompt_render\",\n            \"template\": template_name,\n            \"context_keys\": list(context.keys()),\n            \"output_length\": len(rendered),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return rendered\n</code></pre>"},{"location":"api/core/#safeagent.prompt_renderer.PromptRenderer.__init__","title":"<code>__init__(template_dir)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>template_dir</code> <code>Path</code> <p>Path to the directory containing Jinja2 templates.</p> required Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>def __init__(self, template_dir: Path):\n    \"\"\"\n    Args:\n        template_dir (Path): Path to the directory containing Jinja2 templates.\n    \"\"\"\n    self.env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(str(template_dir)),\n        autoescape=False\n    )\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"api/core/#safeagent.prompt_renderer.PromptRenderer.render","title":"<code>render(template_name, **context)</code>","text":"<p>Render a Jinja2 template with provided context, logging the event and tagging lineage.</p> <p>Parameters:</p> Name Type Description Default <code>template_name</code> <code>str</code> <p>Filename of the template (e.g., 'qa_prompt.j2').</p> required <code>**context</code> <p>Key-value pairs to pass into the template rendering.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The rendered template as a string.</p> Source code in <code>src\\safeagent\\prompt_renderer.py</code> <pre><code>def render(self, template_name: str, **context) -&gt; str:\n    \"\"\"\n    Render a Jinja2 template with provided context, logging the event and tagging lineage.\n\n    Args:\n        template_name (str): Filename of the template (e.g., 'qa_prompt.j2').\n        **context: Key-value pairs to pass into the template rendering.\n\n    Returns:\n        str: The rendered template as a string.\n    \"\"\"\n    # Audit prompt render\n    lineage_metadata = {\"template\": template_name, \"context_keys\": list(context.keys())}\n    self.gov.audit(user_id=\"system\", action=\"prompt_render\", resource=template_name, metadata=lineage_metadata)\n\n    template = self.env.get_template(template_name)\n    rendered = template.render(**context)\n    log_entry = {\n        \"event\": \"prompt_render\",\n        \"template\": template_name,\n        \"context_keys\": list(context.keys()),\n        \"output_length\": len(rendered),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return rendered\n</code></pre>"},{"location":"api/core/#safeagentembeddings","title":"<code>safeagent.embeddings</code>","text":""},{"location":"api/core/#safeagent.embeddings.gemini_embed","title":"<code>gemini_embed(text, api_key, model='embedding-001')</code>","text":"<p>Return an embedding vector from the Gemini embedding API.</p> Source code in <code>src\\safeagent\\embeddings.py</code> <pre><code>def gemini_embed(text: str, api_key: str, model: str = \"embedding-001\") -&gt; List[float]:\n    \"\"\"Return an embedding vector from the Gemini embedding API.\"\"\"\n    url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model}:embedContent?key={api_key}\"\n    payload = {\"content\": {\"parts\": [{\"text\": text}]}}\n    resp = _session.post(url, json=payload, timeout=30)\n    if resp.status_code != 200:\n        raise RuntimeError(f\"Gemini embed failed: {resp.text}\")\n    data = resp.json()\n    return data.get(\"embedding\", {}).get(\"values\", [])\n</code></pre>"},{"location":"api/core/#safeagentretriever","title":"<code>safeagent.retriever</code>","text":""},{"location":"api/core/#safeagent.retriever.BaseRetriever","title":"<code>BaseRetriever</code>","text":"<p>Base interface for retrieval. Requires implementing index and query.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class BaseRetriever:\n    \"\"\"Base interface for retrieval. Requires implementing index and query.\"\"\"\n    def index(self, embeddings: List[Any], metadata: List[Dict[str, Any]]) -&gt; None:\n        raise NotImplementedError\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        raise NotImplementedError\n</code></pre>"},{"location":"api/core/#safeagent.retriever.GraphRetriever","title":"<code>GraphRetriever</code>","text":"<p>               Bases: <code>BaseRetriever</code></p> <p>Neo4j-backed GraphRAG retriever using GDS k-NN, with governance integration.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class GraphRetriever(BaseRetriever):\n    \"\"\"Neo4j-backed GraphRAG retriever using GDS k-NN, with governance integration.\"\"\"\n\n    def __init__(self, neo4j_uri: str, user: str, password: str, gds_graph_name: str, embed_model_fn):\n        \"\"\"Create the retriever.\n\n        Args:\n            neo4j_uri (str): Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').\n            user (str): Username for Neo4j.\n            password (str): Password for Neo4j.\n            gds_graph_name (str): Name of the GDS graph projection in Neo4j.\n            embed_model_fn (callable): Function mapping text to an embedding vector.\n        \"\"\"\n        from neo4j import GraphDatabase\n\n        self.driver = GraphDatabase.driver(neo4j_uri, auth=(user, password))\n        self.gds_graph = gds_graph_name\n        self.embed = embed_model_fn\n        self.gov = GovernanceManager()\n\n    def index(self, embeddings: List[List[float]], metadata: List[Dict[str, Any]]):\n        \"\"\"\n        Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).\n\n        Args:\n            embeddings (List[List[float]]): List of embedding vectors.\n            metadata (List[Dict[str, Any]]): List of metadata dicts (must include 'id').\n        \"\"\"\n        self.gov.audit(user_id=\"system\", action=\"graph_index\", resource=\"neo4j\", metadata={\"count\": len(embeddings)})\n        with self.driver.session() as session:\n            for vec, meta in zip(embeddings, metadata):\n                tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_index\")\n                session.run(\n                    \"MERGE (d:Document {id: $id}) \"\n                    \"SET d.vector = $vector, d.metadata = $meta\",\n                    id=meta[\"id\"], vector=vec, meta=tagged_meta\n                )\n        log_entry = {\n            \"event\": \"graph_index\",\n            \"count\": len(embeddings),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).\n\n        Args:\n            query_text (str): The query string.\n            top_k (int): Number of nearest neighbors to return.\n\n        Returns:\n            List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n        \"\"\"\n        # Encrypt and audit query\n        encrypted_query = self.gov.encrypt(query_text)\n        self.gov.audit(user_id=\"system\", action=\"graph_query\", resource=\"neo4j\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n        vec = self._compute_embedding(query_text)\n        cypher = f\"\"\"\n            CALL gds.knn.query(\n                '{self.gds_graph}',\n                $vector,\n                {{k: $k}}\n            ) YIELD nodeId, similarity\n            RETURN gds.util.asNode(nodeId).id AS id, similarity\n        \"\"\"\n        results = []\n        with self.driver.session() as session:\n            for record in session.run(cypher, vector=vec, k=top_k):\n                node_id = record[\"id\"]\n                score = record[\"similarity\"]\n                meta = session.run(\n                    \"MATCH (d:Document {id: $id}) RETURN d.metadata AS meta\", id=node_id\n                ).single()[\"meta\"]\n                tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_query\")\n                results.append({\"id\": node_id, \"score\": score, \"metadata\": tagged_meta})\n\n        log_entry = {\n            \"event\": \"graph_query\",\n            \"top_k\": top_k,\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return results\n\n    def _compute_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"Return an embedding for ``text`` via the provided embedding function.\"\"\"\n        return self.embed(text)\n</code></pre>"},{"location":"api/core/#safeagent.retriever.GraphRetriever.__init__","title":"<code>__init__(neo4j_uri, user, password, gds_graph_name, embed_model_fn)</code>","text":"<p>Create the retriever.</p> <p>Parameters:</p> Name Type Description Default <code>neo4j_uri</code> <code>str</code> <p>Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').</p> required <code>user</code> <code>str</code> <p>Username for Neo4j.</p> required <code>password</code> <code>str</code> <p>Password for Neo4j.</p> required <code>gds_graph_name</code> <code>str</code> <p>Name of the GDS graph projection in Neo4j.</p> required <code>embed_model_fn</code> <code>callable</code> <p>Function mapping text to an embedding vector.</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def __init__(self, neo4j_uri: str, user: str, password: str, gds_graph_name: str, embed_model_fn):\n    \"\"\"Create the retriever.\n\n    Args:\n        neo4j_uri (str): Bolt URI for Neo4j (e.g., 'bolt://localhost:7687').\n        user (str): Username for Neo4j.\n        password (str): Password for Neo4j.\n        gds_graph_name (str): Name of the GDS graph projection in Neo4j.\n        embed_model_fn (callable): Function mapping text to an embedding vector.\n    \"\"\"\n    from neo4j import GraphDatabase\n\n    self.driver = GraphDatabase.driver(neo4j_uri, auth=(user, password))\n    self.gds_graph = gds_graph_name\n    self.embed = embed_model_fn\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"api/core/#safeagent.retriever.GraphRetriever.index","title":"<code>index(embeddings, metadata)</code>","text":"<p>Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>List[List[float]]</code> <p>List of embedding vectors.</p> required <code>metadata</code> <code>List[Dict[str, Any]]</code> <p>List of metadata dicts (must include 'id').</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def index(self, embeddings: List[List[float]], metadata: List[Dict[str, Any]]):\n    \"\"\"\n    Ingest each document as a node with a 'vector' property and 'metadata' (with lineage tagging).\n\n    Args:\n        embeddings (List[List[float]]): List of embedding vectors.\n        metadata (List[Dict[str, Any]]): List of metadata dicts (must include 'id').\n    \"\"\"\n    self.gov.audit(user_id=\"system\", action=\"graph_index\", resource=\"neo4j\", metadata={\"count\": len(embeddings)})\n    with self.driver.session() as session:\n        for vec, meta in zip(embeddings, metadata):\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_index\")\n            session.run(\n                \"MERGE (d:Document {id: $id}) \"\n                \"SET d.vector = $vector, d.metadata = $meta\",\n                id=meta[\"id\"], vector=vec, meta=tagged_meta\n            )\n    log_entry = {\n        \"event\": \"graph_index\",\n        \"count\": len(embeddings),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n</code></pre>"},{"location":"api/core/#safeagent.retriever.GraphRetriever.query","title":"<code>query(query_text, top_k=5)</code>","text":"<p>Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>query_text</code> <code>str</code> <p>The query string.</p> required <code>top_k</code> <code>int</code> <p>Number of nearest neighbors to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Compute embedding for query_text, run GDS K-NN, and return nearest documents (with lineage tagging).\n\n    Args:\n        query_text (str): The query string.\n        top_k (int): Number of nearest neighbors to return.\n\n    Returns:\n        List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n    \"\"\"\n    # Encrypt and audit query\n    encrypted_query = self.gov.encrypt(query_text)\n    self.gov.audit(user_id=\"system\", action=\"graph_query\", resource=\"neo4j\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n    vec = self._compute_embedding(query_text)\n    cypher = f\"\"\"\n        CALL gds.knn.query(\n            '{self.gds_graph}',\n            $vector,\n            {{k: $k}}\n        ) YIELD nodeId, similarity\n        RETURN gds.util.asNode(nodeId).id AS id, similarity\n    \"\"\"\n    results = []\n    with self.driver.session() as session:\n        for record in session.run(cypher, vector=vec, k=top_k):\n            node_id = record[\"id\"]\n            score = record[\"similarity\"]\n            meta = session.run(\n                \"MATCH (d:Document {id: $id}) RETURN d.metadata AS meta\", id=node_id\n            ).single()[\"meta\"]\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"graph_query\")\n            results.append({\"id\": node_id, \"score\": score, \"metadata\": tagged_meta})\n\n    log_entry = {\n        \"event\": \"graph_query\",\n        \"top_k\": top_k,\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return results\n</code></pre>"},{"location":"api/core/#safeagent.retriever.VectorRetriever","title":"<code>VectorRetriever</code>","text":"<p>               Bases: <code>BaseRetriever</code></p> <p>FAISS-backed vector retriever. Uses an embedding function to map text to vectors, with governance integration.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>class VectorRetriever(BaseRetriever):\n    \"\"\"FAISS-backed vector retriever. Uses an embedding function to map text to vectors, with governance integration.\"\"\"\n    def __init__(self, index_path: str, embed_model_fn):\n        \"\"\"\n        Args:\n            index_path (str): Filesystem path to store/load FAISS index.\n            embed_model_fn (callable): Function that maps text (str) to a numpy ndarray vector.\n        \"\"\"\n        self.embed = embed_model_fn\n        self.gov = GovernanceManager()\n        self.metadata_store: Dict[int, Dict[str, Any]] = {}\n        self.next_id = 0\n        self.index_path = index_path\n        if _FAISS:\n            if Path(index_path).exists():\n                self._index = faiss.read_index(index_path)\n            else:\n                self._index = faiss.IndexFlatL2(768)\n        else:\n            self._index = []  # type: ignore\n\n    def index(self, embeddings: List[np.ndarray], metadata: List[Dict[str, Any]]):\n        \"\"\"\n        Add embeddings to the FAISS index and store metadata (with lineage tagging).\n\n        Args:\n            embeddings (List[np.ndarray]): List of vectors.\n            metadata (List[Dict[str, Any]]): Corresponding metadata dicts (must include 'id').\n        \"\"\"\n        if _FAISS:\n            vectors = np.vstack(embeddings)\n            self._index.add(vectors)\n        else:\n            for vec in embeddings:\n                self._index.append(np.array(vec))\n        for vec, meta in zip(embeddings, metadata):\n            tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"vector_index\")\n            self.metadata_store[self.next_id] = tagged_meta\n            self.next_id += 1\n\n        log_entry = {\n            \"event\": \"vector_index\",\n            \"count\": len(embeddings),\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        if _FAISS:\n            faiss.write_index(self._index, self.index_path)\n\n    def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Perform KNN search on the FAISS index using the embedded query, with encryption and audit.\n\n        Args:\n            query_text (str): The query string.\n            top_k (int): Number of nearest neighbors to return.\n\n        Returns:\n            List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n        \"\"\"\n        # Encrypt and audit query\n        encrypted_query = self.gov.encrypt(query_text)\n        self.gov.audit(user_id=\"system\", action=\"vector_query\", resource=\"faiss\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n        vec = self.embed(query_text)\n        if _FAISS:\n            distances, indices = self._index.search(np.array([vec]), top_k)\n            idx_list = indices[0]\n            dist_list = distances[0]\n        else:\n            if not self._index:\n                idx_list, dist_list = [], []\n            else:\n                def dist(a, b):\n                    return sum((ai - bi) ** 2 for ai, bi in zip(a, b)) ** 0.5\n\n                dists = [dist(v, vec) for v in self._index]\n                sorted_idx = sorted(range(len(dists)), key=lambda i: dists[i])[:top_k]\n                idx_list = sorted_idx\n                dist_list = [dists[i] for i in sorted_idx]\n        results = []\n        for idx, dist in zip(idx_list, dist_list):\n            meta = self.metadata_store.get(int(idx), {})\n            results.append({\"id\": int(idx), \"score\": float(dist), \"metadata\": meta})\n\n        log_entry = {\n            \"event\": \"vector_query\",\n            \"top_k\": top_k,\n            \"timestamp\": time.time()\n        }\n        logging.info(json.dumps(log_entry))\n        return results\n</code></pre>"},{"location":"api/core/#safeagent.retriever.VectorRetriever.__init__","title":"<code>__init__(index_path, embed_model_fn)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>index_path</code> <code>str</code> <p>Filesystem path to store/load FAISS index.</p> required <code>embed_model_fn</code> <code>callable</code> <p>Function that maps text (str) to a numpy ndarray vector.</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def __init__(self, index_path: str, embed_model_fn):\n    \"\"\"\n    Args:\n        index_path (str): Filesystem path to store/load FAISS index.\n        embed_model_fn (callable): Function that maps text (str) to a numpy ndarray vector.\n    \"\"\"\n    self.embed = embed_model_fn\n    self.gov = GovernanceManager()\n    self.metadata_store: Dict[int, Dict[str, Any]] = {}\n    self.next_id = 0\n    self.index_path = index_path\n    if _FAISS:\n        if Path(index_path).exists():\n            self._index = faiss.read_index(index_path)\n        else:\n            self._index = faiss.IndexFlatL2(768)\n    else:\n        self._index = []  # type: ignore\n</code></pre>"},{"location":"api/core/#safeagent.retriever.VectorRetriever.index","title":"<code>index(embeddings, metadata)</code>","text":"<p>Add embeddings to the FAISS index and store metadata (with lineage tagging).</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>List[ndarray]</code> <p>List of vectors.</p> required <code>metadata</code> <code>List[Dict[str, Any]]</code> <p>Corresponding metadata dicts (must include 'id').</p> required Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def index(self, embeddings: List[np.ndarray], metadata: List[Dict[str, Any]]):\n    \"\"\"\n    Add embeddings to the FAISS index and store metadata (with lineage tagging).\n\n    Args:\n        embeddings (List[np.ndarray]): List of vectors.\n        metadata (List[Dict[str, Any]]): Corresponding metadata dicts (must include 'id').\n    \"\"\"\n    if _FAISS:\n        vectors = np.vstack(embeddings)\n        self._index.add(vectors)\n    else:\n        for vec in embeddings:\n            self._index.append(np.array(vec))\n    for vec, meta in zip(embeddings, metadata):\n        tagged_meta = self.gov.tag_lineage(meta.copy(), source=\"vector_index\")\n        self.metadata_store[self.next_id] = tagged_meta\n        self.next_id += 1\n\n    log_entry = {\n        \"event\": \"vector_index\",\n        \"count\": len(embeddings),\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    if _FAISS:\n        faiss.write_index(self._index, self.index_path)\n</code></pre>"},{"location":"api/core/#safeagent.retriever.VectorRetriever.query","title":"<code>query(query_text, top_k=5)</code>","text":"<p>Perform KNN search on the FAISS index using the embedded query, with encryption and audit.</p> <p>Parameters:</p> Name Type Description Default <code>query_text</code> <code>str</code> <p>The query string.</p> required <code>top_k</code> <code>int</code> <p>Number of nearest neighbors to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def query(self, query_text: str, top_k: int = 5) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Perform KNN search on the FAISS index using the embedded query, with encryption and audit.\n\n    Args:\n        query_text (str): The query string.\n        top_k (int): Number of nearest neighbors to return.\n\n    Returns:\n        List[Dict[str, Any]]: Each dict contains 'id', 'score', and 'metadata'.\n    \"\"\"\n    # Encrypt and audit query\n    encrypted_query = self.gov.encrypt(query_text)\n    self.gov.audit(user_id=\"system\", action=\"vector_query\", resource=\"faiss\", metadata={\"query_enc\": encrypted_query[:50], \"top_k\": top_k})\n\n    vec = self.embed(query_text)\n    if _FAISS:\n        distances, indices = self._index.search(np.array([vec]), top_k)\n        idx_list = indices[0]\n        dist_list = distances[0]\n    else:\n        if not self._index:\n            idx_list, dist_list = [], []\n        else:\n            def dist(a, b):\n                return sum((ai - bi) ** 2 for ai, bi in zip(a, b)) ** 0.5\n\n            dists = [dist(v, vec) for v in self._index]\n            sorted_idx = sorted(range(len(dists)), key=lambda i: dists[i])[:top_k]\n            idx_list = sorted_idx\n            dist_list = [dists[i] for i in sorted_idx]\n    results = []\n    for idx, dist in zip(idx_list, dist_list):\n        meta = self.metadata_store.get(int(idx), {})\n        results.append({\"id\": int(idx), \"score\": float(dist), \"metadata\": meta})\n\n    log_entry = {\n        \"event\": \"vector_query\",\n        \"top_k\": top_k,\n        \"timestamp\": time.time()\n    }\n    logging.info(json.dumps(log_entry))\n    return results\n</code></pre>"},{"location":"api/core/#safeagent.retriever.register_retriever","title":"<code>register_retriever(name, cls)</code>","text":"<p>Register a retriever class for dynamic loading.</p> Source code in <code>src\\safeagent\\retriever.py</code> <pre><code>def register_retriever(name: str, cls):\n    \"\"\"Register a retriever class for dynamic loading.\"\"\"\n    RETRIEVER_REGISTRY[name] = cls\n</code></pre>"},{"location":"api/orchestrators/","title":"API: Orchestrators","text":"<p>This section covers the classes responsible for executing agent workflows.</p>"},{"location":"api/orchestrators/#safeagentorchestrator","title":"<code>safeagent.orchestrator</code>","text":""},{"location":"api/orchestrators/#safeagent.orchestrator.SimpleOrchestrator","title":"<code>SimpleOrchestrator</code>","text":"<p>Minimal DAG runner: each node is a function, edges define dependencies, with audit and lineage tagging.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>class SimpleOrchestrator:\n    \"\"\"Minimal DAG runner: each node is a function, edges define dependencies, with audit and lineage tagging.\"\"\"\n\n    def __init__(self):\n        # Map node name to function\n        self.nodes: Dict[str, Callable[..., Any]] = {}\n        # Map node name to list of dependent node names\n        self.edges: Dict[str, List[str]] = {}\n        self.gov = GovernanceManager()\n\n    def add_node(self, name: str, func: Callable[..., Any]):\n        \"\"\"Register a function under the given node name.\"\"\"\n        self.nodes[name] = func\n        self.edges.setdefault(name, [])\n\n    def add_edge(self, src: str, dest: str):\n        \"\"\"Specify that 'dest' depends on 'src'.\"\"\"\n        if src not in self.nodes or dest not in self.nodes:\n            raise ValueError(f\"Either '{src}' or '{dest}' is not registered as a node.\")\n        self.edges[src].append(dest)\n\n    def run(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"\n        Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.\n\n        Args:\n            inputs (Dict[str, Any]): Global inputs (e.g., 'user_input', 'user_id').\n\n        Returns:\n            Dict[str, Any]: Mapping of node name to its return value.\n        \"\"\"\n        results: Dict[str, Any] = {}\n        visited = set()\n\n        # Audit pipeline start\n        self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_start\", resource=\"orchestrator\")\n\n        def execute(node: str):\n            if node in visited:\n                return results.get(node)\n            visited.add(node)\n            func = self.nodes[node]\n            kwargs = {}\n            import inspect\n            params = inspect.signature(func).parameters\n            for name in params:\n                if name in results:\n                    kwargs[name] = results[name]\n                elif name.startswith(\"node_\") and name[5:] in results:\n                    kwargs[name] = results[name[5:]]\n                elif name in inputs:\n                    kwargs[name] = inputs[name]\n            output = func(**kwargs)\n            # Tag lineage on dict outputs\n            if isinstance(output, dict):\n                output = self.gov.tag_lineage(output, source=node)\n            results[node] = output\n            return output\n\n        for node in self.nodes:\n            execute(node)\n\n        # Audit pipeline end\n        self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_end\", resource=\"orchestrator\")\n\n        return results\n</code></pre>"},{"location":"api/orchestrators/#safeagent.orchestrator.SimpleOrchestrator.add_edge","title":"<code>add_edge(src, dest)</code>","text":"<p>Specify that 'dest' depends on 'src'.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def add_edge(self, src: str, dest: str):\n    \"\"\"Specify that 'dest' depends on 'src'.\"\"\"\n    if src not in self.nodes or dest not in self.nodes:\n        raise ValueError(f\"Either '{src}' or '{dest}' is not registered as a node.\")\n    self.edges[src].append(dest)\n</code></pre>"},{"location":"api/orchestrators/#safeagent.orchestrator.SimpleOrchestrator.add_node","title":"<code>add_node(name, func)</code>","text":"<p>Register a function under the given node name.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def add_node(self, name: str, func: Callable[..., Any]):\n    \"\"\"Register a function under the given node name.\"\"\"\n    self.nodes[name] = func\n    self.edges.setdefault(name, [])\n</code></pre>"},{"location":"api/orchestrators/#safeagent.orchestrator.SimpleOrchestrator.run","title":"<code>run(inputs)</code>","text":"<p>Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Dict[str, Any]</code> <p>Global inputs (e.g., 'user_input', 'user_id').</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Mapping of node name to its return value.</p> Source code in <code>src\\safeagent\\orchestrator.py</code> <pre><code>def run(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"\n    Execute all nodes in topological order, audit pipeline start/end, and tag lineage on outputs.\n\n    Args:\n        inputs (Dict[str, Any]): Global inputs (e.g., 'user_input', 'user_id').\n\n    Returns:\n        Dict[str, Any]: Mapping of node name to its return value.\n    \"\"\"\n    results: Dict[str, Any] = {}\n    visited = set()\n\n    # Audit pipeline start\n    self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_start\", resource=\"orchestrator\")\n\n    def execute(node: str):\n        if node in visited:\n            return results.get(node)\n        visited.add(node)\n        func = self.nodes[node]\n        kwargs = {}\n        import inspect\n        params = inspect.signature(func).parameters\n        for name in params:\n            if name in results:\n                kwargs[name] = results[name]\n            elif name.startswith(\"node_\") and name[5:] in results:\n                kwargs[name] = results[name[5:]]\n            elif name in inputs:\n                kwargs[name] = inputs[name]\n        output = func(**kwargs)\n        # Tag lineage on dict outputs\n        if isinstance(output, dict):\n            output = self.gov.tag_lineage(output, source=node)\n        results[node] = output\n        return output\n\n    for node in self.nodes:\n        execute(node)\n\n    # Audit pipeline end\n    self.gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"pipeline_end\", resource=\"orchestrator\")\n\n    return results\n</code></pre>"},{"location":"api/orchestrators/#safeagentstateful_orchestrator","title":"<code>safeagent.stateful_orchestrator</code>","text":""},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.EdgeRegistrationError","title":"<code>EdgeRegistrationError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised during an invalid attempt to register an edge.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class EdgeRegistrationError(OrchestratorError):\n    \"\"\"Raised during an invalid attempt to register an edge.\"\"\"\n    def __init__(self, node_name: str, message: str):\n        self.node_name = node_name\n        super().__init__(\"{}: '{}'\".format(message, node_name))\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.NodeNotFoundError","title":"<code>NodeNotFoundError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when a node name is not found in the graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class NodeNotFoundError(OrchestratorError):\n    \"\"\"Raised when a node name is not found in the graph.\"\"\"\n    def __init__(self, node_name: str):\n        self.node_name = node_name\n        super().__init__(\"Node '{}' not found in the graph.\".format(node_name))\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.OrchestratorError","title":"<code>OrchestratorError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for all stateful orchestrator errors.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class OrchestratorError(Exception):\n    \"\"\"Base exception for all stateful orchestrator errors.\"\"\"\n    pass\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.StateValidationError","title":"<code>StateValidationError</code>","text":"<p>               Bases: <code>OrchestratorError</code></p> <p>Raised when the state does not conform to the defined schema.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class StateValidationError(OrchestratorError):\n    \"\"\"Raised when the state does not conform to the defined schema.\"\"\"\n    def __init__(self, message: str):\n        super().__init__(message)\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.StatefulOrchestrator","title":"<code>StatefulOrchestrator</code>","text":"<p>An orchestrator that manages a central state object, allowing for complex, cyclical, and conditional workflows with integrated governance, human-in-the-loop interrupts, and optional state schema validation.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>class StatefulOrchestrator:\n    \"\"\"\n    An orchestrator that manages a central state object, allowing for complex,\n    cyclical, and conditional workflows with integrated governance, human-in-the-loop\n    interrupts, and optional state schema validation.\n    \"\"\"\n\n    def __init__(self, entry_node: str, state_schema: Optional[Dict[str, Type]] = None):\n        \"\"\"\n        Initializes the stateful orchestrator.\n\n        Args:\n            entry_node (str): The name of the first node to execute in the graph.\n            state_schema (Optional[Dict[str, Type]]): An optional schema defining\n                expected keys and their Python types in the state object.\n        \"\"\"\n        if not isinstance(entry_node, str) or not entry_node:\n            raise ValueError(\"entry_node must be a non-empty string.\")\n\n        self.nodes: Dict[str, Callable[[Dict], Dict]] = {}\n        self.edges: Dict[str, Callable[[Dict], str]] = {}\n        self.entry_node = entry_node\n        self.state_schema = state_schema\n        self.gov = GovernanceManager()\n\n    def add_node(self, name: str, func: Callable[[Dict], Dict]):\n        self.nodes[name] = func\n\n    def add_edge(self, src: str, dest: str):\n        if src not in self.nodes:\n            raise EdgeRegistrationError(src, \"Source node for edge is not registered\")\n        if dest not in self.nodes and dest not in (\"__end__\", \"__interrupt__\"):\n             raise EdgeRegistrationError(dest, \"Destination node for edge is not registered\")\n        self.edges[src] = lambda state: dest\n\n    def add_conditional_edge(self, src: str, path_func: Callable[[Dict], str]):\n        if src not in self.nodes:\n            raise EdgeRegistrationError(src, \"Source node for conditional edge is not registered\")\n        self.edges[src] = path_func\n\n    def _validate_state(self, state: Dict[str, Any], keys_to_check: List[str]):\n        \"\"\"Validates a subset of the state against the schema if it exists.\"\"\"\n        if not self.state_schema:\n            return\n\n        for key in keys_to_check:\n            if key not in self.state_schema:\n                raise StateValidationError(\"Key '{}' in state is not defined in the schema.\".format(key))\n            if key in state and not isinstance(state[key], self.state_schema[key]):\n                expected_type = self.state_schema[key].__name__\n                actual_type = type(state[key]).__name__\n                msg = \"Type mismatch for key '{}'. Expected '{}', got '{}'.\".format(key, expected_type, actual_type)\n                raise StateValidationError(msg)\n\n    def run(self, inputs: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Executes the graph starting from the entry node.\n\n        Returns:\n            A tuple containing the final status ('completed', 'paused', 'error')\n            and the final state of the graph.\n        \"\"\"\n        state = inputs.copy()\n        self._validate_state(state, list(state.keys()))\n        self.gov.audit(user_id, \"stateful_run_start\", \"StatefulOrchestrator\", {\"initial_keys\": list(state.keys())})\n\n        return self._execute_from(self.entry_node, state, user_id, max_steps)\n\n    def resume(self, state: Dict[str, Any], human_input: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n        \"\"\"\n        Resumes execution of a paused graph.\n        \"\"\"\n        if \"__next_node__\" not in state:\n            raise OrchestratorError(\"Cannot resume. The provided state is not a valid paused state.\")\n\n        next_node = state.pop(\"__next_node__\")\n        state.update(human_input)\n\n        self.gov.audit(user_id, \"graph_resume\", \"StatefulOrchestrator\", {\"resuming_at_node\": next_node, \"human_input_keys\": list(human_input.keys())})\n        self._validate_state(state, list(human_input.keys()))\n\n        return self._execute_from(next_node, state, user_id, max_steps, start_step=state.get('__step__', 0))\n\n    def _execute_from(self, start_node: str, state: Dict[str, Any], user_id: str, max_steps: int, start_step: int = 0) -&gt; Tuple[str, Dict[str, Any]]:\n        current_node_name = start_node\n\n        for step in range(start_step, max_steps):\n            if current_node_name == \"__end__\":\n                self.gov.audit(user_id, \"graph_end_reached\", \"StatefulOrchestrator\", {\"step\": step})\n                return \"completed\", state\n\n            if current_node_name == \"__interrupt__\":\n                self.gov.audit(user_id, \"graph_interrupt_human_input\", \"StatefulOrchestrator\", {\"step\": step})\n                if state['__previous_node__'] in self.edges:\n                    state[\"__next_node__\"] = self.edges[state['__previous_node__']](state)\n                    state[\"__step__\"] = step\n                return \"paused\", state\n\n            if current_node_name not in self.nodes:\n                raise NodeNotFoundError(current_node_name)\n\n            self.gov.audit(user_id, \"node_start\", current_node_name, {\"step\": step})\n            node_func = self.nodes[current_node_name]\n\n            try:\n                updates = node_func(state)\n                self._validate_state(updates, list(updates.keys()))\n\n                for key, value in updates.items():\n                    record_to_tag = value if isinstance(value, dict) else {'value': value}\n                    tagged_record = self.gov.tag_lineage(record_to_tag, source=current_node_name)\n                    state[key] = tagged_record.get('value', tagged_record)\n\n                self.gov.audit(user_id, \"node_end\", current_node_name, {\"step\": step, \"updated_keys\": list(updates.keys())})\n            except Exception as e:\n                self.gov.audit(user_id, \"node_error\", current_node_name, {\"step\": step, \"error\": str(e)})\n                raise\n\n            if current_node_name not in self.edges:\n                self.gov.audit(user_id, \"graph_path_end\", \"StatefulOrchestrator\", {\"last_node\": current_node_name})\n                return \"completed\", state\n\n            path_func = self.edges[current_node_name]\n            state[\"__previous_node__\"] = current_node_name\n            next_node_name = path_func(state)\n\n            self.gov.audit(user_id, \"conditional_edge_traversed\", current_node_name, {\"destination\": next_node_name})\n            current_node_name = next_node_name\n        else:\n             self.gov.audit(user_id, \"max_steps_reached\", \"StatefulOrchestrator\", {\"max_steps\": max_steps})\n             return \"max_steps_reached\", state\n\n        return \"completed\", state\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.StatefulOrchestrator.__init__","title":"<code>__init__(entry_node, state_schema=None)</code>","text":"<p>Initializes the stateful orchestrator.</p> <p>Parameters:</p> Name Type Description Default <code>entry_node</code> <code>str</code> <p>The name of the first node to execute in the graph.</p> required <code>state_schema</code> <code>Optional[Dict[str, Type]]</code> <p>An optional schema defining expected keys and their Python types in the state object.</p> <code>None</code> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def __init__(self, entry_node: str, state_schema: Optional[Dict[str, Type]] = None):\n    \"\"\"\n    Initializes the stateful orchestrator.\n\n    Args:\n        entry_node (str): The name of the first node to execute in the graph.\n        state_schema (Optional[Dict[str, Type]]): An optional schema defining\n            expected keys and their Python types in the state object.\n    \"\"\"\n    if not isinstance(entry_node, str) or not entry_node:\n        raise ValueError(\"entry_node must be a non-empty string.\")\n\n    self.nodes: Dict[str, Callable[[Dict], Dict]] = {}\n    self.edges: Dict[str, Callable[[Dict], str]] = {}\n    self.entry_node = entry_node\n    self.state_schema = state_schema\n    self.gov = GovernanceManager()\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.StatefulOrchestrator.resume","title":"<code>resume(state, human_input, user_id='system', max_steps=15)</code>","text":"<p>Resumes execution of a paused graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def resume(self, state: Dict[str, Any], human_input: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Resumes execution of a paused graph.\n    \"\"\"\n    if \"__next_node__\" not in state:\n        raise OrchestratorError(\"Cannot resume. The provided state is not a valid paused state.\")\n\n    next_node = state.pop(\"__next_node__\")\n    state.update(human_input)\n\n    self.gov.audit(user_id, \"graph_resume\", \"StatefulOrchestrator\", {\"resuming_at_node\": next_node, \"human_input_keys\": list(human_input.keys())})\n    self._validate_state(state, list(human_input.keys()))\n\n    return self._execute_from(next_node, state, user_id, max_steps, start_step=state.get('__step__', 0))\n</code></pre>"},{"location":"api/orchestrators/#safeagent.stateful_orchestrator.StatefulOrchestrator.run","title":"<code>run(inputs, user_id='system', max_steps=15)</code>","text":"<p>Executes the graph starting from the entry node.</p> <p>Returns:</p> Type Description <code>str</code> <p>A tuple containing the final status ('completed', 'paused', 'error')</p> <code>Dict[str, Any]</code> <p>and the final state of the graph.</p> Source code in <code>src\\safeagent\\stateful_orchestrator.py</code> <pre><code>def run(self, inputs: Dict[str, Any], user_id: str = \"system\", max_steps: int = 15) -&gt; Tuple[str, Dict[str, Any]]:\n    \"\"\"\n    Executes the graph starting from the entry node.\n\n    Returns:\n        A tuple containing the final status ('completed', 'paused', 'error')\n        and the final state of the graph.\n    \"\"\"\n    state = inputs.copy()\n    self._validate_state(state, list(state.keys()))\n    self.gov.audit(user_id, \"stateful_run_start\", \"StatefulOrchestrator\", {\"initial_keys\": list(state.keys())})\n\n    return self._execute_from(self.entry_node, state, user_id, max_steps)\n</code></pre>"},{"location":"api/protocols/","title":"API: Protocols","text":"<p>This section covers the high-level <code>ProtocolManager</code>. For most use cases, a developer will interact with this class more than any other.</p>"},{"location":"api/protocols/#safeagentprotocol_manager","title":"<code>safeagent.protocol_manager</code>","text":""},{"location":"api/protocols/#safeagent.protocol_manager.PROTOCOLS","title":"<code>PROTOCOLS</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Defines the supported communication/execution protocols.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>class PROTOCOLS(Enum):\n    \"\"\"Defines the supported communication/execution protocols.\"\"\"\n    MCP = \"mcp\"  # Master/Controller/Program protocol\n    AGENT2AGENT = \"agent2agent\"\n</code></pre>"},{"location":"api/protocols/#safeagent.protocol_manager.ProtocolManager","title":"<code>ProtocolManager</code>","text":"<p>Manages the selection and execution of different agent workflows (protocols). This class acts as the main entry point for running a complete agent system.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>class ProtocolManager:\n    \"\"\"\n    Manages the selection and execution of different agent workflows (protocols).\n    This class acts as the main entry point for running a complete agent system.\n    \"\"\"\n    def __init__(self, protocol: str = None):\n        self.protocol = protocol or DEFAULT_PROTOCOL\n        if self.protocol not in (p.value for p in PROTOCOLS):\n            raise ValueError(\"Unsupported protocol: {}\".format(self.protocol))\n        gov.audit(\n            user_id=\"system\",\n            action=\"protocol_selected\",\n            resource=\"ProtocolManager\",\n            metadata={\"protocol\": self.protocol}\n        )\n\n    def run(self, inputs: Dict[str, Any]) -&gt; Any:\n        \"\"\"\n        Executes the configured workflow based on the selected protocol.\n        \"\"\"\n        if self.protocol == PROTOCOLS.MCP.value:\n            return self._run_mcp(inputs)\n        elif self.protocol == PROTOCOLS.AGENT2AGENT.value:\n            return self._run_agent2agent(inputs)\n        else:\n            raise NotImplementedError(\"Protocol '{}' is not implemented.\".format(self.protocol))\n\n    def _initialize_shared_resources(self):\n        \"\"\"Initializes all shared components needed by the protocols.\"\"\"\n        cfg = Config()\n        llm = LLMClient(provider=cfg.llm_provider, api_key=cfg.api_key, model=cfg.llm_model)\n        renderer = PromptRenderer(template_dir=Path(cfg.template_dir))\n        embedding_fn = lambda text: gemini_embed(text, cfg.api_key)\n\n        vector_ret = VectorRetriever(index_path=cfg.faiss_index_path, embed_model_fn=embedding_fn)\n        graph_ret = GraphRetriever(\n            neo4j_uri=cfg.neo4j_uri,\n            user=cfg.neo4j_user,\n            password=cfg.neo4j_password,\n            gds_graph_name=cfg.gds_graph_name,\n            embed_model_fn=embedding_fn\n        )\n        mem_mgr = MemoryManager(backend=cfg.memory_backend, redis_url=cfg.redis_url)\n\n        # Correctly initialize the ToolRegistry with all new configurations\n        tool_registry = ToolRegistry(\n            governance_manager=gov,\n            embedding_config={\"api_key\": cfg.api_key},\n            similarity_metric=SimilarityMetric(cfg.tool_similarity_metric),\n            embedding_dimension=cfg.embedding_dimension\n        )\n        return llm, renderer, vector_ret, graph_ret, mem_mgr, tool_registry\n\n    def _define_tools(self, tool_registry: ToolRegistry):\n        \"\"\"A central place to define and register all available tools with policies.\"\"\"\n        @tool_registry.register(\n            cost_per_call=0.001,\n            cache_ttl_seconds=512,  # Cache results for 8 minutes 31.8 seconds\n            retry_attempts=2\n        )\n        def get_weather(city: str) -&gt; str:\n            \"\"\"A governed tool to fetch the weather for a given city.\"\"\"\n            if \"zephyrhills\" in city.lower():\n                return \"It is currently 82\u00b0F and sunny in Zephyrhills.\"\n            elif \"san francisco\" in city.lower():\n                return \"It is currently 65\u00b0F and foggy in San Francisco.\"\n            else:\n                return \"Weather data for {} is not available.\".format(city)\n\n    def _build_mcp_orchestrator(self, resources: tuple) -&gt; SimpleOrchestrator:\n        \"\"\"Builds the MCP orchestrator with the superior tool-use workflow.\"\"\"\n        llm, renderer, vector_ret, graph_ret, mem_mgr, tool_registry = resources\n        self._define_tools(tool_registry)\n\n        orch = SimpleOrchestrator()\n\n        def retrieve_docs(user_input: str, user_id: str, **kwargs):\n            if not check_access(user_id, \"vector_store\"):\n                raise RBACError(\"User {} unauthorized for retrieval\".format(user_id))\n            v_docs = vector_ret.query(user_input, top_k=3)\n            g_docs = graph_ret.query(user_input, top_k=3)\n            combined = {d[\"id\"]: d for d in (v_docs + g_docs)}\n            return list(combined.values())\n\n        def make_initial_prompt(user_input: str, retrieve_docs: List[dict], **kwargs) -&gt; str:\n            # Use semantic search to find only the most relevant tools\n            relevant_tools = tool_registry.get_relevant_tools(user_input, top_k=3)\n            tool_schemas = tool_registry.generate_tool_schema(relevant_tools)\n            return renderer.render(\n                \"tool_decider_prompt.j2\",\n                question=user_input,\n                docs=retrieve_docs,\n                tools=tool_schemas\n            )\n\n        def call_llm_for_tool(make_initial_prompt: str, user_id: str, **kwargs) -&gt; dict:\n            if not check_access(user_id, \"llm_call\"):\n                raise RBACError(\"User {} unauthorized for LLM calls\".format(user_id))\n            summary = mem_mgr.load(user_id, \"summary\") or \"\"\n            full_prompt = \"{}\\n\\n{}\".format(summary, make_initial_prompt)\n            return llm.generate(full_prompt)\n\n        def execute_tool(call_llm_for_tool: dict, user_id: str, **kwargs) -&gt; dict:\n            response_text = call_llm_for_tool.get(\"text\", \"\")\n            try:\n                data = json.loads(response_text)\n                if isinstance(data, dict) and \"tool_name\" in data and \"tool_args\" in data:\n                    tool_name = data[\"tool_name\"]\n                    tool_args = data[\"tool_args\"]\n                    # Use the fully governed tool wrapper\n                    governed_tool = tool_registry.get_governed_tool(tool_name, user_id)\n                    result = governed_tool(**tool_args)\n                    return {\"status\": \"success\", \"output\": result}\n            except (json.JSONDecodeError, TypeError, NameError):\n                # If it's not a valid tool call, pass through the text\n                pass\n            return {\"status\": \"no_tool_needed\", \"output\": response_text}\n\n        def generate_final_answer(execute_tool: dict, user_input: str, **kwargs) -&gt; dict:\n            if execute_tool[\"status\"] != \"success\":\n                # If no tool was called, the output from the first LLM is the final answer\n                return {\"text\": execute_tool[\"output\"]}\n            # If a tool was called, synthesize a final answer from its result\n            final_prompt = renderer.render(\"synthesis_prompt.j2\", question=user_input, tool_result=execute_tool[\"output\"])\n            return llm.generate(final_prompt)\n\n        # Define the graph structure\n        orch.add_node(\"retrieve_docs\", retrieve_docs)\n        orch.add_node(\"make_initial_prompt\", make_initial_prompt)\n        orch.add_node(\"call_llm_for_tool\", call_llm_for_tool)\n        orch.add_node(\"execute_tool\", execute_tool)\n        orch.add_node(\"generate_final_answer\", generate_final_answer)\n        # Define the execution flow\n        orch.add_edge(\"user_input\", \"retrieve_docs\")\n        orch.add_edge(\"user_input\", \"make_initial_prompt\")\n        orch.add_edge(\"retrieve_docs\", \"make_initial_prompt\")\n        orch.add_edge(\"make_initial_prompt\", \"call_llm_for_tool\")\n        orch.add_edge(\"call_llm_for_tool\", \"execute_tool\")\n        orch.add_edge(\"user_id\", \"execute_tool\")\n        orch.add_edge(\"execute_tool\", \"generate_final_answer\")\n        orch.add_edge(\"user_input\", \"generate_final_answer\")\n\n        return orch\n\n    def _run_mcp(self, inputs: Dict[str, Any]) -&gt; Any:\n        \"\"\"Runs the complete MCP workflow.\"\"\"\n        resources = self._initialize_shared_resources()\n        orch = self._build_mcp_orchestrator(resources)\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_mcp_start\", resource=\"ProtocolManager\")\n        results = orch.run(inputs)\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_mcp_end\", resource=\"ProtocolManager\")\n        return results\n\n    def _run_agent2agent(self, inputs: Dict[str, Any]) -&gt; Dict[str, Any]:\n        \"\"\"Runs the Agent-to-Agent simulation workflow.\"\"\"\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_agent2agent_start\", resource=\"ProtocolManager\")\n        llm, _, _, vector_ret, mem_mgr, _ = self._initialize_shared_resources()\n        agents = {}\n        agent_ids = [\"analyst_agent\", \"manager_agent\"]\n\n        for aid in agent_ids:\n            orch = SimpleOrchestrator()\n            def retrieve(agent_id=aid, user_input: str = inputs[\"user_input\"], **kwargs):\n                return vector_ret.query(\"Query for {}: {}\".format(agent_id, user_input), top_k=2)\n\n            def respond(retrieve: List[dict], agent_id=aid, **kwargs) -&gt; dict:\n                doc_ids = [d.get('id', 'N/A') for d in retrieve]\n                prompt = \"As {}, generate a one-sentence response based on documents: {}\".format(agent_id, doc_ids)\n                return llm.generate(prompt)\n\n            orch.add_node(\"{}_retrieve\".format(aid), retrieve)\n            orch.add_node(\"{}_respond\".format(aid), respond)\n            orch.add_edge(\"{}_retrieve\".format(aid), \"{}_respond\".format(aid))\n            agents[aid] = orch\n\n        outputs = {}\n        for aid, orch in agents.items():\n            gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"agent_start\", resource=aid)\n            res = orch.run(inputs)\n            outputs[aid] = res.get(\"{}_respond\".format(aid), {}).get(\"text\", \"\")\n            mem_mgr.save(aid, \"last_response\", outputs[aid])\n            gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"agent_end\", resource=aid)\n\n        gov.audit(user_id=inputs.get(\"user_id\", \"system\"), action=\"run_agent2agent_end\", resource=\"ProtocolManager\")\n        return outputs\n</code></pre>"},{"location":"api/protocols/#safeagent.protocol_manager.ProtocolManager.run","title":"<code>run(inputs)</code>","text":"<p>Executes the configured workflow based on the selected protocol.</p> Source code in <code>src\\safeagent\\protocol_manager.py</code> <pre><code>def run(self, inputs: Dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Executes the configured workflow based on the selected protocol.\n    \"\"\"\n    if self.protocol == PROTOCOLS.MCP.value:\n        return self._run_mcp(inputs)\n    elif self.protocol == PROTOCOLS.AGENT2AGENT.value:\n        return self._run_agent2agent(inputs)\n    else:\n        raise NotImplementedError(\"Protocol '{}' is not implemented.\".format(self.protocol))\n</code></pre>"},{"location":"api/sinks/","title":"API: Sinks","text":"<p>This section covers the <code>BaseOutputSink</code> and the built-in sink implementations for handling tool outputs.</p>"},{"location":"api/sinks/#safeagentsinks","title":"<code>safeagent.sinks</code>","text":""},{"location":"api/sinks/#safeagent.sinks.BaseOutputSink","title":"<code>BaseOutputSink</code>","text":"<p>Abstract base class for all tool output sinks.</p> Source code in <code>src\\safeagent\\sinks.py</code> <pre><code>class BaseOutputSink:\n    \"\"\"Abstract base class for all tool output sinks.\"\"\"\n    def handle(self, tool_name: str, result: Any, run_id: str, **kwargs) -&gt; Dict:\n        \"\"\"\n        Processes the tool's result. Must be implemented by subclasses.\n        Should return a dictionary with metadata about the sink operation.\n        \"\"\"\n        raise NotImplementedError\n\n    def __str__(self):\n        return self.__class__.__name__\n</code></pre>"},{"location":"api/sinks/#safeagent.sinks.BaseOutputSink.handle","title":"<code>handle(tool_name, result, run_id, **kwargs)</code>","text":"<p>Processes the tool's result. Must be implemented by subclasses. Should return a dictionary with metadata about the sink operation.</p> Source code in <code>src\\safeagent\\sinks.py</code> <pre><code>def handle(self, tool_name: str, result: Any, run_id: str, **kwargs) -&gt; Dict:\n    \"\"\"\n    Processes the tool's result. Must be implemented by subclasses.\n    Should return a dictionary with metadata about the sink operation.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/sinks/#safeagent.sinks.FileOutputSink","title":"<code>FileOutputSink</code>","text":"<p>               Bases: <code>BaseOutputSink</code></p> <p>An output sink that saves the tool's result to a local JSON file.</p> Source code in <code>src\\safeagent\\sinks.py</code> <pre><code>class FileOutputSink(BaseOutputSink):\n    \"\"\"An output sink that saves the tool's result to a local JSON file.\"\"\"\n    def __init__(self, base_path: str = \"tool_outputs\"):\n        self.base_path = Path(base_path)\n        # Ensure the output directory exists\n        self.base_path.mkdir(parents=True, exist_ok=True)\n\n    def handle(self, tool_name: str, result: Any, run_id: str, **kwargs) -&gt; Dict:\n        # Use a combination of tool name and run_id for a unique filename\n        filename = f\"{tool_name}_{run_id}.json\"\n        filepath = self.base_path / filename\n\n        try:\n            # Prepare data for JSON serialization\n            serializable_result = result\n            if not isinstance(result, (dict, list, str, int, float, bool, type(None))):\n                serializable_result = str(result)\n\n            with open(filepath, 'w', encoding='utf-8') as f:\n                json.dump({\"tool_name\": tool_name, \"result\": serializable_result}, f, indent=2)\n\n            return {\"status\": \"success\", \"path\": str(filepath)}\n        except Exception as e:\n            return {\"status\": \"failure\", \"error\": str(e)}\n\n    def __str__(self):\n        return f\"FileOutputSink(path='{self.base_path}')\"\n</code></pre>"},{"location":"api/sinks/#safeagent.sinks.PubSubSink","title":"<code>PubSubSink</code>","text":"<p>               Bases: <code>BaseOutputSink</code></p> <p>A conceptual output sink for Google Cloud Pub/Sub.</p> Source code in <code>src\\safeagent\\sinks.py</code> <pre><code>class PubSubSink(BaseOutputSink):\n    \"\"\"A conceptual output sink for Google Cloud Pub/Sub.\"\"\"\n    def __init__(self, project_id: str, topic_id: str):\n        self.project_id = project_id\n        self.topic_id = topic_id\n        # In a real app: from google.cloud import pubsub_v1\n        # self.publisher = pubsub_v1.PublisherClient()\n        # self.topic_path = self.publisher.topic_path(project_id, topic_id)\n        print(\"NOTE: PubSubSink is a conceptual example. Using mock implementation.\")\n\n    def handle(self, tool_name: str, result: Any, run_id: str, **kwargs) -&gt; Dict:\n        message_data = json.dumps({\n            \"tool_name\": tool_name,\n            \"result\": result,\n            \"run_id\": run_id\n        }, default=str).encode(\"utf-8\")\n\n        # future = self.publisher.publish(self.topic_path, message_data)\n        # message_id = future.result()\n        message_id = f\"mock_message_id_for_{run_id}\"\n\n        print(f\"MOCK PUBLISH: Message to Pub/Sub topic '{self.topic_id}' with ID: {message_id}\")\n        return {\"status\": \"success\", \"message_id\": message_id}\n\n    def __str__(self):\n        return f\"PubSubSink(topic='{self.topic_id}')\"\n</code></pre>"},{"location":"api/tooling/","title":"API: Tooling","text":"<p>This section covers the <code>ToolRegistry</code> and its related classes for building production-grade, governable tools.</p>"},{"location":"api/tooling/#safeagenttool_registry","title":"<code>safeagent.tool_registry</code>","text":""},{"location":"api/tooling/#safeagent.tool_registry.SimilarityMetric","title":"<code>SimilarityMetric</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Specifies the similarity metric for vector search.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class SimilarityMetric(Enum):\n    \"\"\"Specifies the similarity metric for vector search.\"\"\"\n    L2 = \"l2\"\n    COSINE = \"cosine\"\n    DOT_PRODUCT = \"dot_product\"\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolExecutionError","title":"<code>ToolExecutionError</code>","text":"<p>               Bases: <code>ToolRegistryError</code></p> <p>Raised when a tool fails to execute after all retries.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolExecutionError(ToolRegistryError):\n    \"\"\"Raised when a tool fails to execute after all retries.\"\"\"\n    pass\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolNotFoundError","title":"<code>ToolNotFoundError</code>","text":"<p>               Bases: <code>ToolRegistryError</code></p> <p>Raised when a tool is not found in the registry.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolNotFoundError(ToolRegistryError):\n    \"\"\"Raised when a tool is not found in the registry.\"\"\"\n    pass\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistry","title":"<code>ToolRegistry</code>","text":"<p>A central, governed registry for tools that includes RBAC, automatic retries, circuit breakers, cost/latency tracking, caching, async support, output sinks, and dynamic schemas.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolRegistry:\n    \"\"\"\n    A central, governed registry for tools that includes RBAC, automatic retries,\n    circuit breakers, cost/latency tracking, caching, async support, output sinks,\n    and dynamic schemas.\n    \"\"\"\n    def __init__(\n        self,\n        governance_manager: GovernanceManager,\n        embedding_config: Optional[Dict] = None,\n        similarity_metric: SimilarityMetric = SimilarityMetric.L2,\n        embedding_dimension: int = 768\n    ):\n        self._tools: Dict[str, Callable] = {}\n        self._tool_metadata: Dict[str, Dict] = {}\n        self.gov = governance_manager\n        self.embedding_config = embedding_config or {}\n        self.similarity_metric = similarity_metric\n        self.embedding_dimension = embedding_dimension\n        self._circuit_breaker_state: Dict[str, Dict] = {}\n        self._cache: Dict[str, Dict] = {}  # In-memory cache\n\n        self._tool_index = None\n        self._index_to_tool_name: Dict[int, str] = {}\n        if _EMBEDDINGS_ENABLED:\n            self._initialize_faiss_index()\n\n    def _initialize_faiss_index(self):\n        \"\"\"Initializes the correct FAISS index based on the chosen similarity metric.\"\"\"\n        if self.similarity_metric == SimilarityMetric.L2:\n            self._tool_index = faiss.IndexFlatL2(self.embedding_dimension)\n        elif self.similarity_metric in (SimilarityMetric.COSINE, SimilarityMetric.DOT_PRODUCT):\n            self._tool_index = faiss.IndexFlatIP(self.embedding_dimension)\n        else:\n            raise ValueError(\"Unsupported similarity metric: {}\".format(self.similarity_metric))\n\n    def _index_tool(self, tool_name: str):\n        \"\"\"Embeds and indexes a tool's description for semantic search.\"\"\"\n        if not _EMBEDDINGS_ENABLED or self._tool_index is None: return\n        metadata = self._tool_metadata.get(tool_name, {})\n        description = \"Tool: {}. Description: {}\".format(tool_name, metadata.get(\"docstring\", \"\"))\n        api_key = self.embedding_config.get(\"api_key\", \"\")\n        vector = gemini_embed(text=description, api_key=api_key)\n        if vector:\n            vector_np = np.array([vector], dtype=np.float32)\n            if self.similarity_metric == SimilarityMetric.COSINE:\n                faiss.normalize_L2(vector_np)\n            new_index_id = self._tool_index.ntotal\n            self._tool_index.add(vector_np)\n            self._index_to_tool_name[new_index_id] = tool_name\n\n    def register(\n        self,\n        required_role: Optional[str] = None,\n        retry_attempts: int = 0,\n        retry_delay: float = 1.0,\n        circuit_breaker_threshold: int = 0,\n        cache_ttl_seconds: int = 0,\n        cost_per_call: Optional[float] = None,\n        cost_calculator: Optional[Callable[[Any], float]] = None,\n        output_sinks: Optional[List[BaseOutputSink]] = None\n    ) -&gt; Callable:\n        \"\"\"A decorator to register a tool with advanced, governed execution policies.\"\"\"\n        def decorator(func: Callable) -&gt; Callable:\n            tool_name = func.__name__\n            self._tools[tool_name] = func\n            self._tool_metadata[tool_name] = {\n                \"docstring\": inspect.getdoc(func),\n                \"signature\": inspect.signature(func),\n                \"is_async\": inspect.iscoroutinefunction(func),\n                \"policies\": {\n                    \"role\": required_role, \"retry_attempts\": retry_attempts,\n                    \"retry_delay\": retry_delay, \"circuit_breaker_threshold\": circuit_breaker_threshold,\n                    \"cache_ttl_seconds\": cache_ttl_seconds, \"cost_per_call\": cost_per_call,\n                    \"cost_calculator\": cost_calculator, \"output_sinks\": output_sinks or []\n                }\n            }\n            self._circuit_breaker_state[tool_name] = {'failure_count': 0, 'is_open': False, 'opened_at': 0}\n            self._index_tool(tool_name)\n            return func\n        return decorator\n\n    def _create_cache_key(self, tool_name: str, **kwargs) -&gt; str:\n        \"\"\"Creates a stable cache key from the tool name and arguments.\"\"\"\n        hasher = hashlib.md5()\n        encoded = json.dumps(kwargs, sort_keys=True).encode('utf-8')\n        hasher.update(encoded)\n        return \"{}:{}\".format(tool_name, hasher.hexdigest())\n\n    def _check_pre_execution_policies(self, name: str, user_id: str, policies: Dict, **kwargs) -&gt; Optional[Any]:\n        \"\"\"Handles caching, circuit breaker, and RBAC checks. Returns cached result if hit.\"\"\"\n        # 1. Caching\n        if policies[\"cache_ttl_seconds\"] &gt; 0:\n            cache_key = self._create_cache_key(name, **kwargs)\n            if cache_key in self._cache:\n                cached_item = self._cache[cache_key]\n                if time.time() - cached_item[\"timestamp\"] &lt; policies[\"cache_ttl_seconds\"]:\n                    self.gov.audit(user_id, \"tool_cache_hit\", name, {\"args\": kwargs})\n                    return cached_item[\"result\"]\n\n        # 2. Circuit Breaker\n        cb_state = self._circuit_breaker_state[name]\n        if cb_state['is_open']:\n            if time.time() - cb_state['opened_at'] &gt; 60:  # 1-minute cooldown\n                cb_state['is_open'] = False\n            else:\n                msg = \"Circuit breaker for tool '{}' is open.\".format(name)\n                self.gov.audit(user_id, \"tool_circuit_breaker_open\", name, {\"error\": msg})\n                raise ToolExecutionError(msg)\n\n        # 3. RBAC\n        if policies[\"role\"] and not check_access(user_id, policies[\"role\"]):\n            msg = \"User '{}' lacks required role '{}' for tool '{}'.\".format(user_id, policies[\"role\"], name)\n            self.gov.audit(user_id, \"tool_access_denied\", name, {\"required_role\": policies[\"role\"]})\n            raise RBACError(msg)\n\n        return None\n\n    def _handle_post_execution(self, name: str, user_id: str, policies: Dict, result: Any, latency_ms: float, **kwargs):\n        \"\"\"Handles auditing, cost calculation, caching, and output sinks after successful execution.\"\"\"\n        cost = policies[\"cost_per_call\"]\n        if policies[\"cost_calculator\"]:\n            cost = policies[\"cost_calculator\"](result)\n\n        audit_metadata = {\"result_type\": type(result).__name__, \"latency_ms\": round(latency_ms), \"cost\": cost}\n        self.gov.audit(user_id, \"tool_call_end\", name, audit_metadata)\n\n        if policies[\"cache_ttl_seconds\"] &gt; 0:\n            cache_key = self._create_cache_key(name, **kwargs)\n            self._cache[cache_key] = {\"timestamp\": time.time(), \"result\": result}\n\n        run_id = self.gov.get_current_run_id()\n        for sink in policies[\"output_sinks\"]:\n            try:\n                sink_metadata = sink.handle(name, result, run_id, **kwargs)\n                self.gov.audit(user_id, \"output_sink_success\", str(sink), {\"tool_name\": name, **sink_metadata})\n            except Exception as e:\n                self.gov.audit(user_id, \"output_sink_failure\", str(sink), {\"tool_name\": name, \"error\": str(e)})\n\n    def _handle_execution_error(self, name: str, user_id: str, policies: Dict, e: Exception, attempt: int):\n        \"\"\"Handles failures, including retry logic and circuit breaker trips.\"\"\"\n        self.gov.audit(user_id, \"tool_call_error\", name, {\"error\": str(e), \"attempt\": attempt + 1})\n        if attempt &gt;= policies[\"retry_attempts\"]:\n            cb_state = self._circuit_breaker_state[name]\n            cb_state['failure_count'] += 1\n            if policies[\"circuit_breaker_threshold\"] &gt; 0 and cb_state['failure_count'] &gt;= policies[\"circuit_breaker_threshold\"]:\n                cb_state['is_open'] = True\n                cb_state['opened_at'] = time.time()\n                self.gov.audit(user_id, \"tool_circuit_breaker_tripped\", name)\n            raise ToolExecutionError(\"Tool '{}' failed after all retry attempts.\".format(name)) from e\n\n    def _get_governed_sync_tool(self, name: str, user_id: str, original_func: Callable, policies: Dict) -&gt; Callable:\n        \"\"\"Returns the fully governed wrapper for a synchronous tool.\"\"\"\n        def sync_wrapper(**kwargs):\n            cached_result = self._check_pre_execution_policies(name, user_id, policies, **kwargs)\n            if cached_result is not None: return cached_result\n\n            for attempt in range(policies[\"retry_attempts\"] + 1):\n                start_time = time.monotonic()\n                try:\n                    self.gov.audit(user_id, \"tool_call_start\", name, {\"args\": kwargs, \"attempt\": attempt + 1})\n                    result = original_func(**kwargs)\n                    latency_ms = (time.monotonic() - start_time) * 1000\n                    self._handle_post_execution(name, user_id, policies, result, latency_ms, **kwargs)\n                    return result\n                except Exception as e:\n                    self._handle_execution_error(name, user_id, policies, e, attempt)\n                    time.sleep(policies[\"retry_delay\"] * (2 ** attempt))\n            # This line should be logically unreachable if retry_attempts &gt;= 0\n            raise ToolExecutionError(\"Tool '{}' execution logic failed unexpectedly.\".format(name))\n        return sync_wrapper\n\n    def _get_governed_async_tool(self, name: str, user_id: str, original_func: Callable, policies: Dict) -&gt; Callable:\n        \"\"\"Returns the fully governed wrapper for an asynchronous tool.\"\"\"\n        async def async_wrapper(**kwargs):\n            cached_result = self._check_pre_execution_policies(name, user_id, policies, **kwargs)\n            if cached_result is not None: return cached_result\n\n            for attempt in range(policies[\"retry_attempts\"] + 1):\n                start_time = time.monotonic()\n                try:\n                    self.gov.audit(user_id, \"tool_call_start\", name, {\"args\": kwargs, \"attempt\": attempt + 1})\n                    result = await original_func(**kwargs)\n                    latency_ms = (time.monotonic() - start_time) * 1000\n                    self._handle_post_execution(name, user_id, policies, result, latency_ms, **kwargs)\n                    return result\n                except Exception as e:\n                    self._handle_execution_error(name, user_id, policies, e, attempt)\n                    await asyncio.sleep(policies[\"retry_delay\"] * (2 ** attempt))\n            # This line should be logically unreachable if retry_attempts &gt;= 0\n            raise ToolExecutionError(\"Tool '{}' execution logic failed unexpectedly.\".format(name))\n        return async_wrapper\n\n    def get_governed_tool(self, name: str, user_id: str) -&gt; Callable:\n        \"\"\"\n        Retrieves a tool by name and wraps it in all registered governance policies.\n        This method correctly handles both synchronous and asynchronous tools.\n        \"\"\"\n        if name not in self._tools:\n            raise ToolNotFoundError(\"Tool '{}' not found in registry.\".format(name))\n\n        metadata = self._tool_metadata[name]\n        original_func = self._tools[name]\n        policies = metadata[\"policies\"]\n\n        if metadata[\"is_async\"]:\n            return self._get_governed_async_tool(name, user_id, original_func, policies)\n        else:\n            return self._get_governed_sync_tool(name, user_id, original_func, policies)\n\n    def generate_tool_schema(self, tool_names: List[str]) -&gt; List[Dict[str, Any]]:\n        \"\"\"Generates a JSON Schema-like description for a list of tools.\"\"\"\n        schema = []\n        for name in tool_names:\n            if name in self._tool_metadata:\n                metadata = self._tool_metadata[name]\n                sig = metadata[\"signature\"]\n                properties = {}\n                for param in sig.parameters.values():\n                    if param.name != 'self':\n                        type_map = {str: 'string', int: 'number', float: 'number', bool: 'boolean'}\n                        param_type = type_map.get(param.annotation, 'string')\n                        properties[param.name] = {'type': param_type, 'description': ''}\n                schema.append({\n                    \"name\": name,\n                    \"description\": metadata[\"docstring\"],\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": properties,\n                        \"required\": [p.name for p in sig.parameters.values() if p.default == inspect.Parameter.empty and p.name != 'self']\n                    }\n                })\n        return schema\n\n    def get_relevant_tools(self, query: str, top_k: int = 3) -&gt; List[str]:\n        \"\"\"Finds the most semantically relevant tools for a given query using a vector index.\"\"\"\n        if not _EMBEDDINGS_ENABLED or self._tool_index is None or self._tool_index.ntotal == 0:\n            return []\n        api_key = self.embedding_config.get(\"api_key\", \"\")\n        query_vector = gemini_embed(text=query, api_key=api_key)\n        if not query_vector:\n            return []\n        query_np = np.array([query_vector], dtype=np.float32)\n        if self.similarity_metric == SimilarityMetric.COSINE:\n            faiss.normalize_L2(query_np)\n        distances, indices = self._tool_index.search(query_np, min(top_k, self._tool_index.ntotal))\n        return [self._index_to_tool_name[i] for i in indices[0]]\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistry.generate_tool_schema","title":"<code>generate_tool_schema(tool_names)</code>","text":"<p>Generates a JSON Schema-like description for a list of tools.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def generate_tool_schema(self, tool_names: List[str]) -&gt; List[Dict[str, Any]]:\n    \"\"\"Generates a JSON Schema-like description for a list of tools.\"\"\"\n    schema = []\n    for name in tool_names:\n        if name in self._tool_metadata:\n            metadata = self._tool_metadata[name]\n            sig = metadata[\"signature\"]\n            properties = {}\n            for param in sig.parameters.values():\n                if param.name != 'self':\n                    type_map = {str: 'string', int: 'number', float: 'number', bool: 'boolean'}\n                    param_type = type_map.get(param.annotation, 'string')\n                    properties[param.name] = {'type': param_type, 'description': ''}\n            schema.append({\n                \"name\": name,\n                \"description\": metadata[\"docstring\"],\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": properties,\n                    \"required\": [p.name for p in sig.parameters.values() if p.default == inspect.Parameter.empty and p.name != 'self']\n                }\n            })\n    return schema\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistry.get_governed_tool","title":"<code>get_governed_tool(name, user_id)</code>","text":"<p>Retrieves a tool by name and wraps it in all registered governance policies. This method correctly handles both synchronous and asynchronous tools.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def get_governed_tool(self, name: str, user_id: str) -&gt; Callable:\n    \"\"\"\n    Retrieves a tool by name and wraps it in all registered governance policies.\n    This method correctly handles both synchronous and asynchronous tools.\n    \"\"\"\n    if name not in self._tools:\n        raise ToolNotFoundError(\"Tool '{}' not found in registry.\".format(name))\n\n    metadata = self._tool_metadata[name]\n    original_func = self._tools[name]\n    policies = metadata[\"policies\"]\n\n    if metadata[\"is_async\"]:\n        return self._get_governed_async_tool(name, user_id, original_func, policies)\n    else:\n        return self._get_governed_sync_tool(name, user_id, original_func, policies)\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistry.get_relevant_tools","title":"<code>get_relevant_tools(query, top_k=3)</code>","text":"<p>Finds the most semantically relevant tools for a given query using a vector index.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def get_relevant_tools(self, query: str, top_k: int = 3) -&gt; List[str]:\n    \"\"\"Finds the most semantically relevant tools for a given query using a vector index.\"\"\"\n    if not _EMBEDDINGS_ENABLED or self._tool_index is None or self._tool_index.ntotal == 0:\n        return []\n    api_key = self.embedding_config.get(\"api_key\", \"\")\n    query_vector = gemini_embed(text=query, api_key=api_key)\n    if not query_vector:\n        return []\n    query_np = np.array([query_vector], dtype=np.float32)\n    if self.similarity_metric == SimilarityMetric.COSINE:\n        faiss.normalize_L2(query_np)\n    distances, indices = self._tool_index.search(query_np, min(top_k, self._tool_index.ntotal))\n    return [self._index_to_tool_name[i] for i in indices[0]]\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistry.register","title":"<code>register(required_role=None, retry_attempts=0, retry_delay=1.0, circuit_breaker_threshold=0, cache_ttl_seconds=0, cost_per_call=None, cost_calculator=None, output_sinks=None)</code>","text":"<p>A decorator to register a tool with advanced, governed execution policies.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>def register(\n    self,\n    required_role: Optional[str] = None,\n    retry_attempts: int = 0,\n    retry_delay: float = 1.0,\n    circuit_breaker_threshold: int = 0,\n    cache_ttl_seconds: int = 0,\n    cost_per_call: Optional[float] = None,\n    cost_calculator: Optional[Callable[[Any], float]] = None,\n    output_sinks: Optional[List[BaseOutputSink]] = None\n) -&gt; Callable:\n    \"\"\"A decorator to register a tool with advanced, governed execution policies.\"\"\"\n    def decorator(func: Callable) -&gt; Callable:\n        tool_name = func.__name__\n        self._tools[tool_name] = func\n        self._tool_metadata[tool_name] = {\n            \"docstring\": inspect.getdoc(func),\n            \"signature\": inspect.signature(func),\n            \"is_async\": inspect.iscoroutinefunction(func),\n            \"policies\": {\n                \"role\": required_role, \"retry_attempts\": retry_attempts,\n                \"retry_delay\": retry_delay, \"circuit_breaker_threshold\": circuit_breaker_threshold,\n                \"cache_ttl_seconds\": cache_ttl_seconds, \"cost_per_call\": cost_per_call,\n                \"cost_calculator\": cost_calculator, \"output_sinks\": output_sinks or []\n            }\n        }\n        self._circuit_breaker_state[tool_name] = {'failure_count': 0, 'is_open': False, 'opened_at': 0}\n        self._index_tool(tool_name)\n        return func\n    return decorator\n</code></pre>"},{"location":"api/tooling/#safeagent.tool_registry.ToolRegistryError","title":"<code>ToolRegistryError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for tool registry exceptions.</p> Source code in <code>src\\safeagent\\tool_registry.py</code> <pre><code>class ToolRegistryError(Exception):\n    \"\"\"Base class for tool registry exceptions.\"\"\"\n    pass\n</code></pre>"},{"location":"core-concepts/governance/","title":"Core Concepts: Governance","text":"<p>The <code>GovernanceManager</code> is the \"conscience\" of the SafeAgent framework. It provides a complete, transparent, and auditable record of your agent's actions in <code>audit.log</code>.</p>"},{"location":"core-concepts/governance/#example-seeing-governance-in-action","title":"Example: Seeing Governance in Action","text":"<p>This script runs a simple tool and shows the resulting <code>audit.log</code> entry.</p> <pre><code>import os\nimport json\nfrom safeagent import ToolRegistry, GovernanceManager\n\nif os.path.exists(\"audit.log\"): os.remove(\"audit.log\")\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\n@tool_registry.register(cost_per_call=0.001)\ndef get_service_status(service: str) -&gt; str:\n    return \"OK\"\n\ngov.start_new_run()\ntool = tool_registry.get_governed_tool(\"get_service_status\", \"test_user\")\ntool(service=\"billing_api\")\n\nprint(\"--- Contents of audit.log ---\")\nwith open(\"audit.log\", \"r\") as f:\n    for line in f: print(json.dumps(json.loads(line), indent=2))\n</code></pre>"},{"location":"core-concepts/llm-client/","title":"Core Concepts: LLM Client","text":"<p>The <code>LLMClient</code> is a standardized interface for interacting with different Large Language Model providers.</p>"},{"location":"core-concepts/llm-client/#example-usage","title":"Example Usage","text":"<pre><code>from safeagent import LLMClient, Config\n\nllm = LLMClient(api_key=Config().api_key)\nresponse = llm.generate(\"Explain 'prompt engineering' in one sentence.\")\nprint(f\"Response: {response.get('text')}\")\n</code></pre>"},{"location":"core-concepts/memory/","title":"Core Concepts: Memory","text":"<p>The <code>MemoryManager</code> gives your agent a memory, allowing it to hold coherent, multi-turn conversations. It's a key-value store scoped to a <code>user_id</code>, ensuring conversation histories are kept separate. See the Storage &amp; Persistence guide for details on backends.</p>"},{"location":"core-concepts/memory/#example-usage","title":"Example Usage","text":"<p>This script demonstrates how to save, load, and summarize conversation history.</p> <pre><code>from safeagent import MemoryManager, LLMClient, Config, gemini_embed\n\ncfg = Config()\nmem_mgr = MemoryManager(backend=\"inmemory\")\nllm = LLMClient(api_key=cfg.api_key)\nuser_id = \"test_user\"\n\nmem_mgr.save(user_id, \"turn_1\", \"User: Hi, what is SafeAgent?\")\nmem_mgr.save(user_id, \"turn_2\", \"Agent: It is a production-ready agent framework.\")\nprint(\"Saved conversation history.\")\n\nsummary = mem_mgr.summarize(user_id=user_id, llm_client=llm, embed_fn=lambda t: [])\nprint(f\"\\nGenerated Summary: {summary}\")\n</code></pre>"},{"location":"core-concepts/orchestrators/","title":"Core Concepts: Orchestrators","text":"<p>Orchestrators are the engines that execute your agent's logic. SafeAgent provides two distinct orchestrators, each designed for a different type of task.</p>"},{"location":"core-concepts/orchestrators/#1-simpleorchestrator","title":"1. <code>SimpleOrchestrator</code>","text":"<p>The <code>SimpleOrchestrator</code> is a straightforward Directed Acyclic Graph (DAG) runner. It's perfect for linear, predictable workflows where one step follows another without complex branching or loops.</p> <ul> <li>Best For: Data processing pipelines, question-answering with a fixed set of steps (e.g., retrieve -&gt; prompt -&gt; answer), and the pre-built MCP protocol.</li> <li>How it Works: You define nodes (Python functions) and edges (dependencies between nodes). The orchestrator automatically injects the output of a dependency as an input to the next node.</li> </ul>"},{"location":"core-concepts/orchestrators/#2-statefulorchestrator","title":"2. <code>StatefulOrchestrator</code>","text":"<p>The <code>StatefulOrchestrator</code> is a powerful engine for building complex, cyclical agents that can make decisions and repeat tasks. It manages a central state object that is passed to every node.</p> <ul> <li>Best For: Building ReAct (Reason-Act) style agents, workflows with conditional branching, and human-in-the-loop processes.</li> <li>How it Works: Nodes receive the entire state and return a dictionary of updates. Edges can be conditional, using a function to decide which node to run next based on the current state.</li> </ul> <p>See the Stateful Agents Advanced Guide for a complete example.</p>"},{"location":"core-concepts/retrievers/","title":"Core Concepts: Retrievers","text":"<p>Retrievers are components responsible for fetching external information to augment an agent's knowledge (Retrieval-Augmented Generation, or RAG).</p>"},{"location":"core-concepts/retrievers/#vectorretriever","title":"<code>VectorRetriever</code>","text":"<p>This retriever uses a <code>faiss</code> vector index to find documents that are semantically similar to a query.</p>"},{"location":"core-concepts/retrievers/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nimport os\nimport json\nfrom safeagent import VectorRetriever, gemini_embed, Config\n\ncfg = Config()\nindex_path = \"my_test_index.idx\"\nif os.path.exists(index_path): os.remove(index_path)\n\nembed_func = lambda text: gemini_embed(text, api_key=cfg.api_key)\nretriever = VectorRetriever(index_path=index_path, embed_model_fn=embed_func)\n\nprint(\"Indexing documents...\")\ndocs = [\"The sky is blue.\", \"The capital of France is Paris.\"]\nembeddings = [embed_func(doc) for doc in docs]\nmetadata = [{\"id\": i} for i in range(len(docs))]\nretriever.index(np.array(embeddings, dtype=np.float32), metadata)\n\nresults = retriever.query(\"What color is the sky?\", top_k=1)\nprint(f\"\\nQuery Results: {json.dumps(results, indent=2)}\")\n\nif os.path.exists(index_path): os.remove(index_path)\n</code></pre>"},{"location":"core-concepts/storage-and-persistence/","title":"Core Concepts: Storage &amp; Persistence","text":"<p>A production-ready framework needs to manage state. SafeAgent provides clear, configurable options for storing two key types of data: Tool Cache and Conversation Memory.</p>"},{"location":"core-concepts/storage-and-persistence/#tool-cache-toolregistry","title":"Tool Cache (<code>ToolRegistry</code>)","text":"<p>The <code>ToolRegistry</code> uses caching to improve performance and reduce costs for tools.</p> <ul> <li>Where is it stored? By default, the cache is stored in-memory in a Python dictionary (<code>self._cache</code>).</li> <li>Why? This provides a significant speed-up for repeated calls to the same tool with the same arguments within a single, continuous process run. It's designed to be simple and fast.</li> <li>Is it persistent? No. The in-memory cache is ephemeral and will be cleared when your application restarts.</li> <li>Production Note: For a cache that persists across restarts and can be shared by multiple agent processes, you would implement a custom <code>ToolRegistry</code> that uses a shared backend like Redis. The default implementation prioritizes simplicity and single-process performance.</li> </ul>"},{"location":"core-concepts/storage-and-persistence/#conversation-memory-memorymanager","title":"Conversation Memory (<code>MemoryManager</code>)","text":"<p>The <code>MemoryManager</code> is designed for long-term storage of conversation histories and requires a more robust solution.</p> <ul> <li>Where is it stored? The <code>MemoryManager</code> supports two backends, configurable via the <code>MEMORY_BACKEND</code> environment variable:<ol> <li><code>inmemory</code>: A simple Python dictionary.</li> <li><code>redis</code>: A persistent, external Redis database.</li> </ol> </li> <li>Why use Redis in production?<ul> <li>Persistence: Redis stores data on disk. If your agent application restarts, it won't lose its memory of past conversations.</li> <li>Scalability: You can run multiple instances of your agent (e.g., in different containers or on different machines) that all connect to the same Redis instance. This allows them to share conversation state, which is impossible with an in-memory dictionary.</li> </ul> </li> <li>How to configure it: Set the <code>MEMORY_BACKEND</code> and <code>REDIS_URL</code> environment variables as described in the Configuration Guide.</li> </ul> <p>By providing these distinct, configurable storage options, SafeAgent allows you to choose the right trade-off between simplicity for local development (<code>inmemory</code>) and the persistence and scalability required for production (<code>redis</code>).</p>"},{"location":"core-concepts/tool-registry/","title":"Core Concepts: Tool Registry","text":"<p>The <code>ToolRegistry</code> is one of the most powerful and unique components of SafeAgent. It's not just a place to store functions; it's a complete, production-grade framework for managing how your agent interacts with the outside world.</p>"},{"location":"core-concepts/tool-registry/#the-register-decorator","title":"The <code>@register</code> Decorator","text":"<p>You add tools to the registry using the <code>@register</code> decorator. In its simplest form, you can just decorate a Python function.</p> <pre><code>from minillm import ToolRegistry, GovernanceManager\n\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\n@tool_registry.register()\ndef get_current_user():\n    \"\"\"Returns the name of the current user.\"\"\"\n    return \"Alex\"\n</code></pre>"},{"location":"core-concepts/tool-registry/#built-in-superior-features","title":"Built-in Superior Features","text":"<p>Even in this simple example, the <code>ToolRegistry</code> is already providing immense value that is superior to other frameworks:</p> <ol> <li>Automatic Governance: Every time <code>get_current_user</code> is called via the registry, its execution is logged by the <code>GovernanceManager</code> with details about the arguments, result, and latency.</li> <li>Semantic Searchability: The tool's name (<code>get_current_user</code>) and its docstring (<code>Returns the name...</code>) are automatically embedded and indexed in a vector store. This allows the framework to dynamically find the most relevant tools for a given task.</li> <li>Automatic Schema Generation: The registry can inspect the function's signature and docstring to generate a perfect, machine-readable schema to show to the LLM, ensuring it knows how to call the tool correctly.</li> </ol>"},{"location":"core-concepts/tool-registry/#production-grade-policies","title":"Production-Grade Policies","text":"<p>The true power of the <code>ToolRegistry</code> is revealed when you add policies to the decorator. These allow you to declaratively add reliability and security features to any tool.</p> <pre><code>@tool_registry.register(\n    required_role=\"analyst\", # Security\n    cache_ttl_seconds=60,    # Caching\n    retry_attempts=3,        # Reliability\n    cost_per_call=0.01,      # Cost Tracking\n    output_sinks=[FileOutputSink()] # NEW: Output Handling\n)\ndef get_financial_data(ticker: str):\n    \"\"\"Fetches financial data for a stock ticker.\"\"\"\n    # ...\n</code></pre> <p>These features are what elevate SafeAgent from a prototyping tool to a true production framework. To learn more, see the Production Policies Advanced Guide and the guide on Output Sinks.</p>"},{"location":"examples/custom-tool-suite/","title":"Example: Building a Custom Tool Suite","text":"<p>This example demonstrates how to create and register multiple custom tools, including one that interacts with the local filesystem, each with its own set of production-grade policies.</p>"},{"location":"examples/custom-tool-suite/#1-the-goal","title":"1. The Goal","text":"<p>We want to create an agent that can both look up user information and save notes to a file. These tools have very different requirements: one is a read-only operation that can be cached, while the other is a write operation that should never be cached.</p>"},{"location":"examples/custom-tool-suite/#2-defining-the-tools","title":"2. Defining the Tools","text":"<p>This is a complete, runnable script that defines and then tests the tools.</p> <pre><code>from safeagent import ToolRegistry, GovernanceManager\nimport datetime\nimport os\nimport shutil\n\n# --- Setup ---\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\n# --- Tool 1: A read-only data lookup tool ---\n@tool_registry.register(\n    cache_ttl_seconds=3600,\n    required_role=\"support_agent\"\n)\ndef get_user_details(username: str) -&gt; dict:\n    \"\"\"Retrieves profile information for a given username, such as signup date and account tier.\"\"\"\n    print(f\"DATABASE: Querying for user '{username}'...\")\n    if username == \"alice\":\n        return {\"username\": \"alice\", \"signup_date\": \"2023-01-15\", \"tier\": \"premium\"}\n    return {\"error\": \"User not found\"}\n\n# --- Tool 2: A tool that interacts with the filesystem ---\n@tool_registry.register(\n    retry_attempts=1,\n    required_role=\"support_agent\"\n)\ndef save_note_to_file(filename: str, content: str) -&gt; str:\n    \"\"\"Saves a string of text to a local file, appending a timestamp.\"\"\"\n    try:\n        os.makedirs(\"notes\", exist_ok=True)\n        filepath = os.path.join(\"notes\", filename)\n        with open(filepath, 'a') as f:\n            f.write(f\"[{datetime.datetime.now().isoformat()}] {content}\\n\")\n        return f\"Successfully saved note to {filepath}.\"\n    except Exception as e:\n        raise e\n\n# --- Using the Tools ---\nprint(\"--- Testing the Tool Suite ---\")\ngov.start_new_run()\nuser_details_tool = tool_registry.get_governed_tool(\"get_user_details\", \"support_agent\")\n\nprint(\"\\nCalling 'get_user_details' for the first time...\")\nresult1 = user_details_tool(username=\"alice\")\nprint(f\"Result 1: {result1}\")\n\nprint(\"\\nCalling 'get_user_details' again to test cache...\")\nresult2 = user_details_tool(username=\"alice\")\nprint(f\"Result 2: {result2}\")\nprint(\"Note: The 'DATABASE: Querying...' message should only appear once.\")\n\ngov.start_new_run()\nsave_note_tool = tool_registry.get_governed_tool(\"save_note_to_file\", \"support_agent\")\nprint(\"\\nCalling 'save_note_to_file'...\")\nsave_result = save_note_tool(filename=\"support_log.txt\", content=\"Customer issue #555 resolved.\")\nprint(f\"Result: {save_result}\")\n\nif os.path.exists(\"notes\"): shutil.rmtree(\"notes\")\n\n</code></pre>"},{"location":"examples/database-integration/","title":"Example: Database Integration Agent","text":"<p>A common use case for an LLM agent is to provide a natural language interface to a database. This example shows how to build a tool that can query a SQLite database, and an agent that can use it.</p>"},{"location":"examples/database-integration/#1-setup-create-a-dummy-database","title":"1. Setup: Create a Dummy Database","text":"<p>This script creates a simple <code>company.db</code> file with some sample data.</p> <pre><code>import sqlite3\nimport os\n\nprint(\"Creating dummy database 'company.db'...\")\nconn = sqlite3.connect(\"company.db\")\ncursor = conn.cursor()\ncursor.execute(\"DROP TABLE IF EXISTS employees\")\ncursor.execute(\"CREATE TABLE employees (id INT, name TEXT, role TEXT, department TEXT)\")\ncursor.execute(\"INSERT INTO employees VALUES (1, 'Alice', 'Engineer', 'Technology')\")\ncursor.execute(\"INSERT INTO employees VALUES (2, 'Bob', 'Sales Manager', 'Sales')\")\nconn.commit()\nconn.close()\nprint(\"Database created successfully.\")\n</code></pre>"},{"location":"examples/database-integration/#2-full-agent-script","title":"2. Full Agent Script","text":"<p>This is the complete, runnable script for the database agent.</p> <pre><code>from safeagent import *\nimport sqlite3\nimport json\nimport os\n\n# --- Tool Definition ---\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\n@tool_registry.register(required_role=\"analyst\", cost_per_call=0.005)\ndef execute_sql_query(query: str) -&gt; str:\n    \"\"\"Executes a read-only SQL query on the company database. Only SELECT statements are allowed.\"\"\"\n    if not query.strip().upper().startswith(\"SELECT\"):\n        return \"Error: Only SELECT queries are permitted.\"\n    try:\n        conn = sqlite3.connect(\"company.db\")\n        cursor = conn.cursor()\n        cursor.execute(query)\n        results = cursor.fetchall()\n        column_names = [d[0] for d in cursor.description]\n        conn.close()\n        if not results: return \"Query returned no results.\"\n        return json.dumps({\"columns\": column_names, \"data\": results})\n    except Exception as e:\n        return f\"Query failed. Error: {e}\"\n\n# --- Agent Setup ---\ncfg = Config()\nllm = LLMClient(api_key=cfg.api_key)\nagent = StatefulOrchestrator(entry_node=\"formulate_query\")\n\n# --- Node Definitions ---\ndef formulate_query(state: dict) -&gt; dict:\n    prompt = f\"Given the user question, write a single, valid SQLite query to answer it. Table: 'employees' (id, name, role, department).\\nQuestion: {state['question']}\\nSQL Query:\"\n    response = llm.generate(prompt)\n    sql_query = response['text'].strip().replace('`', '').replace('sql', '')\n    return {\"sql_query\": sql_query}\n\ndef run_query(state: dict) -&gt; dict:\n    tool = tool_registry.get_governed_tool(\"execute_sql_query\", \"analyst_user\")\n    results = tool(query=state['sql_query'])\n    return {\"db_results\": results}\n\ndef synthesize_answer(state: dict) -&gt; dict:\n    prompt = f\"Based on these DB results, answer the user's question.\\nQuestion: {state['question']}\\nDB Results: {state['db_results']}\\nAnswer:\"\n    response = llm.generate(prompt)\n    return {\"final_answer\": response['text']}\n\n# --- Build and Run ---\nagent.add_node(\"formulate_query\", formulate_query)\nagent.add_node(\"run_query\", run_query)\nagent.add_node(\"synthesize_answer\", synthesize_answer)\nagent.add_edge(\"formulate_query\", \"run_query\")\nagent.add_edge(\"run_query\", \"synthesize_answer\")\nagent.add_edge(\"synthesize_answer\", \"__end__\")\n\ngov.start_new_run()\ninitial_state = {\"question\": \"Who is the sales manager?\"}\nstatus, final_state = agent.run(initial_state)\n\nprint(f\"\\n--- FINAL ANSWER ---\\n{final_state.get('final_answer')}\")\n\nif os.path.exists(\"company.db\"): os.remove(\"company.db\")\n</code></pre>"},{"location":"examples/multi-tool-agent/","title":"Example: Multi-Tool ReAct Agent","text":"<p>This advanced example builds an agent with access to multiple tools. The agent uses semantic search to choose the best tool for the job.</p>"},{"location":"examples/multi-tool-agent/#full-agent-script","title":"Full Agent Script","text":"<pre><code>from safeagent import *\nimport json\n\n# --- Setup ---\ngov = GovernanceManager()\ncfg = Config()\nllm = LLMClient(api_key=cfg.api_key)\ntool_registry = ToolRegistry(\n    governance_manager=gov,\n    embedding_config={\"api_key\": cfg.api_key},\n    similarity_metric=SimilarityMetric.COSINE\n)\n\n# --- Tool 1: Weather ---\n@tool_registry.register(cache_ttl_seconds=60)\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Gets the current weather conditions for a specified city.\"\"\"\n    if \"boston\" in city.lower(): return \"68\u00b0F and cloudy.\"\n    return \"Weather unavailable.\"\n\n# --- Tool 2: User Profile ---\n@tool_registry.register(required_role=\"support\")\ndef get_user_email(username: str) -&gt; str:\n    \"\"\"Retrieves the contact email address for a given system username.\"\"\"\n    if \"alex\" in username.lower(): return \"alex@example.com\"\n    return \"User not found.\"\n\n# --- Agent Nodes ---\ndef reason_node(state: dict) -&gt; dict:\n    question = state['question']\n    relevant_tools = tool_registry.get_relevant_tools(question, top_k=2)\n    tool_schemas = tool_registry.generate_tool_schema(relevant_tools)\n\n    prompt = f\"Question: {question}\\nHistory: {state.get('history', [])}\\nChoose the best tool from this list to answer. If no tool is relevant or you have enough info, respond with the final answer. Tools: {json.dumps(tool_schemas)}\"\n    response = llm.generate(prompt)\n\n    try:\n        decision = json.loads(response['text'])\n        return {\"decision\": decision}\n    except json.JSONDecodeError:\n        return {\"decision\": {\"tool_name\": \"__end__\", \"final_answer\": response['text']}}\n\ndef act_node(state: dict) -&gt; dict:\n    tool_name = state['decision']['tool_name']\n    tool_args = state['decision']['tool_args']\n    governed_tool = tool_registry.get_governed_tool(tool_name, user_id=\"support\")\n    observation = governed_tool(**tool_args)\n    new_history = state.get('history', []) + [f\"Tool '{tool_name}' said: '{observation}'\"]\n    return {\"history\": new_history}\n\ndef should_continue(state: dict) -&gt; str:\n    return \"__end__\" if state['decision'].get('tool_name') == \"__end__\" else \"reason_node\"\n\n# --- Build and Run ---\nagent = StatefulOrchestrator(entry_node=\"reason_node\")\nagent.add_node(\"reason_node\", reason_node)\nagent.add_node(\"act_node\", act_node)\nagent.add_conditional_edge(\"reason_node\", should_continue)\nagent.add_edge(\"act_node\", \"reason_node\")\n\n# --- Test Cases ---\nprint(\"\\n--- Test Case 1: Weather ---\")\ngov.start_new_run()\ninitial_state_1 = {\"question\": \"What's the weather like in Boston?\"}\nstatus, final_state = agent.run(initial_state_1)\nprint(f\"\\nFinal Answer: {final_state.get('decision', {}).get('final_answer')}\")\n\nprint(\"\\n--- Test Case 2: User Email ---\")\ngov.start_new_run()\ninitial_state_2 = {\"question\": \"I need the email for user alex.\"}\nstatus, final_state = agent.run(initial_state_2)\nprint(f\"\\nFinal Answer: {final_state.get('decision', {}).get('final_answer')}\")\n</code></pre>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>SafeAgent is configured primarily through environment variables, allowing you to easily switch settings without changing code. All configuration is managed by the <code>minillm.config.Config</code> dataclass.</p>"},{"location":"getting-started/configuration/#core-configuration-variables","title":"Core Configuration Variables","text":"Environment Variable <code>Config</code> Attribute Default Value Description <code>LLM_PROVIDER</code> <code>llm_provider</code> <code>\"gemini\"</code> The LLM provider to use (e.g., 'openai'). <code>GEMINI_API_KEY</code> <code>api_key</code> <code>\"\"</code> The API key for your chosen provider. <code>LLM_MODEL</code> <code>llm_model</code> <code>\"gemini-pro\"</code> The specific model to use for generation. <code>TEMPLATE_DIR</code> <code>template_dir</code> <code>\"templates\"</code> Directory for prompt templates. <code>MEMORY_BACKEND</code> <code>memory_backend</code> <code>\"redis\"</code> Backend for the MemoryManager (<code>redis</code> or <code>inmemory</code>). <code>REDIS_URL</code> <code>redis_url</code> <code>\"redis://localhost:6379\"</code> URL for your Redis server."},{"location":"getting-started/configuration/#tool-registry-embedding-configuration","title":"Tool Registry &amp; Embedding Configuration","text":"<p>These variables allow you to customize the behavior of the semantic tool search.</p> Environment Variable <code>Config</code> Attribute Default Value Description <code>EMBEDDING_DIMENSION</code> <code>embedding_dimension</code> <code>768</code> The vector dimension of your embedding model (e.g., Gemini's is 768, OpenAI's is 1536). <code>TOOL_SIMILARITY_METRIC</code> <code>tool_similarity_metric</code> <code>\"cosine\"</code> The metric for vector search. Can be <code>cosine</code>, <code>l2</code>, or <code>dot_product</code>."},{"location":"getting-started/tutorial/","title":"Getting Started with SafeAgent","text":"<p>Welcome! This guide will walk you through the core value of SafeAgent: building powerful, production-ready tools with minimal effort. We'll show you how to take a simple Python function and instantly upgrade it with security, reliability, and governance.</p>"},{"location":"getting-started/tutorial/#installation","title":"Installation","text":"<p>First, you'll need to install SafeAgent and its optional dependencies. It's recommended to do this in a virtual environment.</p> <pre><code>pip install -e .[test] faiss-cpu numpy rbac\n</code></pre> <p>Next, SafeAgent needs an LLM API key. Set your key as an environment variable, and the framework will automatically detect it.</p> <pre><code>export GEMINI_API_KEY=\"YOUR_API_KEY\"\n</code></pre>"},{"location":"getting-started/tutorial/#the-one-decorator-advantage","title":"The \"One-Decorator\" Advantage","text":"<p>The core philosophy of SafeAgent's <code>ToolRegistry</code> is to let you focus on your business logic. You write a plain Python function, and our <code>@register</code> decorator wraps it in a complete production-grade safety harness.</p> <p>Let's build an example step-by-step.</p>"},{"location":"getting-started/tutorial/#step-1-initialize-safeagent-components","title":"Step 1: Initialize SafeAgent Components","text":"<p>Every project starts by initializing the core components. For this guide, we only need the <code>GovernanceManager</code> and the <code>ToolRegistry</code>.</p> <pre><code>from minillm import ToolRegistry, GovernanceManager\n\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n</code></pre>"},{"location":"getting-started/tutorial/#step-2-define-your-core-logic","title":"Step 2: Define Your Core Logic","text":"<p>Imagine you have a function that calls a weather API which is sometimes unreliable.</p> <pre><code>def get_weather_from_flaky_api(city: str) -&gt; str:\n    \"\"\"Gets the current weather, but the API fails sometimes.\"\"\"\n    if not hasattr(get_weather_from_flaky_api, \"call_count\"):\n        get_weather_from_flaky_api.call_count = 0\n    get_weather_from_flaky_api.call_count += 1\n    if get_weather_from_flaky_api.call_count == 1:\n        raise ConnectionError(\"Network Error: Failed to connect.\")\n    return f\"It is 75\u00b0F and sunny in {city}.\"\n</code></pre>"},{"location":"getting-started/tutorial/#step-3-apply-production-policies-with-register","title":"Step 3: Apply Production Policies with <code>@register</code>","text":"<p>We take our simple, flaky function and make it robust by registering it as a governed tool.</p> <pre><code>from minillm import RBACError\n\n@tool_registry.register(\n    required_role=\"weather_forecaster\",\n    retry_attempts=2,\n    cache_ttl_seconds=60,\n    cost_per_call=0.002\n)\ndef get_weather(city: str) -&gt; str:\n    \"\"\"A governed tool to fetch the weather for a specified city.\"\"\"\n    return get_weather_from_flaky_api(city)\n</code></pre>"},{"location":"getting-started/tutorial/#step-4-use-the-governed-tool","title":"Step 4: Use the Governed Tool","text":"<p>Now, instead of calling your original function, you get the \"governed\" version from the registry.</p> <pre><code># Get the wrapped, robust version of your tool.\ngoverned_weather_tool = tool_registry.get_governed_tool(\n    name=\"get_weather\",\n    user_id=\"forecaster_alex\" # This user has the required role.\n)\n</code></pre>"},{"location":"getting-started/tutorial/#full-script-for-convenience","title":"Full Script for Convenience","text":"<p>Here is the complete, runnable script from this tutorial.</p> <pre><code>import os\nimport json\nfrom minillm import ToolRegistry, GovernanceManager, RBACError\n\nprint(\"Initializing SafeAgent components...\")\ngov = GovernanceManager()\ntool_registry = ToolRegistry(governance_manager=gov)\n\nif os.path.exists(\"audit.log\"): os.remove(\"audit.log\")\n\ndef get_weather_from_flaky_api(city: str) -&gt; str:\n    if not hasattr(get_weather_from_flaky_api, \"call_count\"):\n        get_weather_from_flaky_api.call_count = 0\n    get_weather_from_flaky_api.call_count += 1\n    if get_weather_from_flaky_api.call_count == 1:\n        raise ConnectionError(\"Network Error: Failed to connect.\")\n    return f\"It is 75\u00b0F and sunny in {city}.\"\n\n@tool_registry.register(\n    required_role=\"weather_forecaster\",\n    retry_attempts=2,\n    retry_delay=0.1,\n    cache_ttl_seconds=60,\n    cost_per_call=0.002\n)\ndef get_weather(city: str) -&gt; str:\n    return get_weather_from_flaky_api(city)\n\nprint(\"\\n--- DEMONSTRATING GOVERNED EXECUTION ---\")\ngoverned_tool = tool_registry.get_governed_tool(\"get_weather\", \"forecaster_alex\")\n\nprint(\"\\n1. Calling the tool for the first time (will retry internally)...\")\ngov.start_new_run()\nresult1 = governed_tool(city=\"Miami\")\nprint(f\"   -&gt; Success! Result: '{result1}'\")\n\nprint(\"\\n2. Calling the tool again (will hit cache)...\")\ngov.start_new_run()\nresult2 = governed_tool(city=\"Miami\")\nprint(f\"   -&gt; Success! Result: '{result2}'\")\n\nprint(\"\\n3. Calling with an unauthorized user...\")\nunauthorized_tool = tool_registry.get_governed_tool(\"get_weather\", \"intern_bob\")\ntry:\n    unauthorized_tool(city=\"Miami\")\nexcept RBACError as e:\n    print(f\"   -&gt; Success! Tool call failed as expected: {e}\")\n\nprint(\"\\n--- GOVERNANCE PROOF: INSPECTING audit.log ---\")\nwith open(\"audit.log\", \"r\") as f:\n    for line in f:\n        log = json.loads(line)\n        action = log.get('action')\n        if action == 'tool_call_error': print(\"[LOG] The underlying network error was automatically caught and logged.\")\n        if action == 'tool_call_start' and log.get('metadata', {}).get('attempt') == 2: print(\"[LOG] The retry policy automatically triggered a second attempt.\")\n        if action == 'tool_call_end': print(f\"[LOG] The tool succeeded. Log includes latency and cost: {log.get('metadata')}\")\n        if action == 'tool_cache_hit': print(\"[LOG] The second call was a cache hit! The function did not run again.\")\n        if action == 'tool_access_denied': print(f\"[LOG] The unauthorized user was correctly denied access.\")\n</code></pre>"}]}